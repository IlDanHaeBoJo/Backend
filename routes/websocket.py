import asyncio
import json
import logging
import os
from pathlib import Path
from typing import Dict, Any
import wave
import numpy as np

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from google.cloud import speech

from core.startup import service_manager
from core.config import settings

logger = logging.getLogger(__name__)

# WebSocket ë¼ìš°í„° ìƒì„±
router = APIRouter()

class AudioProcessor:
    """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì‚¬ìš©ìë³„ ì„¸ì…˜ ê´€ë¦¬
        self.user_sessions: Dict[str, Dict] = {}
    
    def get_user_session(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        if user_id not in self.user_sessions:
            self.user_sessions[user_id] = {
                "audio_buffer": bytearray(),
                "is_speaking": False,
                "silence_duration": 0,
                "min_speech_duration": 1.0,
                "max_silence_duration": 1.0,  # ë¹ ë¥¸ ì‘ë‹µ
                "is_processing": False,  # STT ì²˜ë¦¬ ì¤‘ í”Œë˜ê·¸
                "should_cancel": False,  # ì²˜ë¦¬ ì·¨ì†Œ í”Œë˜ê·¸
                "conversation_ended": False,  # ëŒ€í™” ì¢…ë£Œ í”Œë˜ê·¸
            }
        return self.user_sessions[user_id]
    
    def clear_user_session(self, user_id: str):
        """ì‚¬ìš©ì ì„¸ì…˜ ì •ë¦¬"""
        if user_id in self.user_sessions:
            del self.user_sessions[user_id]
    
    async def detect_voice_activity(self, audio_chunk: bytes) -> bool:
        """ìŒì„± í™œë™ ê°ì§€ (VAD)"""
        try:
            if len(audio_chunk) == 0:
                return False
            
            # 16-bit PCMìœ¼ë¡œ ë³€í™˜
            audio_data = np.frombuffer(audio_chunk, dtype=np.int16)
            
            if len(audio_data) == 0:
                return False
            
            # RMS ê³„ì‚°ìœ¼ë¡œ ìŒì„± ë ˆë²¨ ì¸¡ì •
            rms = np.sqrt(np.mean(audio_data.astype(np.float32) ** 2))
            
            # ë™ì  ì„ê³„ê°’ (í™˜ê²½ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
            voice_threshold = 300  # ì¡°ì • ê°€ëŠ¥
            
            return rms > voice_threshold
            
        except Exception as e:
            logger.error(f"VAD ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return False
    
    async def save_audio_buffer_as_wav(self, audio_buffer: bytearray, file_path: str):
        """ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with wave.open(file_path, 'wb') as wav_file:
                wav_file.setnchannels(settings.AUDIO_CHANNELS)
                wav_file.setsampwidth(settings.AUDIO_SAMPLE_WIDTH)
                wav_file.setframerate(settings.AUDIO_SAMPLE_RATE)
                wav_file.writeframes(bytes(audio_buffer))
                
        except Exception as e:
            logger.error(f"WAV íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            raise
    
    async def process_complete_utterance(self, websocket: WebSocket, user_id: str, audio_buffer: bytearray, session: dict):
        """ì™„ì „í•œ ë°œí™” ì²˜ë¦¬ (ì·¨ì†Œ ê°€ëŠ¥)"""
        if len(audio_buffer) == 0:
            return
        
        try:
            logger.info(f"[{user_id}] ë°œí™” ì™„ë£Œ, STT ì²˜ë¦¬ ì‹œì‘")
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                return
            
            # ì²˜ë¦¬ ì¤‘ ìƒíƒœ ì „ì†¡
            await websocket.send_text(json.dumps({
                "type": "processing",
                "message": "ìŒì„±ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "avatar_action": "thinking"
            }, ensure_ascii=False))
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                return
            
            # ì„ì‹œ WAV íŒŒì¼ ìƒì„±
            timestamp = int(asyncio.get_event_loop().time())
            temp_path = settings.TEMP_AUDIO_DIR / f"stream_{user_id}_{timestamp}.wav"
            
            # ì˜¤ë””ì˜¤ ì €ì¥
            await self.save_audio_buffer_as_wav(audio_buffer, str(temp_path))
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                if temp_path.exists():
                    temp_path.unlink()
                return
            
            # STT ì²˜ë¦¬
            user_text = await self._perform_stt(temp_path)
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                if temp_path.exists():
                    temp_path.unlink()
                return
            
            if user_text:
                logger.info(f"[{user_id}] STT ê²°ê³¼: {user_text}")
                
                # AI ì‘ë‹µ ìƒì„±
                response_data = await self._generate_ai_response(user_id, user_text)
                
                # ì·¨ì†Œ í™•ì¸ (ë§ˆì§€ë§‰ ì²´í¬)
                if session["should_cancel"]:
                    logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                    if temp_path.exists():
                        temp_path.unlink()
                    return
                
                # ëŒ€í™” ì¢…ë£Œ í™•ì¸ ë° ì„¸ì…˜ì— í”Œë˜ê·¸ ì„¤ì •
                if response_data.get("conversation_ended", False):
                    session["conversation_ended"] = True
                    logger.info(f"ğŸ [{user_id}] ì„¸ì…˜ì— ëŒ€í™” ì¢…ë£Œ í”Œë˜ê·¸ ì„¤ì • - ì´í›„ ìŒì„± ì²˜ë¦¬ ì°¨ë‹¨")
                
                # WebSocketìœ¼ë¡œ ì‘ë‹µ ì „ì†¡
                await websocket.send_text(json.dumps(response_data, ensure_ascii=False))
            else:
                # ìŒì„± ì¸ì‹ ì‹¤íŒ¨
                if not session["should_cancel"]:
                    await websocket.send_text(json.dumps({
                        "type": "no_speech",
                        "message": "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "avatar_action": "listening"
                    }, ensure_ascii=False))
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_path.exists():
                temp_path.unlink()
                
        except Exception as e:
            logger.error(f"ë°œí™” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            if not session["should_cancel"]:
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "message": "ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "avatar_action": "error"
                }, ensure_ascii=False))
    
    async def _perform_stt(self, audio_file_path: Path) -> str:
        """STT ìˆ˜í–‰"""
        try:
            with open(audio_file_path, "rb") as audio_file:
                audio_content = audio_file.read()
            
            audio = speech.RecognitionAudio(content=audio_content)
            response = service_manager.speech_client.recognize(
                config=service_manager.speech_config, 
                audio=audio
            )
            
            # ì¸ì‹ ê²°ê³¼ ìˆ˜ì§‘
            user_text = ""
            for result in response.results:
                user_text += result.alternatives[0].transcript
            
            # í•œêµ­ì–´ ì˜ë£Œ ìš©ì–´ í›„ì²˜ë¦¬
            user_text = self._correct_medical_terms(user_text.strip())
            
            return user_text
            
        except Exception as e:
            logger.error(f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return ""
    
    def _correct_medical_terms(self, text: str) -> str:
        """í•œêµ­ì–´ ì˜ë£Œ ìš©ì–´ ì˜¤ì¸ì‹ êµì •"""
        medical_corrections = {
            "ìœ„ì—¼": ["ìœ„ì—½", "ìœ„ì—´"],
            "ë³µí†µ": ["ë³µí‰", "ë³µíŠ¼", "ë³µí†¤"],
            "ë‘í†µ": ["ë‘íŠ¼", "ë‘í†¤", "íˆ¬í†µ"],
            "ì–´ì§€ëŸ¼": ["ì–´ì§€ëŸ¼ì¦", "ì–´ì§€ëŸ¬ì›€"],
            "êµ¬í† ": ["êµ´í† ", "ì¿ í† "],
            "ì„¤ì‚¬": ["ì…œì‚¬", "ì„¤ì‹¸"]
        }
        
        for correct, variants in medical_corrections.items():
            for variant in variants:
                if variant in text and variant != correct:
                    text = text.replace(variant, correct)
                    logger.info(f"ì˜ë£Œ ìš©ì–´ êµì •: {variant} â†’ {correct}")
        
        return text
    
    async def _generate_ai_response(self, user_id: str, user_text: str) -> Dict[str, Any]:
        """AI ì‘ë‹µ ìƒì„± (ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜)"""
        try:
            # ì…ë ¥ ë¡œê¹…
            print(f"\nğŸ¤ ì‚¬ìš©ì ì…ë ¥: '{user_text}'")
            
            # LLM ì‘ë‹µ ìƒì„± (ê³ ì •ëœ ì‹œë‚˜ë¦¬ì˜¤ ì‚¬ìš©)
            llm_response = await service_manager.llm_service.generate_response(user_text, user_id)
            response_text = llm_response["text"]
            conversation_ended = llm_response["conversation_ended"]
            
            # ì¶œë ¥ ë¡œê¹…
            print(f"ğŸ¤– AI ì‘ë‹µ: '{response_text}'")
            
            # TTS ìƒì„±
            audio_path = await service_manager.tts_service.generate_speech(response_text)
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„±
            response_data = {
                "type": "voice_response",
                "user_text": user_text,
                "ai_text": response_text,
                "audio_url": f"/static/audio/{Path(audio_path).name}" if audio_path else None,
                "avatar_action": "talking",
                "processing_time": "ì‹¤ì‹œê°„",
                "conversation_ended": conversation_ended
            }
            
            # ëŒ€í™” ì¢…ë£Œ ì‹œ íŠ¹ë³„ ì²˜ë¦¬
            if conversation_ended:
                response_data["type"] = "conversation_ended"
                response_data["avatar_action"] = "goodbye"
                response_data["message"] = "ì§„ë£Œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ì„¸ì…˜ì´ ê³§ ì¢…ë£Œë©ë‹ˆë‹¤."
                print(f"ğŸ [{user_id}] ëŒ€í™” ì¢…ë£Œ - ìŒì„± ì²˜ë¦¬ë¥¼ ì¤‘ë‹¨í•©ë‹ˆë‹¤")
            
            return response_data
            
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "type": "error",
                "message": "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "avatar_action": "error",
                "conversation_ended": False
            }

# ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
audio_processor = AudioProcessor()

@router.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    """WebSocket ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë°"""
    await websocket.accept()
    logger.info(f"ğŸ”— ì‹¤ì‹œê°„ ìŒì„± ì—°ê²°: {user_id}")
    
    # ì‚¬ìš©ì ì„¸ì…˜ ì´ˆê¸°í™”
    session = audio_processor.get_user_session(user_id)
    
    try:
        # ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ ë©”ì‹œì§€ ì „ì†¡
        scenarios = service_manager.llm_service.get_available_scenarios()
        scenario_options = "\n".join([f"{k}. {v}" for k, v in scenarios.items()])
        
        await websocket.send_text(json.dumps({
            "type": "scenario_selection",
            "message": f"ğŸ¥ CPX ì‹œìŠ¤í…œì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! ({user_id})\n\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:\n{scenario_options}\n\në²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê³  ìŒì„±ìœ¼ë¡œ 'ì‹œì‘'ì´ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”.",
            "scenarios": scenarios,
            "avatar_action": "idle"
        }, ensure_ascii=False))
        
        while True:
            # ì‹¤ì‹œê°„ ë©”ì‹œì§€ ìˆ˜ì‹ 
            message = await websocket.receive()
            
            if message["type"] == "websocket.receive":
                if "bytes" in message:
                    # ìŒì„± ì²­í¬ ì²˜ë¦¬
                    await handle_audio_chunk(websocket, user_id, message["bytes"], session)
                    
                elif "text" in message:
                    # í…ìŠ¤íŠ¸ ëª…ë ¹ ì²˜ë¦¬
                    command = json.loads(message["text"])
                    await handle_command(websocket, user_id, command)
                    
    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ ì—°ê²° í•´ì œ: {user_id}")
    except Exception as e:
        logger.error(f"WebSocket ì˜¤ë¥˜: {e}")
    finally:
        # ì„¸ì…˜ ì •ë¦¬ (WebSocket ì—°ê²° í•´ì œ ì‹œ)
        audio_processor.clear_user_session(user_id)
        # LLM ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ìƒíƒœë„ ì •ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
        service_manager.llm_service.clear_user_memory(user_id)
        logger.info(f"ğŸ§¹ [{user_id}] ëª¨ë“  ì‚¬ìš©ì ìƒíƒœ ì •ë¦¬ ì™„ë£Œ")

async def handle_audio_chunk(websocket: WebSocket, user_id: str, audio_chunk: bytes, session: Dict):
    """ìŒì„± ì²­í¬ ì²˜ë¦¬"""
    try:
        # ëŒ€í™” ì¢…ë£Œ í™•ì¸ - ì¢…ë£Œëœ ê²½ìš° ìŒì„± ì²˜ë¦¬ ì°¨ë‹¨
        if session.get("conversation_ended", False):
            logger.info(f"ğŸ”’ [{user_id}] ëŒ€í™” ì¢…ë£Œë¨ - ìŒì„± ì²˜ë¦¬ ì°¨ë‹¨")
            return
        
        # ì˜¤ë””ì˜¤ ë²„í¼ì— ì¶”ê°€
        session["audio_buffer"].extend(audio_chunk)
        
        # ìŒì„± í™œë™ ê°ì§€
        has_voice = await audio_processor.detect_voice_activity(audio_chunk)
        
        if has_voice:
            if not session["is_speaking"]:
                # ìƒˆë¡œìš´ ë°œí™” ì‹œì‘ - ê¸°ì¡´ ì²˜ë¦¬ ì¤‘ì´ë©´ ì·¨ì†Œ
                if session["is_processing"]:
                    logger.info(f"[{user_id}] ğŸ”„ ìƒˆ ë°œí™” ê°ì§€ - ê¸°ì¡´ ì²˜ë¦¬ ì·¨ì†Œ")
                    session["should_cancel"] = True
                    session["is_processing"] = False
                    # ê¸°ì¡´ ë²„í¼ ì´ˆê¸°í™”
                    session["audio_buffer"].clear()
                
                logger.info(f"[{user_id}] ğŸ¤ ë°œí™” ì‹œì‘")
                session["is_speaking"] = True
                session["silence_duration"] = 0
                session["should_cancel"] = False
                
                # ë¦¬ìŠ¤ë‹ ìƒíƒœ ì „ì†¡
                await websocket.send_text(json.dumps({
                    "type": "listening",
                    "message": "ìŒì„±ì„ ë“£ê³  ìˆìŠµë‹ˆë‹¤...",
                    "avatar_action": "listening"
                }, ensure_ascii=False))
            
            session["silence_duration"] = 0
            
            # ì§§ì€ ë°œí™”ëŠ” í˜¸ì‘ì–´ì¼ ê°€ëŠ¥ì„± - ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬
            if len(session["audio_buffer"]) > 0:
                buffer_duration = len(session["audio_buffer"]) / (16000 * 2)  # ì´ˆ ë‹¨ìœ„
                if buffer_duration > 0.3 and buffer_duration < 1.5:  # 0.3ì´ˆ~1.5ì´ˆ ì§§ì€ ë°œí™”
                    session["max_silence_duration"] = 0.7  # í˜¸ì‘ì–´ëŠ” ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬
                else:
                    session["max_silence_duration"] = 1.0  # ì¼ë°˜ ë°œí™”
        else:
            # ì¹¨ë¬µ êµ¬ê°„
            if session["is_speaking"]:
                session["silence_duration"] += 0.1  # 100ms ë‹¨ìœ„
                
                # ì¶©ë¶„í•œ ì¹¨ë¬µì‹œ ë°œí™” ì¢…ë£Œ ì²˜ë¦¬
                if session["silence_duration"] >= session["max_silence_duration"]:
                    # STT ì²˜ë¦¬ ì‹œì‘ í‘œì‹œ
                    session["is_processing"] = True
                    
                    await audio_processor.process_complete_utterance(
                        websocket, user_id, session["audio_buffer"], session
                    )
                    
                    # ì·¨ì†Œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì„¸ì…˜ ì´ˆê¸°í™”
                    if not session["should_cancel"]:
                        session["audio_buffer"].clear()
                        session["is_speaking"] = False
                        session["silence_duration"] = 0
                        session["is_processing"] = False
                    
    except Exception as e:
        logger.error(f"ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

async def handle_command(websocket: WebSocket, user_id: str, command: Dict):
    """í´ë¼ì´ì–¸íŠ¸ ëª…ë ¹ ì²˜ë¦¬"""
    cmd_type = command.get("type", "")
    
    if cmd_type == "select_scenario":
        scenario_id = command.get("scenario_id", "")
        logger.info(f"[{user_id}] ğŸ­ ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ: {scenario_id}")
        
        # LLM ì„œë¹„ìŠ¤ì— ì‚¬ìš©ìë³„ ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •  
        success = service_manager.llm_service.select_scenario(scenario_id, user_id)
        
        if success:
            scenario_name = service_manager.llm_service.scenarios[scenario_id]["name"]
            response = {
                "type": "scenario_selected",
                "scenario_id": scenario_id,
                "scenario_name": scenario_name,
                "message": f"âœ… {scenario_name} ì„ íƒë¨!\n\nì´ì œ í™˜ìì—ê²Œ ë§ì„ ê±¸ì–´ë³´ì„¸ìš”.",
                "avatar_action": "ready"
            }
        else:
            response = {
                "type": "error",
                "message": f"âŒ ì˜ëª»ëœ ì‹œë‚˜ë¦¬ì˜¤ ë²ˆí˜¸ì…ë‹ˆë‹¤: {scenario_id}",
                "avatar_action": "error"
            }
        
        await websocket.send_text(json.dumps(response, ensure_ascii=False))
        
    elif cmd_type == "start_session":
        case_id = command.get("case_id", "IM_001")
        logger.info(f"[{user_id}] ğŸ¥ CPX ì„¸ì…˜ ì‹œì‘: {case_id}")
        
        response = {
            "type": "session_started",
            "case_id": case_id,
            "message": "CPX ì„¸ì…˜ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ìì—ê²Œ ë§ì„ ê±¸ì–´ë³´ì„¸ìš”.",
            "avatar_action": "ready"
        }
        await websocket.send_text(json.dumps(response, ensure_ascii=False))
        
    elif cmd_type == "end_session":
        logger.info(f"[{user_id}] ğŸ CPX ì„¸ì…˜ ì¢…ë£Œ")
        
        response = {
            "type": "session_ended",
            "message": "CPX ì„¸ì…˜ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.",
            "avatar_action": "goodbye"
        }
        await websocket.send_text(json.dumps(response, ensure_ascii=False))
        
    elif cmd_type == "text_input":
        # í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥ (STT ìš°íšŒìš©)
        text_input = command.get("text", "")
        logger.info(f"[{user_id}] ğŸ“ í…ìŠ¤íŠ¸ ì§ì ‘ ì…ë ¥: '{text_input}'")
        
        if not text_input.strip():
            await websocket.send_text(json.dumps({
                "type": "error",
                "message": "ì…ë ¥ í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.",
                "avatar_action": "error"
            }, ensure_ascii=False))
            return
        
        # ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸°
        session = audio_processor.get_user_session(user_id)
        
        # ëŒ€í™” ì¢…ë£Œ í™•ì¸
        if session.get("conversation_ended", False):
            logger.info(f"ğŸ”’ [{user_id}] ëŒ€í™” ì¢…ë£Œë¨ - í…ìŠ¤íŠ¸ ì…ë ¥ ì°¨ë‹¨")
            await websocket.send_text(json.dumps({
                "type": "conversation_ended",
                "message": "ëŒ€í™”ê°€ ì´ë¯¸ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
                "avatar_action": "goodbye"
            }, ensure_ascii=False))
            return
        
        # AI ì‘ë‹µ ìƒì„± (ìŒì„± ì²˜ë¦¬ì™€ ë™ì¼í•œ ë¡œì§)
        response_data = await audio_processor._generate_ai_response(user_id, text_input)
        
        # ëŒ€í™” ì¢…ë£Œ í™•ì¸ ë° ì„¸ì…˜ì— í”Œë˜ê·¸ ì„¤ì •
        if response_data.get("conversation_ended", False):
            session["conversation_ended"] = True
            logger.info(f"ğŸ [{user_id}] í…ìŠ¤íŠ¸ ì…ë ¥ìœ¼ë¡œ ëŒ€í™” ì¢…ë£Œ ê°ì§€")
        
        # ì‘ë‹µ ì „ì†¡
        await websocket.send_text(json.dumps(response_data, ensure_ascii=False))
        
    elif cmd_type == "ping":
        # ì—°ê²° ìƒíƒœ í™•ì¸
        await websocket.send_text(json.dumps({
            "type": "pong",
            "message": "ì—°ê²° ìƒíƒœ ì–‘í˜¸",
            "timestamp": asyncio.get_event_loop().time()
        }, ensure_ascii=False)) 