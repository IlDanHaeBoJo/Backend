import asyncio
import json
import logging
import os
from pathlib import Path
from typing import Dict, Any
import wave
import numpy as np
from datetime import datetime

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from google.cloud import speech

from core.startup import service_manager
from core.config import settings
from infra.inmemory_queue import (
    enqueue_user_utterance,
    enqueue_ai_utterance,
    enqueue_conversation_ended,
    start_worker_once,
)

logger = logging.getLogger(__name__)

# WebSocket ë¼ìš°í„° ìƒì„±
router = APIRouter()

class AudioProcessor:
    """ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        # ì‚¬ìš©ìë³„ ì„¸ì…˜ ê´€ë¦¬
        self.user_sessions: Dict[str, Dict] = {}
        # í‰ê°€ ì„¸ì…˜ ID ê´€ë¦¬
        self.user_evaluation_sessions: Dict[str, str] = {}  # user_id -> session_id
    
    def get_user_session(self, user_id: str) -> Dict[str, Any]:
        """ì‚¬ìš©ì ì„¸ì…˜ ê°€ì ¸ì˜¤ê¸° ë˜ëŠ” ìƒì„±"""
        if user_id not in self.user_sessions:
            self.user_sessions[user_id] = {
                "audio_buffer": bytearray(),
                "is_speaking": False,
                "silence_duration": 0,
                "min_speech_duration": 1.0,
                "max_silence_duration": 1.0,  # ë¹ ë¥¸ ì‘ë‹µ
                "is_processing": False,  # STT ì²˜ë¦¬ ì¤‘ í”Œë˜ê·¸
                "should_cancel": False,  # ì²˜ë¦¬ ì·¨ì†Œ í”Œë˜ê·¸
                "conversation_ended": False,  # ëŒ€í™” ì¢…ë£Œ í”Œë˜ê·¸
                # "conversation_log": [],  # ëŒ€í™” ë¡œê·¸ ì €ì¥
                "scenario_id": None,  # ì„ íƒëœ ì‹œë‚˜ë¦¬ì˜¤
                "session_start_time": None,  # ì„¸ì…˜ ì‹œì‘ ì‹œê°„
            }
        return self.user_sessions[user_id]
    
    def clear_user_session(self, user_id: str):
        """ì‚¬ìš©ì ì„¸ì…˜ ì •ë¦¬"""
        if user_id in self.user_sessions:
            del self.user_sessions[user_id]
        if user_id in self.user_evaluation_sessions:
            del self.user_evaluation_sessions[user_id]
    
    async def detect_voice_activity(self, audio_chunk: bytes) -> bool:
        """ìŒì„± í™œë™ ê°ì§€ (VAD)"""
        try:
            if len(audio_chunk) == 0:
                return False
            
            # 16-bit PCMìœ¼ë¡œ ë³€í™˜
            audio_data = np.frombuffer(audio_chunk, dtype=np.int16)
            
            if len(audio_data) == 0:
                return False
            
            # RMS ê³„ì‚°ìœ¼ë¡œ ìŒì„± ë ˆë²¨ ì¸¡ì •
            rms = np.sqrt(np.mean(audio_data.astype(np.float32) ** 2))
            
            # ë™ì  ì„ê³„ê°’ (í™˜ê²½ì— ë”°ë¼ ì¡°ì • ê°€ëŠ¥)
            voice_threshold = 300  # ì¡°ì • ê°€ëŠ¥
            
            return rms > voice_threshold
            
        except Exception as e:
            logger.error(f"VAD ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return False
    
    async def save_audio_buffer_as_wav(self, audio_buffer: bytearray, file_path: str):
        """ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥"""
        try:
            with wave.open(file_path, 'wb') as wav_file:
                wav_file.setnchannels(settings.AUDIO_CHANNELS)
                wav_file.setsampwidth(settings.AUDIO_SAMPLE_WIDTH)
                wav_file.setframerate(settings.AUDIO_SAMPLE_RATE)
                wav_file.writeframes(bytes(audio_buffer))
                
        except Exception as e:
            logger.error(f"WAV íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {e}")
            raise
    
    async def process_complete_utterance(self, websocket: WebSocket, user_id: str, audio_buffer: bytearray, session: dict):
        """ì™„ì „í•œ ë°œí™” ì²˜ë¦¬ (ì·¨ì†Œ ê°€ëŠ¥)"""
        if len(audio_buffer) == 0:
            return
        
        try:
            logger.info(f"[{user_id}] ë°œí™” ì™„ë£Œ, STT ì²˜ë¦¬ ì‹œì‘")
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                return
            
            # ì²˜ë¦¬ ì¤‘ ìƒíƒœ ì „ì†¡
            await websocket.send_text(json.dumps({
                "type": "processing",
                "message": "ìŒì„±ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...",
                "avatar_action": "thinking"
            }, ensure_ascii=False))
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                return
            
            # ì„ì‹œ WAV íŒŒì¼ ìƒì„±
            timestamp = int(asyncio.get_event_loop().time()) # ??

            # ì‚¬ìš©ìë³„ í•˜ìœ„ ë””ë ‰í„°ë¦¬ ìƒì„± (ì„¸ì…˜ë³„)
            user_audio_dir = settings.TEMP_AUDIO_DIR / str(user_id) / settings.RUN_ID # "temp_audio/user_id/run_id(250807_151053)"
            user_audio_dir.mkdir(parents=True, exist_ok=True)
            temp_path = user_audio_dir / f"stream_{timestamp}.wav"
            
            # ì˜¤ë””ì˜¤ ì €ì¥
            await self.save_audio_buffer_as_wav(audio_buffer, str(temp_path))
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                if temp_path.exists():
                    temp_path.unlink()
                return
            
            # STT ì²˜ë¦¬
            user_text = await self._perform_stt(temp_path)
            
            # ì·¨ì†Œ í™•ì¸
            if session["should_cancel"]:
                logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                if temp_path.exists():
                    temp_path.unlink()
                return
            
            if user_text:
                logger.info(f"[{user_id}] STT ê²°ê³¼: {user_text}")
                
                # ì‚¬ìš©ì ë°œí™” í ì ì¬ (ë¹„ë™ê¸°, ë°±ì˜¤í”„ ì¬ì‹œë„)
                if user_id in self.user_evaluation_sessions:
                    session_id = self.user_evaluation_sessions[user_id]
                    session.setdefault("seq", 0)
                    session["seq"] += 1
                    asyncio.create_task(
                        self._enqueue_with_retry(
                            enqueue_user_utterance,
                            session_id,
                            user_id,
                            session["seq"],
                            str(temp_path),
                            user_text,
                        )
                    )
                
                # AI ì‘ë‹µ ìƒì„± (ìŒì„± íŒŒì¼ ê²½ë¡œ í¬í•¨)
                response_data = await self._generate_ai_response(user_id, user_text, str(temp_path))
                
            # ì·¨ì†Œ í™•ì¸ (ë§ˆì§€ë§‰ ì²´í¬)
                if session["should_cancel"]:
                    logger.info(f"[{user_id}] â¹ï¸  ì²˜ë¦¬ ì·¨ì†Œë¨ (ìƒˆ ë°œí™” ê°ì§€)")
                    if temp_path.exists():
                        temp_path.unlink()
                    return
                
                # ëŒ€í™” ì¢…ë£Œ í™•ì¸ ë° ì„¸ì…˜ì— í”Œë˜ê·¸ ì„¤ì •
                if response_data.get("conversation_ended", False):
                    session["conversation_ended"] = True
                    logger.info(f"ğŸ [{user_id}] ì„¸ì…˜ì— ëŒ€í™” ì¢…ë£Œ í”Œë˜ê·¸ ì„¤ì • - ì´í›„ ìŒì„± ì²˜ë¦¬ ì°¨ë‹¨")
                
                # WebSocketìœ¼ë¡œ ì‘ë‹µ ì „ì†¡
                await websocket.send_text(json.dumps(response_data, ensure_ascii=False))

                # ë°±ê·¸ë¼ìš´ë“œ í ì ì¬ (AI ë°œí™” / ì¢…ë£Œ)
                if user_id in self.user_evaluation_sessions:
                    session_id = self.user_evaluation_sessions[user_id]
                    if not response_data.get("conversation_ended", False):
                        # AI ë°œí™” í ì ì¬ (ë¹„ë™ê¸°, ë°±ì˜¤í”„ ì¬ì‹œë„)
                        session.setdefault("seq", 0)
                        session["seq"] += 1
                        asyncio.create_task(
                            self._enqueue_with_retry(
                                enqueue_ai_utterance,
                                session_id,
                                user_id,
                                session["seq"],
                                response_data.get("audio_url"),
                                response_data.get("ai_text", ""),
                            )
                        )
                    else:
                        # ì¢…ë£Œ ì‹ í˜¸ í ì ì¬ í›„ ì†Œì¼“ ì¢…ë£Œ (ë¹„ë™ê¸°, ë°±ì˜¤í”„ ì¬ì‹œë„)
                        session.setdefault("seq", 0)
                        session["seq"] += 1
                        asyncio.create_task(
                            self._enqueue_with_retry(
                                enqueue_conversation_ended,
                                session_id,
                                user_id,
                                session["seq"],
                            )
                        )
                        try:
                            await websocket.close(code=1000)
                        except Exception:
                            pass
            else:
                # ìŒì„± ì¸ì‹ ì‹¤íŒ¨
                if not session["should_cancel"]:
                    await websocket.send_text(json.dumps({
                        "type": "no_speech",
                        "message": "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "avatar_action": "listening"
                    }, ensure_ascii=False))
            
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬ - í‰ê°€ ì„œë¹„ìŠ¤ì—ì„œ ê´€ë¦¬í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ì‚­ì œí•˜ì§€ ì•ŠìŒ
            # í‰ê°€ ì™„ë£Œ ì‹œ _cleanup_audio_files()ì—ì„œ ì¼ê´„ ì‚­ì œ
            # if temp_path.exists():
            #     temp_path.unlink()
                
        except Exception as e:
            logger.error(f"ë°œí™” ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            if not session["should_cancel"]:
                await websocket.send_text(json.dumps({
                    "type": "error",
                    "message": "ìŒì„± ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                    "avatar_action": "error"
                }, ensure_ascii=False))
    
    async def _perform_stt(self, audio_file_path: Path) -> str:
        """STT ìˆ˜í–‰"""
        try:
            with open(audio_file_path, "rb") as audio_file:
                audio_content = audio_file.read()
            
            audio = speech.RecognitionAudio(content=audio_content)
            response = service_manager.speech_client.recognize(
                config=service_manager.speech_config, 
                audio=audio
            )
            
            # ì¸ì‹ ê²°ê³¼ ìˆ˜ì§‘
            user_text = ""
            for result in response.results:
                user_text += result.alternatives[0].transcript
            
            # í•œêµ­ì–´ ì˜ë£Œ ìš©ì–´ í›„ì²˜ë¦¬
            user_text = self._correct_medical_terms(user_text.strip())
            
            return user_text
            
        except Exception as e:
            logger.error(f"STT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return ""
    
    def _correct_medical_terms(self, text: str) -> str:
        """í•œêµ­ì–´ ì˜ë£Œ ìš©ì–´ ì˜¤ì¸ì‹ êµì •"""
        medical_corrections = {
            "ìœ„ì—¼": ["ìœ„ì—½", "ìœ„ì—´"],
            "ë³µí†µ": ["ë³µí‰", "ë³µíŠ¼", "ë³µí†¤"],
            "ë‘í†µ": ["ë‘íŠ¼", "ë‘í†¤", "íˆ¬í†µ"],
            "ì–´ì§€ëŸ¼": ["ì–´ì§€ëŸ¼ì¦", "ì–´ì§€ëŸ¬ì›€"],
            "êµ¬í† ": ["êµ´í† ", "ì¿ í† "],
            "ì„¤ì‚¬": ["ì…œì‚¬", "ì„¤ì‹¸"]
        }
        
        for correct, variants in medical_corrections.items():
            for variant in variants:
                if variant in text and variant != correct:
                    text = text.replace(variant, correct)
                    logger.info(f"ì˜ë£Œ ìš©ì–´ êµì •: {variant} â†’ {correct}")
        
        return text
    
    async def _generate_ai_response(self, user_id: str, user_text: str, audio_file_path: str = None) -> Dict[str, Any]:
        """AI ì‘ë‹µ ìƒì„± (ì‹œë‚˜ë¦¬ì˜¤ ê¸°ë°˜)"""
        try:
            # ì„¸ì…˜ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            session = self.get_user_session(user_id)
            
            # ì…ë ¥ ë¡œê¹…
            print(f"\nğŸ¤ ì‚¬ìš©ì ì…ë ¥: '{user_text}'")
            
            # LLM ì‘ë‹µ ìƒì„± (ê³ ì •ëœ ì‹œë‚˜ë¦¬ì˜¤ ì‚¬ìš©)
            llm_response = await service_manager.llm_service.generate_response(user_text, user_id)
            response_text = llm_response["text"]
            conversation_ended = llm_response["conversation_ended"]
            
            # ì¶œë ¥ ë¡œê¹…
            print(f"ğŸ¤– AI ì‘ë‹µ: '{response_text}'")
            
            # TTS ìƒì„±
            audio_path = await service_manager.tts_service.generate_speech(response_text)
            logger.info(f"ğŸ”Š TTS íŒŒì¼ ìƒì„±ë¨: {audio_path}")
            
            # ì‘ë‹µ ë°ì´í„° êµ¬ì„± (í”„ë¡ íŠ¸ ì „ì†¡ìš© audio_url, ì„œë²„ ë‚´ë¶€ìš© audio_path ëª¨ë‘ ìœ ì§€)
            audio_url = Path(audio_path).name if audio_path else None
            logger.info(f"ğŸ”— WebSocket ì „ì†¡í•  audio_url: {audio_url}")
            response_data = {
                "type": "voice_response",
                "user_text": user_text,
                "ai_text": response_text,
                "audio_url": audio_url,
                "audio_path": str(audio_path) if audio_path else None,
                "avatar_action": "talking",
                "processing_time": "ì‹¤ì‹œê°„",
                "conversation_ended": conversation_ended,
            }
            
            # ëŒ€í™” ì¢…ë£Œ ì‹œ íŠ¹ë³„ ì²˜ë¦¬(ì‘ë‹µ êµ¬ì„±ë§Œ ë³€ê²½). í‰ê°€ëŠ” ì›Œì»¤ê°€ ì¢…ë£Œ ì´ë²¤íŠ¸ + pendingìœ¼ë¡œ íŠ¸ë¦¬ê±°
            if conversation_ended:
                response_data["type"] = "conversation_ended"
                response_data["avatar_action"] = "goodbye"
                response_data["message"] = "ì§„ë£Œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. í‰ê°€ ê²°ê³¼ëŠ” ê³§ ì €ì¥ë©ë‹ˆë‹¤."
            
            return response_data
            
        except Exception as e:
            logger.error(f"AI ì‘ë‹µ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                "type": "error",
                "message": "ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.",
                "avatar_action": "error",
                "conversation_ended": False
            }

    async def _enqueue_with_retry(self, func, *args, **kwargs):
        """ë¹„ë™ê¸° í ì ì¬ì— ëŒ€í•œ ê°„ë‹¨í•œ ë°±ì˜¤í”„ ì¬ì‹œë„ ë˜í¼
        - func: enqueue_user_utterance/enqueue_ai_utterance/enqueue_conversation_ended
        - args: í•´ë‹¹ í•¨ìˆ˜ ì¸ì ê·¸ëŒ€ë¡œ ì „ë‹¬
        ì •ì±…: 3íšŒ ì¬ì‹œë„, 0.1s, 0.3s, 0.9s ì§€ìˆ˜ ë°±ì˜¤í”„
        ì‹¤íŒ¨ ì‹œ ë¡œê¹…ë§Œ í•˜ê³  ë“œë¡­(ìš”êµ¬ì‚¬í•­ìƒ ìœ ì‹¤ í—ˆìš©)
        """
        delays = [0.1, 0.3, 0.9]
        last_exc = None
        for i, delay in enumerate([0.0] + delays):
            if delay > 0:
                await asyncio.sleep(delay)
            try:
                await func(*args, **kwargs)
                return True
            except Exception as e:
                last_exc = e
                logger.warning(
                    f"enqueue retry {i}/{len(delays)} failed: func={getattr(func, '__name__', str(func))}, err={e}"
                )
        logger.error(
            f"enqueue failed after retries: func={getattr(func, '__name__', str(func))}, args={args}, kwargs={kwargs}, err={last_exc}"
        )
        return False

# ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ì¸ìŠ¤í„´ìŠ¤
audio_processor = AudioProcessor()

@router.websocket("/ws/{user_id}")
async def websocket_endpoint(websocket: WebSocket, user_id: str):
    """WebSocket ì‹¤ì‹œê°„ ìŒì„± ìŠ¤íŠ¸ë¦¬ë°"""
    await websocket.accept()
    logger.info(f"ğŸ”— ì‹¤ì‹œê°„ ìŒì„± ì—°ê²°: {user_id}")
    
    # ì‚¬ìš©ì ì„¸ì…˜ ì´ˆê¸°í™”
    session = audio_processor.get_user_session(user_id)
    
    try:
        # ì›Œì»¤ ì‹œì‘ (ìµœì´ˆ 1íšŒ)
        start_worker_once()

        # ì‹œë‚˜ë¦¬ì˜¤ ì„ íƒ ë©”ì‹œì§€ ì „ì†¡
        scenarios = service_manager.llm_service.get_available_scenarios()
        scenario_options = "\n".join([f"{k}. {v}" for k, v in scenarios.items()])
        # ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤(ì¹˜ë§¤) ì„¤ì • ë° í‰ê°€ ì„¸ì…˜ ì‹œì‘
        default_scenario_id = "3"  # ì¹˜ë§¤ ì‹œë‚˜ë¦¬ì˜¤
        session["scenario_id"] = default_scenario_id
        session["session_start_time"] = datetime.now().isoformat()
        
        # LLM ì„œë¹„ìŠ¤ì— ì‹œë‚˜ë¦¬ì˜¤ ì„¤ì •
        service_manager.llm_service.select_scenario(default_scenario_id, user_id)
        
        # í‰ê°€ ì„¸ì…˜ ì‹œì‘
        eval_session_id = await service_manager.evaluation_service.start_evaluation_session(
            user_id, default_scenario_id
        )
        audio_processor.user_evaluation_sessions[user_id] = eval_session_id
        
        print(f"ğŸ­ [{user_id}] ê¸°ë³¸ ì‹œë‚˜ë¦¬ì˜¤({default_scenario_id}) ì„¤ì • ë° í‰ê°€ ì„¸ì…˜ ì‹œì‘: {eval_session_id}")
        
        # ì‹œì‘ ë©”ì‹œì§€ ì „ì†¡
        await websocket.send_text(json.dumps({
            # "type": "scenario_selection",
            # "message": f"ğŸ¥ CPX ì‹œìŠ¤í…œì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! ({user_id})\n\nğŸ“‹ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”:\n{scenario_options}\n\në²ˆí˜¸ë¥¼ ì…ë ¥í•˜ê³  ìŒì„±ìœ¼ë¡œ 'ì‹œì‘'ì´ë¼ê³  ë§ì”€í•´ì£¼ì„¸ìš”.",
            # "scenarios": scenarios,
            # "avatar_action": "idle"
            "type": "session_started",
            "message": f"ğŸ¥ CPX ì‹œìŠ¤í…œì— ì—°ê²°ë˜ì—ˆìŠµë‹ˆë‹¤! ({user_id})\n\nì¹˜ë§¤ í™˜ì ì‹œë‚˜ë¦¬ì˜¤ê°€ ì„¤ì •ë˜ì—ˆìŠµë‹ˆë‹¤.\nì§€ê¸ˆë¶€í„° í™˜ìì—ê²Œ ë§ì„ ê±¸ì–´ë³´ì„¸ìš”.",
            "scenario_id": default_scenario_id,
            "avatar_action": "ready"
        }, ensure_ascii=False))
        
        while True:
            # ì‹¤ì‹œê°„ ë©”ì‹œì§€ ìˆ˜ì‹ 
            message = await websocket.receive()
            
            if message["type"] == "websocket.receive":
                if "bytes" in message:
                    # ìŒì„± ì²­í¬ ì²˜ë¦¬
                    await handle_audio_chunk(websocket, user_id, message["bytes"], session)
                    
    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ ì—°ê²° í•´ì œ: {user_id}")
    except Exception as e:
        logger.error(f"WebSocket ì˜¤ë¥˜: {e}")
    finally:
        # í‰ê°€ ì„¸ì…˜ ë³´í˜¸: í‰ê°€ ì§„í–‰ ì¤‘ì´ë©´ ì •ë¦¬ ì—°ê¸°
        if user_id in audio_processor.user_evaluation_sessions:
            session_id = audio_processor.user_evaluation_sessions[user_id]
            print(f"âš ï¸ [{user_id}] í‰ê°€ ì„¸ì…˜ ë³´í˜¸ - ë°±ê·¸ë¼ìš´ë“œ í‰ê°€ ì™„ë£Œê¹Œì§€ ëŒ€ê¸°: {session_id}")
            # í‰ê°€ ì„¸ì…˜ì€ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì •ë¦¬í•˜ë„ë¡ í•¨
        
        # WebSocket ì„¸ì…˜ë§Œ ì •ë¦¬ (í‰ê°€ ì„¸ì…˜ì€ ë³´ì¡´)
        if user_id in audio_processor.user_sessions:
            del audio_processor.user_sessions[user_id]
        
        # LLM ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ì ìƒíƒœë„ ì •ë¦¬ (ë©”ëª¨ë¦¬ ì ˆì•½)
        service_manager.llm_service.clear_user_memory(user_id)
        logger.info(f"ğŸ§¹ [{user_id}] WebSocket ì„¸ì…˜ ì •ë¦¬ ì™„ë£Œ (í‰ê°€ ì„¸ì…˜ ë³´ì¡´)")

async def handle_audio_chunk(websocket: WebSocket, user_id: str, audio_chunk: bytes, session: Dict):
    """ìŒì„± ì²­í¬ ì²˜ë¦¬"""
    try:
        # ëŒ€í™” ì¢…ë£Œ í™•ì¸ - ì¢…ë£Œëœ ê²½ìš° ìŒì„± ì²˜ë¦¬ ì°¨ë‹¨
        if session.get("conversation_ended", False):
            logger.info(f"ğŸ”’ [{user_id}] ëŒ€í™” ì¢…ë£Œë¨ - ìŒì„± ì²˜ë¦¬ ì°¨ë‹¨")
            return
        
        # ì˜¤ë””ì˜¤ ë²„í¼ì— ì¶”ê°€
        session["audio_buffer"].extend(audio_chunk)
        
        # ìŒì„± í™œë™ ê°ì§€
        has_voice = await audio_processor.detect_voice_activity(audio_chunk)
        
        if has_voice:
            if not session["is_speaking"]:
                # ìƒˆë¡œìš´ ë°œí™” ì‹œì‘ - ê¸°ì¡´ ì²˜ë¦¬ ì¤‘ì´ë©´ ì·¨ì†Œ
                if session["is_processing"]:
                    logger.info(f"[{user_id}] ğŸ”„ ìƒˆ ë°œí™” ê°ì§€ - ê¸°ì¡´ ì²˜ë¦¬ ì·¨ì†Œ")
                    session["should_cancel"] = True
                    session["is_processing"] = False
                    # ê¸°ì¡´ ë²„í¼ ì´ˆê¸°í™”
                    session["audio_buffer"].clear()
                
                logger.info(f"[{user_id}] ğŸ¤ ë°œí™” ì‹œì‘")
                session["is_speaking"] = True
                session["silence_duration"] = 0
                session["should_cancel"] = False
                
                # ë¦¬ìŠ¤ë‹ ìƒíƒœ ì „ì†¡
                await websocket.send_text(json.dumps({
                    "type": "listening",
                    "message": "ìŒì„±ì„ ë“£ê³  ìˆìŠµë‹ˆë‹¤...",
                    "avatar_action": "listening"
                }, ensure_ascii=False))
            
            session["silence_duration"] = 0
            
            # ì§§ì€ ë°œí™”ëŠ” í˜¸ì‘ì–´ì¼ ê°€ëŠ¥ì„± - ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬
            if len(session["audio_buffer"]) > 0:
                buffer_duration = len(session["audio_buffer"]) / (16000 * 2)  # ì´ˆ ë‹¨ìœ„
                if buffer_duration > 0.3 and buffer_duration < 1.5:  # 0.3ì´ˆ~1.5ì´ˆ ì§§ì€ ë°œí™”
                    session["max_silence_duration"] = 0.7  # í˜¸ì‘ì–´ëŠ” ë” ë¹ ë¥´ê²Œ ì²˜ë¦¬
                else:
                    session["max_silence_duration"] = 1.0  # ì¼ë°˜ ë°œí™”
        else:
            # ì¹¨ë¬µ êµ¬ê°„
            if session["is_speaking"]:
                session["silence_duration"] += 0.1  # 100ms ë‹¨ìœ„
                
                # ì¶©ë¶„í•œ ì¹¨ë¬µì‹œ ë°œí™” ì¢…ë£Œ ì²˜ë¦¬
                if session["silence_duration"] >= session["max_silence_duration"]:
                    # STT ì²˜ë¦¬ ì‹œì‘ í‘œì‹œ
                    session["is_processing"] = True
                    
                    await audio_processor.process_complete_utterance(
                        websocket, user_id, session["audio_buffer"], session
                    )
                    
                    # ì·¨ì†Œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì„¸ì…˜ ì´ˆê¸°í™”
                    if not session["should_cancel"]:
                        session["audio_buffer"].clear()
                        session["is_speaking"] = False
                        session["silence_duration"] = 0
                        session["is_processing"] = False
                    
    except Exception as e:
        logger.error(f"ì˜¤ë””ì˜¤ ì²­í¬ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

 