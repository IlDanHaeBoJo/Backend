from typing import Dict, List, Optional, TypedDict, Annotated
from datetime import datetime
from pathlib import Path
import json
import asyncio
import aiofiles
import torch
import numpy as np
import librosa
import logging
import os

# LangGraph ê´€ë ¨ import
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage as AnyMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# CPX í‰ê°€ ìƒíƒœ ì •ì˜ (Multi-Step Reasoning ì „ìš©)
class CPXEvaluationState(TypedDict):
    """CPX í‰ê°€ ìƒíƒœ ì •ì˜ - Multi-Step Reasoning ì „ìš©"""
    # ì…ë ¥ ë°ì´í„°
    user_id: str
    scenario_id: str
    conversation_log: List[Dict]
    
    # Multi-Step Reasoning ê²°ê³¼ë“¤ (í•µì‹¬)
    medical_context_analysis: Optional[Dict]
    question_intent_analysis: Optional[Dict]
    completeness_assessment: Optional[Dict]
    quality_evaluation: Optional[Dict]
    appropriateness_validation: Optional[Dict]
    
    # ì¢…í•© í‰ê°€ ê²°ê³¼
    comprehensive_evaluation: Optional[Dict]
    
    # ìµœì¢… ê²°ê³¼
    final_scores: Optional[Dict]
    feedback: Optional[Dict]
    
    # ë©”íƒ€ë°ì´í„°
    evaluation_metadata: Optional[Dict]
    
    # ë©”ì‹œì§€ ì¶”ì 
    messages: Annotated[List[AnyMessage], add_messages]

class EvaluationService:
    def __init__(self):
        """CPX í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        # ì¹´í…Œê³ ë¦¬ë³„ í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        self.evaluation_checklists = self._load_evaluation_checklists()
        
        # ê¸°ì¡´ í•˜ë“œì½”ë”©ëœ ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ëŠ” ì œê±°í•˜ê³  JSON ê¸°ë°˜ìœ¼ë¡œ í†µí•©
        
        self.session_data = {}  # ì„¸ì…˜ë³„ í‰ê°€ ë°ì´í„°
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥ ë””ë ‰í„°ë¦¬
        self.evaluation_dir = Path("evaluation_results")
        self.evaluation_dir.mkdir(parents=True, exist_ok=True)
        
        # ê°ì • ë¶„ì„ ëª¨ë¸ ê´€ë ¨ (SER)
        self.emotion_model = None
        self.emotion_processor = None
        self.emotion_labels = ["Anxious", "Dry", "Kind"]
        self.ser_model_path = Path("Backend/SER/results_quick_test/adversary_model_augment_v1_epoch_5")  # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        
        # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ ê´€ë ¨
        self.llm = None
        self.workflow = None
        self._initialize_langgraph_components()

    def _load_evaluation_checklists(self) -> Dict:
        """ì¹´í…Œê³ ë¦¬ë³„ í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ"""
        checklists = {}
        checklist_dir = Path("evaluation_checklists")
        
        if not checklist_dir.exists():
            print("âš ï¸ evaluation_checklists ë””ë ‰í„°ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return checklists
        
        for json_file in checklist_dir.glob("*.json"):
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    category = data.get("category")
                    if category:
                        checklists[category] = data
                        print(f"âœ… í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ: {category}")
                    else:
                        print(f"âš ï¸ {json_file.name}ì—ì„œ category í•„ë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except json.JSONDecodeError as e:
                print(f"âŒ JSON íŒŒì‹± ì˜¤ë¥˜ ({json_file.name}): {e}")
            except Exception as e:
                print(f"âŒ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ ì˜¤ë¥˜ ({json_file.name}): {e}")
        
        return checklists

    def get_evaluation_checklist(self, category: str) -> Optional[Dict]:
        """ì¹´í…Œê³ ë¦¬ë³„ í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë°˜í™˜"""
        return self.evaluation_checklists.get(category)

    def _get_scenario_category(self, scenario_id: str) -> Optional[str]:
        """ì‹œë‚˜ë¦¬ì˜¤ íŒŒì¼ì—ì„œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë¡œë“œ"""
        try:
            scenario_path = Path(f"scenarios/neurology_dementia_case.json")  # í˜„ì¬ëŠ” í•˜ë‚˜ì˜ ì‹œë‚˜ë¦¬ì˜¤ë§Œ
            if not scenario_path.exists():
                return None
            
            with open(scenario_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                return data.get("scenario_info", {}).get("category")
        except Exception as e:
            print(f"âŒ ì‹œë‚˜ë¦¬ì˜¤ ì¹´í…Œê³ ë¦¬ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None

    def _extract_applicable_categories(self, checklist: Dict) -> List[Dict]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ì—ì„œ ì ìš© ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ë“¤ ì¶”ì¶œ"""
        categories = []
        
        for area_name, area_data in checklist.get("evaluation_areas", {}).items():
            for subcat_id, subcat_data in area_data.get("subcategories", {}).items():
                # applicableì´ Falseì¸ ê²½ìš° ì œì™¸
                if subcat_data.get("applicable", True):
                    categories.append({
                        "category_id": subcat_id,
                        "name": subcat_data["name"],
                        "required_questions": subcat_data.get("required_questions", subcat_data.get("required_actions", [])),
                        "weight": subcat_data.get("weight", 0.1),
                        "area": area_name
                    })
        
        return categories

    def _create_default_completeness_result(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """ê¸°ë³¸ ì™„ì„±ë„ ê²°ê³¼ ìƒì„± (ì˜¤ë¥˜ ì‹œ)"""
        completeness = {
            "category_completeness": {},
            "overall_completeness_score": 0.0,
            "critical_gaps": [],
            "medical_completeness_analysis": "ì¹´í…Œê³ ë¦¬ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ í‰ê°€ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤."
        }
        
        return {
            **state,
            "completeness_assessment": completeness,
            "messages": state["messages"] + [HumanMessage(content="Step 3: ê¸°ë³¸ ì™„ì„±ë„ í‰ê°€ ì™„ë£Œ")]
        }

    async def start_evaluation_session(self, user_id: str, scenario_id: str) -> str:
        """í‰ê°€ ì„¸ì…˜ ì‹œì‘"""
        session_id = f"{user_id}_{scenario_id}_{int(datetime.now().timestamp())}"
        
        self.session_data[session_id] = {
            "user_id": user_id,
            "scenario_id": scenario_id,
            "start_time": datetime.now(),
            "conversation_entries": [],  # ì‹¤ì‹œê°„ ëŒ€í™” ë°ì´í„°
            # "audio_files": [],  # ì„ì‹œ ì €ì¥ëœ wav íŒŒì¼ ê²½ë¡œë“¤
            "status": "active"
        }
        
        return session_id

    async def add_conversation_entry(self, session_id: str, audio_file_path: str, 
                                   text: str, speaker_role: str) -> Dict:
        """ì‹¤ì‹œê°„ ëŒ€í™” ì—”íŠ¸ë¦¬ ì¶”ê°€ (ìŒì„± ë¶„ì„ í¬í•¨)"""
        if session_id not in self.session_data:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        try:
            timestamp = datetime.now()
            emotion_analysis = None
            
            # ì˜ì‚¬(doctor) ìŒì„±ì¸ ê²½ìš°ì—ë§Œ ê°ì • ë¶„ì„ ìˆ˜í–‰
            if speaker_role == "doctor":
                await self.load_emotion_model()  # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ
                
                if self.emotion_model is not None:
                    emotion_result = await self.analyze_single_audio(audio_file_path)
                    if "error" not in emotion_result:
                        emotion_analysis = {
                            "predicted_emotion": emotion_result["predicted_emotion"],
                            "confidence": emotion_result["confidence"],
                            "emotion_scores": emotion_result["emotion_scores"]
                        }
                        print(f"ğŸ­ [{session_id}] ê°ì • ë¶„ì„ ì™„ë£Œ: {emotion_analysis['predicted_emotion']} ({emotion_analysis['confidence']:.2f})")
            
            # ëŒ€í™” ì—”íŠ¸ë¦¬ ìƒì„±
            conversation_entry = {
                "timestamp": timestamp.isoformat(),
                "text": text,
                "emotion": emotion_analysis,
                "speaker_role": speaker_role,  # "doctor" (ì˜ì‚¬) or "patient" (í™˜ì)
                "audio_file_path": audio_file_path
            }
            
            # ì„¸ì…˜ ë°ì´í„°ì— ì¶”ê°€
            session = self.session_data[session_id]
            session["conversation_entries"].append(conversation_entry)
            session["audio_files"].append(audio_file_path)
            
            print(f"ğŸ“ [{session_id}] ëŒ€í™” ì—”íŠ¸ë¦¬ ì¶”ê°€: {speaker_role} - {text[:50]}...")
            
            # í‰ê°€ ì™„ë£Œ í›„ ì„ì‹œ WAV íŒŒì¼ë“¤ ì‚­ì œ
            try:
                await self._cleanup_audio_files(audio_file_path)
            except Exception as e:
                print(f"âŒ [{audio_file_path}] ì„ì‹œ WAV íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {e}")
            
            return {
                "success": True,
                "entry": conversation_entry,
                "total_entries": len(session["conversation_entries"])
            }
            
        except Exception as e:
            print(f"âŒ [{session_id}] ëŒ€í™” ì—”íŠ¸ë¦¬ ì¶”ê°€ ì‹¤íŒ¨: {e}")
            return {"error": str(e)}

    async def load_emotion_model(self):
        """ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ (ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)"""
        if self.emotion_model is not None:
            return 
        
        try:
            print("ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # ëª¨ë¸ ê²½ë¡œ í™•ì¸
            if self.ser_model_path.exists():
                from transformers import Wav2Vec2Processor
                from SER.finetune_direct import custom_Wav2Vec2ForEmotionClassification
                
                self.emotion_model = custom_Wav2Vec2ForEmotionClassification.from_pretrained(
                    str(self.ser_model_path)
                )
                self.emotion_processor = Wav2Vec2Processor.from_pretrained(
                    str(self.ser_model_path)
                )
                
                # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
                self.emotion_model.eval()
                
                print("âœ… ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âš ï¸ ê°ì • ë¶„ì„ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {self.ser_model_path}")
                print("   ê¸°ë³¸ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
                
                from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor, Wav2Vec2Config
                
                model_name = "kresnik/wav2vec2-large-xlsr-korean"
                label2id = {label: i for i, label in enumerate(self.emotion_labels)}
                id2label = {i: label for i, label in enumerate(self.emotion_labels)}
                
                config = Wav2Vec2Config.from_pretrained(
                    model_name,
                    num_labels=len(self.emotion_labels),
                    label2id=label2id,
                    id2label=id2label,
                    finetuning_task="emotion_classification"
                )
                
                self.emotion_model = Wav2Vec2ForSequenceClassification.from_pretrained(
                    model_name,
                    config=config,
                    ignore_mismatched_sizes=True
                )
                self.emotion_processor = Wav2Vec2Processor.from_pretrained(model_name)
                self.emotion_model.eval()
                
                print("âœ… ê¸°ë³¸ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.emotion_model = None
            self.emotion_processor = None

    async def analyze_single_audio(self, audio_file_path: str) -> Dict:
        """ë‹¨ì¼ ìŒì„± íŒŒì¼ ê°ì • ë¶„ì„"""
        if self.emotion_model is None or self.emotion_processor is None:
            await self.load_emotion_model()
            
        if self.emotion_model is None:
            return {"error": "ê°ì • ë¶„ì„ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
            audio_path = Path(audio_file_path)
            if not audio_path.exists():
                return {"error": f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}"}
            
            # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
            audio_data = await self._preprocess_audio(str(audio_path))
            if audio_data is None:
                return {"error": "ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨"}
            
            # ê°ì • ë¶„ì„ ìˆ˜í–‰
            with torch.no_grad():
                inputs = {
                    "input_values": audio_data,  # ì´ë¯¸ ë°°ì¹˜ ì°¨ì›ì´ ìˆìŒ (1, sequence_length)
                    "attention_mask": None
                }
                
                outputs = self.emotion_model(**inputs)
                logits = outputs['emotion_logits']
                
                # ì˜ˆì¸¡ ê²°ê³¼ ê³„ì‚°
                probabilities = torch.nn.functional.softmax(logits, dim=-1)
                predicted_id = torch.argmax(logits, dim=-1).item()
                confidence = probabilities[0][predicted_id].item()
                
                # ì˜ˆì¸¡ ê°ì • ê²°ê³¼
                predicted_emotion = self.emotion_labels[predicted_id]
                
                # ëª¨ë“  ê°ì •ë³„ í™•ë¥ 
                emotion_scores = {
                    emotion: probabilities[0][i].item() 
                    for i, emotion in enumerate(self.emotion_labels)
                }
                
                return {
                    "predicted_emotion": predicted_emotion,
                    "confidence": confidence,
                    "emotion_scores": emotion_scores,
                    "file_path": str(audio_path)
                }
                
        except Exception as e:
            return {"error": f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}

    async def _preprocess_audio(self, file_path: str) -> Optional[torch.Tensor]:
        """ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (Wav2Vec2ìš©)"""
        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ (16kHzë¡œ ë¦¬ìƒ˜í”Œë§)
            audio, sr = librosa.load(file_path, sr=16000, res_type='kaiser_fast')
            
            # ê¸¸ì´ ì œí•œ (ìµœëŒ€ 10ì´ˆ)
            max_duration = 10.0
            target_length = int(16000 * max_duration)
            
            if len(audio) > target_length:
                # ê°€ìš´ë° ë¶€ë¶„ ì‚¬ìš©
                start_idx = np.random.randint(0, len(audio) - target_length + 1)
                audio = audio[start_idx:start_idx + target_length]
            elif len(audio) < target_length:
                # íŒ¨ë”© ì¶”ê°€
                pad_length = target_length - len(audio)
                audio = np.pad(audio, (0, pad_length), mode='constant', constant_values=0)
            
            # ì •ê·œí™”
            # if np.max(np.abs(audio)) > 0:
            #     audio = audio / np.max(np.abs(audio)) * 0.8
            
            # Wav2Vec2 processorë¡œ ë³€í™˜
            inputs = self.emotion_processor(
                audio,
                sampling_rate=16000,
                return_tensors="pt",
                padding=True
            )
            
            return inputs.input_values.squeeze(0)
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None





    async def end_evaluation_session(self, session_id: str) -> Dict:
        """í‰ê°€ ì„¸ì…˜ ì¢…ë£Œ ë° ì¢…í•© í‰ê°€ ì‹¤í–‰"""
        if session_id not in self.session_data:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        session = self.session_data[session_id]
        session["end_time"] = datetime.now()
        session["status"] = "completed"
        
        # ì¢…í•© í‰ê°€ ì‹¤í–‰
        evaluation_result = await self._comprehensive_evaluation(session_id, session)
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥
        await self._save_evaluation_result(session_id, evaluation_result)
        
        return evaluation_result

    def get_session_summary(self, user_id: str) -> list:
        """ì‚¬ìš©ìì˜ ì„¸ì…˜ ìš”ì•½"""
        return [
            {
                "session_id": sid,
                "scenario_id": data["scenario_id"],
                "date": data["start_time"].strftime("%Y-%m-%d %H:%M"),
                "status": data["status"]
            }
            for sid, data in self.session_data.items()
            if data["user_id"] == user_id
        ]

    async def _comprehensive_evaluation(self, session_id: str, session: Dict) -> Dict:
        """ì¢…í•©ì ì¸ ì„¸ì…˜ í‰ê°€ ìˆ˜í–‰ (SER + LangGraph í†µí•©)"""
        print(f"ğŸ” [{session_id}] ì¢…í•© í‰ê°€ ì‹œì‘...")
        
        # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ (ìƒˆë¡œìš´ ëŒ€í™” ë°ì´í„° ì‚¬ìš©)
        langgraph_analysis = None
        if self.llm and self.workflow:
            try:
                # ìƒˆë¡œìš´ conversation_entriesë¥¼ conversation_log í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                conversation_log = []
                for entry in session.get("conversation_entries", []):
                    conversation_log.append({
                        "role": entry["speaker_role"],
                        "content": entry["text"],
                        "timestamp": entry["timestamp"],
                        "emotion": entry.get("emotion")
                    })
                
                if conversation_log:  # ëŒ€í™” ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ í‰ê°€
                    langgraph_analysis = await self.evaluate_conversation_with_langgraph(
                        session["user_id"], 
                        session["scenario_id"], 
                        conversation_log
                    )
                    print(f"âœ… [{session_id}] LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì™„ë£Œ")
                else:
                    print(f"âš ï¸ [{session_id}] ëŒ€í™” ë°ì´í„°ê°€ ì—†ì–´ LangGraph í‰ê°€ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤")
                
            except Exception as e:
                print(f"âŒ [{session_id}] LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì‹¤íŒ¨: {e}")
                langgraph_analysis = {"error": str(e)}
        
        # ì¢…í•© ê²°ê³¼ êµ¬ì„±
        evaluation_result = {
            "session_id": session_id,
            "user_id": session["user_id"],
            "scenario_id": session["scenario_id"],
            "start_time": session["start_time"].isoformat(),
            "end_time": session["end_time"].isoformat(),
            "duration_minutes": (session["end_time"] - session["start_time"]).total_seconds() / 60,
            
            # ìƒì„¸ ë¶„ì„ ê²°ê³¼
            "langgraph_text_analysis": langgraph_analysis,  # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ ê²°ê³¼
            
            # ì‹¤ì‹œê°„ ëŒ€í™” ë°ì´í„° (ê°ì • ë¶„ì„ í¬í•¨)
            "conversation_entries": [
                {
                    "timestamp": entry["timestamp"],
                    "text": entry["text"],
                    "speaker_role": entry["speaker_role"],
                    "emotion": entry.get("emotion"),
                    "audio_file": entry["audio_file_path"]
                }
                for entry in session.get("conversation_entries", [])
            ]
        }
        
        print(f"âœ… [{session_id}] ì¢…í•© í‰ê°€ ì™„ë£Œ")
        return evaluation_result

    async def _save_evaluation_result(self, session_id: str, result: Dict):
        """í‰ê°€ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # JSON íŒŒì¼ë¡œ ì €ì¥
            json_path = self.evaluation_dir / f"{session_id}_evaluation.json"
            
            async with aiofiles.open(json_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(result, ensure_ascii=False, indent=2))
            
            print(f"ğŸ’¾ [{session_id}] í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_path}")
            
        except Exception as e:
            print(f"âŒ [{session_id}] í‰ê°€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    async def get_evaluation_result(self, session_id: str) -> Dict:
        """ì €ì¥ëœ í‰ê°€ ê²°ê³¼ ì¡°íšŒ"""
        json_path = self.evaluation_dir / f"{session_id}_evaluation.json"
        
        if not json_path.exists():
            return {"error": "í‰ê°€ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        try:
            async with aiofiles.open(json_path, 'r', encoding='utf-8') as f:
                content = await f.read()
                return json.loads(content)
        except Exception as e:
            return {"error": f"í‰ê°€ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}"}

    # =============================================================================
    # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ ê¸°ëŠ¥ (í†µí•©)
    # =============================================================================
    
    def _initialize_langgraph_components(self):
        """LangGraph ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”"""
        try:
            # OpenAI API ì„¤ì •
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self.llm = ChatOpenAI(
                    openai_api_key=api_key,
                    model_name="gpt-3.5-turbo",
                    temperature=0.3,
                    max_tokens=2000
                )
                
                # ì›Œí¬í”Œë¡œìš° ìƒì„±
                self.workflow = self._create_evaluation_workflow()
                print("âœ… LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ í‰ê°€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ LangGraph ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
            self.workflow = None



    async def evaluate_conversation(self, user_id: str, scenario_id: str, conversation_log: List[Dict]) -> Dict:
        """LangGraph ì›Œí¬í”Œë¡œìš°ë¥¼ ì‚¬ìš©í•œ CPX í‰ê°€ ì‹¤í–‰"""
        # ì´ˆê¸° ìƒíƒœ êµ¬ì„± (Multi-Step ì „ìš©)
        initial_state = CPXEvaluationState(
            user_id=user_id,
            scenario_id=scenario_id,
            conversation_log=conversation_log,
            medical_context_analysis=None,
            question_intent_analysis=None,
            completeness_assessment=None,
            quality_evaluation=None,
            appropriateness_validation=None,
            comprehensive_evaluation=None,
            final_scores=None,
            feedback=None,
            evaluation_metadata=None,
            messages=[]
        )
        
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            print(f"ğŸš€ [{user_id}] CPX í‰ê°€ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
            final_state = self.workflow.invoke(initial_state)
            
            # ê°„ë‹¨í•œ ëŒ€í™” ìš”ì•½ ì •ë³´ ìƒì„±
            student_questions = [msg for msg in conversation_log if msg.get("role") == "student"]
            conversation_summary = {
                "total_questions": len(student_questions),
                "duration_minutes": len(conversation_log) * 0.5
            }
            
            # ìµœì¢… ê²°ê³¼ êµ¬ì„±
            result = {
                "evaluation_metadata": final_state.get("evaluation_metadata", {}),
                "scores": final_state.get("final_scores", {}),
                "feedback": final_state.get("feedback", {}),
                "conversation_summary": conversation_summary,
                "detailed_analysis": {
                    "medical_context": final_state.get("medical_context_analysis", {}),
                    "question_intent": final_state.get("question_intent_analysis", {}),
                    "completeness": final_state.get("completeness_assessment", {}),
                    "quality": final_state.get("quality_evaluation", {}),
                    "appropriateness": final_state.get("appropriateness_validation", {}),
                    "comprehensive": final_state.get("comprehensive_evaluation", {})
                },
                "evaluation_method": "6ë‹¨ê³„ ì˜í•™ì  ë¶„ì„",
                "system_info": {
                    "version": "v2.0",
                    "evaluation_steps": 6
                }
            }
            
            print(f"ğŸ‰ [{user_id}] CPX í‰ê°€ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
            
            return result
            
        except Exception as e:
            print(f"âŒ [{user_id}] í‰ê°€ ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
            return {
                "error": str(e),
                "user_id": user_id,
                "scenario_id": scenario_id,
                "evaluation_date": datetime.now().isoformat()
            }

    # ê¸°ì¡´ í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
    async def evaluate_conversation_with_langgraph(self, user_id: str, scenario_id: str, conversation_log: List[Dict]) -> Dict:
        """LangGraphë¥¼ ì‚¬ìš©í•œ ëŒ€í™” í…ìŠ¤íŠ¸ í‰ê°€ (í˜¸í™˜ì„± ìœ ì§€)"""
        return await self.evaluate_conversation(user_id, scenario_id, conversation_log)

    def _create_evaluation_workflow(self):
        """CPX í‰ê°€ ì›Œí¬í”Œë¡œìš° ìƒì„±"""
        workflow = StateGraph(CPXEvaluationState)

        workflow.add_node("initialize", self._initialize_evaluation)
        workflow.add_node("medical_context", self._analyze_medical_context)
        workflow.add_node("question_intent", self._analyze_question_intent)
        workflow.add_node("completeness", self._assess_medical_completeness)
        workflow.add_node("quality", self._evaluate_question_quality)
        workflow.add_node("appropriateness", self._validate_scenario_appropriateness)
        workflow.add_node("comprehensive_evaluation", self._generate_comprehensive_evaluation)
        workflow.add_node("calculate_scores", self._calculate_final_scores)
        workflow.add_node("generate_feedback", self._generate_feedback)
        workflow.add_node("finalize_results", self._finalize_results)

        workflow.set_entry_point("initialize")
        workflow.add_edge("initialize", "medical_context")
        workflow.add_edge("medical_context", "question_intent")
        workflow.add_edge("question_intent", "completeness")
        workflow.add_edge("completeness", "quality")
        workflow.add_edge("quality", "appropriateness")
        workflow.add_edge("appropriateness", "comprehensive_evaluation")
        workflow.add_edge("comprehensive_evaluation", "calculate_scores")
        workflow.add_edge("calculate_scores", "generate_feedback")
        workflow.add_edge("generate_feedback", "finalize_results")
        workflow.add_edge("finalize_results", END)

        return workflow.compile()

    def _initialize_evaluation(self, state: CPXEvaluationState) -> CPXEvaluationState:
        print(f"ğŸ¯ [{state['user_id']}] CPX í‰ê°€ ì´ˆê¸°í™” - ì‹œë‚˜ë¦¬ì˜¤: {state['scenario_id']}")
        
        metadata = {
            "user_id": state["user_id"],
            "scenario_id": state["scenario_id"],
            "evaluation_date": datetime.now().isoformat(),
            "conversation_duration_minutes": len(state["conversation_log"]) * 0.5,
            "voice_recording_path": "s3ë¡œ ì €ì¥",
            "conversation_transcript": json.dumps(state["conversation_log"], ensure_ascii=False)
        }
        
        return {
            **state,
            "evaluation_metadata": metadata,
            "messages": [HumanMessage(content="CPX í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")]
        }



    def _analyze_medical_context(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """Step 1: ì˜í•™ì  ë§¥ë½ ì´í•´"""
        print(f"ğŸ§  [{state['user_id']}] Step 1: ì˜í•™ì  ë§¥ë½ ë¶„ì„ ì‹œì‘")
        
        scenario_id = state["scenario_id"]
        scenario_info = self.scenario_applicable_elements.get(scenario_id, {})
        scenario_name = scenario_info.get("name", f"ì‹œë‚˜ë¦¬ì˜¤ {scenario_id}")
        
        medical_context_prompt = f"""
ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ì‹œë‚˜ë¦¬ì˜¤ì˜ ì˜í•™ì  ë§¥ë½ì„ ë¶„ì„í•˜ì„¸ìš”.

ã€ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ã€‘: {scenario_name}

ë‹¤ìŒ ê´€ì ì—ì„œ ë¶„ì„í•˜ì„¸ìš”:
1. ì£¼ìš” ê°ë³„ì§„ë‹¨ë“¤ê³¼ ê°ê°ì˜ ìœ„í—˜ë„
2. ë†“ì¹˜ë©´ ì•ˆ ë˜ëŠ” Critical ì •ë³´ë“¤
3. ì‹œê°„ íš¨ìœ¨ì„± ì¸¡ë©´ì—ì„œ ìš°ì„ ìˆœìœ„
4. í™˜ì ì•ˆì „ì„ ìœ„í•´ ë°˜ë“œì‹œ í™•ì¸í•´ì•¼ í•  ìš”ì†Œë“¤

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "primary_differentials": ["ì£¼ìš” ê°ë³„ì§„ë‹¨ ë¦¬ìŠ¤íŠ¸"],
    "critical_elements": ["ë†“ì¹˜ë©´ ìœ„í—˜í•œ í•µì‹¬ ìš”ì†Œë“¤"],
    "time_priority": ["ì‹œê°„ ì œì•½ í•˜ì—ì„œ ìš°ì„ ìˆœìœ„ ìš”ì†Œë“¤"],
    "safety_concerns": ["í™˜ì ì•ˆì „ ê´€ë ¨ í•„ìˆ˜ í™•ì¸ì‚¬í•­"],
    "medical_importance_score": ì˜í•™ì  ì¤‘ìš”ë„(1-10)
}}
"""
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ì˜í•™êµìœ¡ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=medical_context_prompt)
        ]
        
        response = self.llm(messages)
        result_text = response.content.strip()
        
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if not json_match:
            raise ValueError(f"Step 1ì—ì„œ JSON í˜•ì‹ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ì‘ë‹µ: {result_text[:100]}")
        
        medical_context = json.loads(json_match.group())
        
        print(f"âœ… [{state['user_id']}] Step 1: ì˜í•™ì  ë§¥ë½ ë¶„ì„ ì™„ë£Œ")
        
        return {
            **state,
            "medical_context_analysis": medical_context,
            "messages": state["messages"] + [HumanMessage(content="Step 1: ì˜í•™ì  ë§¥ë½ ë¶„ì„ ì™„ë£Œ")]
        }

    def _analyze_question_intent(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """Step 2: ì§ˆë¬¸ ì˜ë„ ë¶„ì„"""
        print(f"ğŸ¯ [{state['user_id']}] Step 2: ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì‹œì‘")
        
        conversation_text = self._build_conversation_text(state["conversation_log"])
        medical_context = state.get("medical_context_analysis", {})
        
        question_intent_prompt = f"""
ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸ë“¤ì˜ ì˜ë„ë¥¼ ë¶„ì„í•˜ì„¸ìš”.

ã€ì˜í•™ì  ë§¥ë½ã€‘: {medical_context}

ã€í•™ìƒ-í™˜ì ëŒ€í™”ã€‘: {conversation_text}

ë‹¤ìŒ ê´€ì ì—ì„œ ì§ˆë¬¸ ì˜ë„ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
1. ì˜í•™ì  ëª©ì ì˜ ëª…í™•ì„± - ê° ì§ˆë¬¸ì´ ëª…í™•í•œ ì˜í•™ì  ëª©ì ì„ ê°€ì§€ê³  ìˆëŠ”ê°€?
2. ì²´ê³„ì  ì ‘ê·¼ì„± - ë…¼ë¦¬ì ì´ê³  ì²´ê³„ì ì¸ ìˆœì„œë¡œ ì§ˆë¬¸í–ˆëŠ”ê°€?
3. í™˜ì ì¤‘ì‹¬ì„± - í™˜ìê°€ ì´í•´í•˜ê¸° ì‰½ê³  í¸ì•ˆí•˜ê²Œ ë‹µí•  ìˆ˜ ìˆë„ë¡ ì§ˆë¬¸í–ˆëŠ”ê°€?
4. ì‹œê°„ íš¨ìœ¨ì„± - ì œí•œëœ ì‹œê°„ ë‚´ì—ì„œ íš¨ìœ¨ì ìœ¼ë¡œ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ë ¤ í–ˆëŠ”ê°€?

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "medical_purpose_clarity": ì˜í•™ì  ëª©ì  ëª…í™•ì„± ì ìˆ˜(1-10),
    "systematic_approach": ì²´ê³„ì  ì ‘ê·¼ì„± ì ìˆ˜(1-10),
    "patient_centeredness": í™˜ì ì¤‘ì‹¬ì„± ì ìˆ˜(1-10),
    "time_efficiency": ì‹œê°„ íš¨ìœ¨ì„± ì ìˆ˜(1-10),
    "overall_intent_score": ì „ì²´ ì˜ë„ ì ìˆ˜(1-10),
    "intent_analysis": "ì§ˆë¬¸ ì˜ë„ì— ëŒ€í•œ êµ¬ì²´ì  ë¶„ì„"
}}
"""
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=question_intent_prompt)
        ]
        
        response = self.llm(messages)
        result_text = response.content.strip()
        
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if not json_match:
            raise ValueError(f"Step 2ì—ì„œ JSON í˜•ì‹ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ì‘ë‹µ: {result_text[:100]}")
        
        question_intent = json.loads(json_match.group())
        
        print(f"âœ… [{state['user_id']}] Step 2: ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì™„ë£Œ")
        
        return {
            **state,
            "question_intent_analysis": question_intent,
            "messages": state["messages"] + [HumanMessage(content="Step 2: ì§ˆë¬¸ ì˜ë„ ë¶„ì„ ì™„ë£Œ")]
        }

    def _build_conversation_text(self, conversation_log: List[Dict]) -> str:
        """ëŒ€í™” ë¡œê·¸ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
        conversation_parts = []
        for msg in conversation_log:
            speaker = "í•™ìƒ" if msg.get("role") == "student" else "í™˜ì"
            content = msg.get("content", "")
            conversation_parts.append(f"{speaker}: {content}")
        return "\n".join(conversation_parts)

    def _assess_medical_completeness(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """Step 3: ì˜í•™ì  ì™„ì„±ë„ í‰ê°€ - ì‹œë‚˜ë¦¬ì˜¤ ì¹´í…Œê³ ë¦¬ ê¸°ë°˜ í‰ê°€"""
        print(f"ğŸ“‹ [{state['user_id']}] Step 3: ì˜í•™ì  ì™„ì„±ë„ í‰ê°€ ì‹œì‘")
        
        conversation_text = self._build_conversation_text(state["conversation_log"])
        scenario_id = state["scenario_id"]
        
        # ì‹œë‚˜ë¦¬ì˜¤ì—ì„œ ì¹´í…Œê³ ë¦¬ ì •ë³´ ë¡œë“œ
        scenario_category = self._get_scenario_category(scenario_id)
        if not scenario_category:
            print(f"âš ï¸ ì‹œë‚˜ë¦¬ì˜¤ {scenario_id}ì˜ ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return self._create_default_completeness_result(state)
        
        # í•´ë‹¹ ì¹´í…Œê³ ë¦¬ì˜ í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        checklist = self.get_evaluation_checklist(scenario_category)
        if not checklist:
            print(f"âš ï¸ '{scenario_category}' ì¹´í…Œê³ ë¦¬ì˜ í‰ê°€ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return self._create_default_completeness_result(state)
        
        print(f"âœ… ì¹´í…Œê³ ë¦¬ '{scenario_category}' ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‚¬ìš©")
        
        # í‰ê°€ ì˜ì—­ë³„ë¡œ í‰ê°€ ìˆ˜í–‰
        applicable_categories = self._extract_applicable_categories(checklist)
        
        # ê° ì¹´í…Œê³ ë¦¬ë³„ë¡œ ê°œë³„ í‰ê°€ ìˆ˜í–‰
        category_results = {}
        critical_gaps = []
        for category in applicable_categories:
            print(f" ğŸ“ [{category['name']}] ê°œë³„ í‰ê°€ ì¤‘...")
            result = self._evaluate_single_category(
                conversation_text, category, scenario_id
            )
            category_results[category['category_id']] = result
            
            # Critical gap í™•ì¸
            if result.get('completion_level') == 'none':
                critical_gaps.append(category['name'])
        
        # ì „ì²´ ì™„ì„±ë„ ì ìˆ˜ ê³„ì‚°
        if category_results:
            total_score = sum(r.get('completeness_score', 0) for r in category_results.values())
            overall_score = total_score / len(category_results)
        else:
            overall_score = 0
        
        completeness = {
            "category_completeness": category_results,
            "overall_completeness_score": overall_score,
            "critical_gaps": critical_gaps,
            "medical_completeness_analysis": f"ê°œë³„ ì¹´í…Œê³ ë¦¬ í‰ê°€ë¥¼ í†µí•´ {len(category_results)}ê°œ í•­ëª© ì¤‘ {len(critical_gaps)}ê°œ í•­ëª©ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤."
        }
        
        print(f"âœ… [{state['user_id']}] Step 3: ì˜í•™ì  ì™„ì„±ë„ í‰ê°€ ì™„ë£Œ")
        
        return {
            **state,
            "completeness_assessment": completeness,
            "messages": state["messages"] + [HumanMessage(content="Step 3: ì˜í•™ì  ì™„ì„±ë„ í‰ê°€ ì™„ë£Œ")]
        }

    def _evaluate_single_category(self, conversation_text: str, category: Dict, scenario_id: str) -> Dict:
        """ë‹¨ì¼ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì§‘ì¤‘ í‰ê°€"""
        # ì¹´í…Œê³ ë¦¬ë³„ ì¼ë°˜ì  ì˜ˆì‹œ ë° ìœ ì‚¬ í‘œí˜„ ì¶”ê°€
        category_examples = {
            "ì™¸ìƒë ¥": "ë¨¸ë¦¬ ë‹¤ì¹¨, êµí†µì‚¬ê³ , ë‚™ìƒ, ì™¸ìƒ, ë¶€ìƒ, ê³¨ì ˆ ë“± ì™¸ìƒ ê²½í—˜ì— ê´€í•œ ì§ˆë¬¸",
            "ê°€ì¡±ë ¥": "ê°€ì¡± ì¤‘ ì§ˆë³‘ë ¥, ë¶€ëª¨ë‹˜ ë³‘ë ¥, í˜•ì œìë§¤ ì§ˆí™˜, ìœ ì „ì  ì§ˆí™˜ ë“±ì— ê´€í•œ ì§ˆë¬¸",
            "ê³¼ê±°ë ¥": "ê¸°ì¡´ ì§ˆë³‘, ê³¼ê±° ë³‘ì› ì¹˜ë£Œ, ìˆ˜ìˆ  ê²½í—˜, ì…ì›ë ¥ ë“±ì— ê´€í•œ ì§ˆë¬¸",
            "ì•½ë¬¼ë ¥": "í˜„ì¬ ë³µìš© ì•½ë¬¼, ì²˜ë°©ì•½, ì¼ë°˜ì˜ì•½í’ˆ, ì•Œë ˆë¥´ê¸° ë“±ì— ê´€í•œ ì§ˆë¬¸",
            "ì‚¬íšŒë ¥": "í¡ì—°, ìŒì£¼, ì§ì—…, ìƒí™œìŠµê´€, ìš´ë™ ë“±ì— ê´€í•œ ì§ˆë¬¸",
            "O (Onset) - ë°œë³‘ ì‹œê¸°": "ì¦ìƒ ì‹œì‘ ì‹œì , ì–¸ì œë¶€í„°, ì–¼ë§ˆë‚˜ ì˜¤ë˜ ë“± ì‹œê°„ ê´€ë ¨ ì§ˆë¬¸. ìœ ì‚¬í‘œí˜„: 'ì–¸ì œë¶€í„°', 'ì–¼ë§ˆë‚˜ ì˜¤ë˜', 'ì‹œì‘ëœ ì‹œê¸°', 'ì²˜ìŒ ëŠë‚€ ë•Œ'",
            "C (Character) - íŠ¹ì§•": "ì¦ìƒì˜ ì„±ì§ˆ, ì–‘ìƒ, ê°•ë„, ì •ë„ ë“±ì— ê´€í•œ ì§ˆë¬¸. ìœ ì‚¬í‘œí˜„: 'ì–´ë–¤ ì¦ìƒ', 'ì–´ë–»ê²Œ ëŠê»´ì§€ëŠ”ì§€', 'ì¦ìƒì˜ íŠ¹ì§•', 'ì–´ë–¤ ê¸°ì–µë ¥ ë¬¸ì œ'",
            "A (Associated symptom) - ë™ë°˜ ì¦ìƒ": "í•¨ê»˜ ë‚˜íƒ€ë‚˜ëŠ” ì¦ìƒ, ê´€ë ¨ ì¦ìƒ ë“±ì— ê´€í•œ ì§ˆë¬¸. ìœ ì‚¬í‘œí˜„: 'ë‹¤ë¥¸ ì¦ìƒ', 'í•¨ê»˜ ë‚˜íƒ€ë‚˜ëŠ”', 'ë™ë°˜ë˜ëŠ”', 'ì¶”ê°€ ì¦ìƒ'",
            "F (Factor) - ì•…í™”/ì™„í™”ìš”ì¸": "ì¦ìƒì„ ì•…í™”ì‹œí‚¤ëŠ” ìš”ì¸, ì™„í™”ì‹œí‚¤ëŠ” ìš”ì¸ ë“±ì— ê´€í•œ ì§ˆë¬¸. ìœ ì‚¬í‘œí˜„: 'ì•…í™”ë˜ëŠ” ë•Œ', 'ë‚˜ì•„ì§€ëŠ” ë•Œ', 'ìŠ¤íŠ¸ë ˆìŠ¤', 'íœ´ì‹'",
            "ì¸ì§€ ê²€ì‚¬ (ê°„ì´ MMSE)": "MMSE, ì¸ì§€ê²€ì‚¬, ê¸°ì–µë ¥ê²€ì‚¬, ê°„ì´ì •ì‹ ìƒíƒœê²€ì‚¬ ë“±. ìœ ì‚¬í‘œí˜„: 'MMSE', 'mnse', 'ì— ì— ì—ìŠ¤ì´', 'ì¸ì§€ê²€ì‚¬', 'ê¸°ì–µë ¥ í…ŒìŠ¤íŠ¸', 'ê°„ì´ ê²€ì‚¬'",
            "ì‹ ê²½í•™ì  ê²€ì‚¬": "ë‡Œì‹ ê²½ê²€ì‚¬, ì‹ ê²½í•™ì  ê²€ì‚¬, ë°˜ì‚¬ê²€ì‚¬ ë“±. ìœ ì‚¬í‘œí˜„: 'ë‡Œì‹ ê²½', 'ì‹ ê²½ê²€ì‚¬', 'ë°˜ì‚¬', 'ì‹ ê²½í•™ì ', 'ë‡Œ ê²€ì‚¬'",
            "ìš´ë™ ê²€ì‚¬": "ë³´í–‰ê²€ì‚¬, ê±¸ìŒê±¸ì´, ìš´ë™ê¸°ëŠ¥ ë“±. ìœ ì‚¬í‘œí˜„: 'ë³´í–‰', 'ê±¸ì–´ë³´ì„¸ìš”', 'ê±¸ìŒ', 'ìš´ë™', 'ì›€ì§ì„'"
        }
        
        example_text = category_examples.get(category['name'], "")
        
        single_category_prompt = f"""
ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ ë³‘ë ¥ì²­ì·¨ ëŒ€í™”ì—ì„œ "{category['name']}" í•­ëª©ë§Œ ì§‘ì¤‘ì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”.

ã€í‰ê°€ ëŒ€ìƒã€‘: {category['name']}
ã€í•„ìˆ˜ ìš”ì†Œë“¤ã€‘: {category['required_elements']}
ã€ì˜ˆì‹œ ë° ìœ ì‚¬ í‘œí˜„ã€‘: {example_text}

ã€í•™ìƒ-í™˜ì ëŒ€í™”ã€‘: {conversation_text}

âš ï¸ **í‰ê°€ ì›ì¹™**:
- **ê´€ëŒ€í•œ í‰ê°€**: ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ì§ˆë¬¸ì´ë©´ ì ìˆ˜ ë¶€ì—¬
- **STT ì˜¤ë¥˜ ê³ ë ¤**: ë°œìŒ ì°¨ì´ë‚˜ ì¸ì‹ ì˜¤ë¥˜ ê°ì•ˆ (ì˜ˆ: MMSE â†’ mnse, ì— ì— ì—ìŠ¤ì´)
- **ì˜ë„ ì¤‘ì‹¬**: ì •í™•í•œ ìš©ì–´ë³´ë‹¤ëŠ” ì§ˆë¬¸/ê²€ì‚¬ ì˜ë„ê°€ ìˆëŠ”ì§€ íŒë‹¨
- **êµ¬ìˆ  ê²€ì‚¬**: ì‹¤ì œ ê²€ì‚¬ ìˆ˜í–‰ì´ ì•„ë‹Œ êµ¬ìˆ ë¡œ ê²€ì‚¬ ì–¸ê¸‰ë§Œ í•´ë„ ì¸ì •

ì´ ëŒ€í™”ì—ì„œ "{category['name']}" ê´€ë ¨ ë‚´ìš©ì´ ì–´ëŠ ì •ë„ ë‹¤ë¤„ì¡ŒëŠ”ì§€ë§Œ í‰ê°€í•˜ì„¸ìš”:
1. ì§ì ‘ì  ì™„ë£Œ: ëª…ì‹œì ìœ¼ë¡œ ì§ˆë¬¸í•˜ê±°ë‚˜ ê²€ì‚¬ ì–¸ê¸‰í•¨
2. ê°„ì ‘ì  ì™„ë£Œ: ëŒ€í™” ë§¥ë½ì—ì„œ ì •ë³´ê°€ íŒŒì•…ë¨
3. ë¶€ë¶„ì  ì™„ë£Œ: ë¶ˆì™„ì „í•˜ì§€ë§Œ ì‹œë„í•¨
4. ë¯¸ì™„ë£Œ: ì „í˜€ ë‹¤ë¤„ì§€ì§€ ì•ŠìŒ

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "completion_level": "direct/indirect/partial/none",
    "medical_risk_level": "high/medium/low", 
    "completeness_score": ì ìˆ˜(1-10),
    "evidence": "íŒë‹¨ ê·¼ê±°ê°€ ë˜ëŠ” ëŒ€í™” ë‚´ìš©"
}}
"""
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=single_category_prompt)
        ]
        
        response = self.llm(messages)
        result_text = response.content.strip()
        
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if not json_match:
            # í‰ê°€ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
            return {
                "completion_level": "none",
                "medical_risk_level": "medium",
                "completeness_score": 0,
                "evidence": f"JSON íŒŒì‹± ì‹¤íŒ¨: {result_text[:100]}"
            }
        
        try:
            result = json.loads(json_match.group())
            return result
        except json.JSONDecodeError:
            return {
                "completion_level": "none",
                "medical_risk_level": "medium",
                "completeness_score": 0,
                "evidence": f"JSON ë””ì½”ë”© ì‹¤íŒ¨: {result_text[:100]}"
            }

    def _evaluate_question_quality(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """Step 4: ì§ˆì  ìˆ˜ì¤€ í‰ê°€"""
        print(f"â­ [{state['user_id']}] Step 4: ì§ˆì  ìˆ˜ì¤€ í‰ê°€ ì‹œì‘")
        
        conversation_text = self._build_conversation_text(state["conversation_log"])
        
        quality_prompt = f"""
ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒ ì§ˆë¬¸ë“¤ì˜ ì§ˆì  ìˆ˜ì¤€ì„ í‰ê°€í•˜ì„¸ìš”.

ã€í•™ìƒ-í™˜ì ëŒ€í™”ã€‘: {conversation_text}

ë‹¤ìŒ 4ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ ì§ˆë¬¸ í’ˆì§ˆì„ í‰ê°€í•˜ì„¸ìš”:
1. ì˜í•™ì  ì •í™•ì„± (1-10ì )
2. ì†Œí†µ íš¨ìœ¨ì„± (1-10ì )  
3. ì„ìƒì  ì‹¤ìš©ì„± (1-10ì )
4. í™˜ì ë°°ë ¤ (1-10ì )

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "medical_accuracy": ì˜í•™ì  ì •í™•ì„± ì ìˆ˜(1-10),
    "communication_efficiency": ì†Œí†µ íš¨ìœ¨ì„± ì ìˆ˜(1-10),
    "clinical_practicality": ì„ìƒì  ì‹¤ìš©ì„± ì ìˆ˜(1-10),
    "patient_care": í™˜ì ë°°ë ¤ ì ìˆ˜(1-10),
    "overall_quality_score": ì „ì²´ í’ˆì§ˆ ì ìˆ˜(1-10),
    "quality_analysis": "ì§ˆì  ìˆ˜ì¤€ì— ëŒ€í•œ êµ¬ì²´ì  ë¶„ì„"
}}
"""
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=quality_prompt)
        ]
        
        response = self.llm(messages)
        result_text = response.content.strip()
        
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if not json_match:
            raise ValueError(f"Step 4ì—ì„œ JSON í˜•ì‹ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ì‘ë‹µ: {result_text[:100]}")
        
        quality = json.loads(json_match.group())
        
        print(f"âœ… [{state['user_id']}] Step 4: ì§ˆì  ìˆ˜ì¤€ í‰ê°€ ì™„ë£Œ")
        
        return {
            **state,
            "quality_evaluation": quality,
            "messages": state["messages"] + [HumanMessage(content="Step 4: ì§ˆì  ìˆ˜ì¤€ í‰ê°€ ì™„ë£Œ")]
        }

    def _validate_scenario_appropriateness(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """Step 5: ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„± ê²€ì¦"""
        print(f"ğŸ­ [{state['user_id']}] Step 5: ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„± ê²€ì¦ ì‹œì‘")
        
        conversation_text = self._build_conversation_text(state["conversation_log"])
        scenario_id = state["scenario_id"]
        scenario_info = self.scenario_applicable_elements.get(scenario_id, {})
        scenario_name = scenario_info.get("name", f"ì‹œë‚˜ë¦¬ì˜¤ {scenario_id}")
        
        appropriateness_prompt = f"""
ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í•™ìƒì˜ ì§ˆë¬¸ë“¤ì´ í•´ë‹¹ ì‹œë‚˜ë¦¬ì˜¤ì— ì í•©í–ˆëŠ”ì§€ ê²€ì¦í•˜ì„¸ìš”.

ã€ì‹œë‚˜ë¦¬ì˜¤ ì •ë³´ã€‘: {scenario_name}
ã€í•™ìƒ-í™˜ì ëŒ€í™”ã€‘: {conversation_text}

ë‹¤ìŒ ê´€ì ì—ì„œ ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„±ì„ ê²€ì¦í•˜ì„¸ìš”:
1. ë¶€ì ì ˆí•œ ì§ˆë¬¸ ì²´í¬
2. ì ì ˆì„± í‰ê°€

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "inappropriate_questions": ["ë¶€ì ì ˆí•œ ì§ˆë¬¸ë“¤ê³¼ ì´ìœ "],
    "scenario_specific_score": ì‹œë‚˜ë¦¬ì˜¤ íŠ¹í™” ì ìˆ˜(1-10),
    "patient_profile_score": í™˜ì í”„ë¡œí•„ ì í•©ì„± ì ìˆ˜(1-10),
    "time_allocation_score": ì‹œê°„ ë°°ë¶„ ì ì ˆì„± ì ìˆ˜(1-10),
    "overall_appropriateness_score": ì „ì²´ ì í•©ì„± ì ìˆ˜(1-10),
    "appropriateness_analysis": "ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„±ì— ëŒ€í•œ êµ¬ì²´ì  ë¶„ì„"
}}
"""
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=appropriateness_prompt)
        ]
        
        response = self.llm(messages)
        result_text = response.content.strip()
        
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if not json_match:
            raise ValueError(f"Step 5ì—ì„œ JSON í˜•ì‹ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ì‘ë‹µ: {result_text[:100]}")
        
        appropriateness = json.loads(json_match.group())
        
        print(f"âœ… [{state['user_id']}] Step 5: ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„± ê²€ì¦ ì™„ë£Œ")
        
        return {
            **state,
            "appropriateness_validation": appropriateness,
            "messages": state["messages"] + [HumanMessage(content="Step 5: ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„± ê²€ì¦ ì™„ë£Œ")]
        }

    def _generate_comprehensive_evaluation(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """Step 6: ì¢…í•© í‰ê°€ ë° ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        print(f"ğŸ¯ [{state['user_id']}] Step 6: ì¢…í•© í‰ê°€ ì‹œì‘")
        
        # Multi-Step ê²°ê³¼ë“¤ ìˆ˜ì§‘
        medical_context = state.get("medical_context_analysis", {})
        question_intent = state.get("question_intent_analysis", {})
        completeness = state.get("completeness_assessment", {})
        quality = state.get("quality_evaluation", {})
        appropriateness = state.get("appropriateness_validation", {})
        
        comprehensive_prompt = f"""
ë‹¹ì‹ ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë‹¤ìŒ Multi-Step ë¶„ì„ ê²°ê³¼ë“¤ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… í‰ê°€ë¥¼ ìˆ˜í–‰í•˜ì„¸ìš”.

ã€Step 1 - ì˜í•™ì  ë§¥ë½ã€‘: {medical_context}
ã€Step 2 - ì§ˆë¬¸ ì˜ë„ã€‘: {question_intent}
ã€Step 3 - ì˜í•™ì  ì™„ì„±ë„ã€‘: {completeness}
ã€Step 4 - ì§ˆì  ìˆ˜ì¤€ã€‘: {quality}
ã€Step 5 - ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„±ã€‘: {appropriateness}

ì¢…í•© í‰ê°€ ê¸°ì¤€:
1. ê¸°ë³¸ ì™„ë£Œìœ¨: Step 3ì˜ ì™„ì„±ë„ ê¸°ë°˜ (40% ê°€ì¤‘ì¹˜)
2. í’ˆì§ˆ ê°€ì¤‘ì¹˜: Step 4ì˜ ì§ˆì  ìˆ˜ì¤€ ë°˜ì˜ (30% ê°€ì¤‘ì¹˜)
3. ì í•©ì„± ë³´ì •: Step 5ì˜ ì‹œë‚˜ë¦¬ì˜¤ ì í•©ì„± (20% ê°€ì¤‘ì¹˜)
4. ì˜ë„ ì ìˆ˜: Step 2ì˜ ì§ˆë¬¸ ì˜ë„ (10% ê°€ì¤‘ì¹˜)

ë°˜ë“œì‹œ ì•„ë˜ì˜ ì •í™•í•œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
    "final_completion_rate": 0.8,
    "final_quality_score": 7.5,
    "weighted_scores": {{
        "completeness_weighted": 32.0,
        "quality_weighted": 22.5,
        "appropriateness_weighted": 16.0,
        "intent_weighted": 8.5
    }},
    "detailed_feedback": {{
        "strengths": ["êµ¬ì²´ì ì¸ ê°•ì  1", "êµ¬ì²´ì ì¸ ê°•ì  2"],
        "weaknesses": ["êµ¬ì²´ì ì¸ ì•½ì  1", "êµ¬ì²´ì ì¸ ì•½ì  2"],
        "medical_insights": ["ì˜í•™ì  í†µì°° 1", "ì˜í•™ì  í†µì°° 2"]
    }},
    "comprehensive_analysis": "ì¢…í•© ë¶„ì„ ë‚´ìš©ì„ ì—¬ê¸°ì— ì‘ì„±"
}}
"""
        
        messages = [
            SystemMessage(content="ë‹¹ì‹ ì€ ê²½í—˜ ë§ì€ ì˜í•™êµìœ¡ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."),
            HumanMessage(content=comprehensive_prompt)
        ]
        
        response = self.llm(messages)
        result_text = response.content.strip()
        
        import re
        json_match = re.search(r'\{.*\}', result_text, re.DOTALL)
        if not json_match:
            raise ValueError(f"Step 6ì—ì„œ JSON í˜•ì‹ ì‘ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLM ì‘ë‹µ: {result_text[:100]}")
        
        try:
            comprehensive = json.loads(json_match.group())
        except json.JSONDecodeError as e:
            raise ValueError(f"Step 6ì—ì„œ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        
        print(f"âœ… [{state['user_id']}] Step 6: ì¢…í•© í‰ê°€ ì™„ë£Œ")
        
        return {
            **state,
            "comprehensive_evaluation": comprehensive,
            "messages": state["messages"] + [HumanMessage(content="Step 6: ì¢…í•© í‰ê°€ ì™„ë£Œ")]
        }

    def _calculate_final_scores(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        print(f"ğŸ§® [{state['user_id']}] ìµœì¢… ì ìˆ˜ ê³„ì‚° ì‹œì‘")
        
        evaluation_result = state["comprehensive_evaluation"]
        completion_rate = evaluation_result["final_completion_rate"]
        quality_score = evaluation_result["final_quality_score"]
        weighted_scores = evaluation_result["weighted_scores"]
        
        final_total_score = (completion_rate * 70) + (quality_score * 3)
        final_total_score = min(100, max(0, final_total_score))
        
        scores = {
            "total_score": round(final_total_score, 1),
            "completion_rate": round(completion_rate, 2),
            "quality_score": round(quality_score, 1),
            "weighted_breakdown": {
                "completeness_score": round(weighted_scores["completeness_weighted"], 1),
                "quality_score": round(weighted_scores["quality_weighted"], 1),
                "appropriateness_score": round(weighted_scores["appropriateness_weighted"], 1),
                "intent_score": round(weighted_scores["intent_weighted"], 1)
            },
            "grade": self._calculate_grade(final_total_score)
        }
        
        print(f"âœ… [{state['user_id']}] ìµœì¢… ì ìˆ˜ ê³„ì‚° ì™„ë£Œ - ì´ì : {final_total_score:.1f}")
        
        return {
            **state,
            "final_scores": scores,
            "messages": state["messages"] + [HumanMessage(content=f"ìµœì¢… ì ìˆ˜ ê³„ì‚° ì™„ë£Œ - ì´ì : {final_total_score:.1f}ì ")]
        }

    def _generate_feedback(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """í”¼ë“œë°± ìƒì„±"""
        print(f"ğŸ“ [{state['user_id']}] í”¼ë“œë°± ìƒì„± ì‹œì‘")
        
        evaluation_result = state["comprehensive_evaluation"]
        final_scores = state["final_scores"]
        evaluation_feedback = evaluation_result["detailed_feedback"]
        
        feedback = {
            "overall_feedback": f"6ë‹¨ê³„ ì˜í•™ì  ë¶„ì„ì„ í†µí•œ ì¢…í•© í‰ê°€ì…ë‹ˆë‹¤. ì´ì : {final_scores['total_score']}ì ",
            "strengths": evaluation_feedback["strengths"],
            "weaknesses": evaluation_feedback["weaknesses"],
            "medical_insights": evaluation_feedback["medical_insights"],
            "comprehensive_analysis": evaluation_result["comprehensive_analysis"],
            "evaluation_method": "6ë‹¨ê³„ ì˜í•™ì  ë¶„ì„"
        }
        
        print(f"âœ… [{state['user_id']}] í”¼ë“œë°± ìƒì„± ì™„ë£Œ")
        
        return {
            **state,
            "feedback": feedback,
            "messages": state["messages"] + [HumanMessage(content="í”¼ë“œë°± ìƒì„± ì™„ë£Œ")]
        }

    def _finalize_results(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """ê²°ê³¼ ìµœì¢…í™”"""
        print(f"ğŸ¯ [{state['user_id']}] í‰ê°€ ê²°ê³¼ ìµœì¢…í™”")
        
        total_score = state.get('final_scores', {}).get('total_score', 0)
        print(f"ğŸ‰ [{state['user_id']}] CPX í‰ê°€ ì™„ë£Œ - ì´ì : {total_score}ì ")
        
        return {
            **state,
            "messages": state["messages"] + [HumanMessage(content="CPX í‰ê°€ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")]
        }

    def _calculate_grade(self, score: float) -> str:
        """ì ìˆ˜ì— ë”°ë¥¸ ë“±ê¸‰ ê³„ì‚°"""
        if score >= 90:
            return "A+"
        elif score >= 85:
            return "A"
        elif score >= 80:
            return "B+"
        elif score >= 75:
            return "B"
        elif score >= 70:
            return "C+"
        elif score >= 65:
            return "C"
        else:
            return "F"

    # =============================================================================
    # ìƒˆë¡œìš´ ì‹¤ì‹œê°„ ëŒ€í™” ë°ì´í„° ë¶„ì„ ë©”ì„œë“œë“¤
    # =============================================================================
    
    async def _analyze_conversation_entries(self, session: Dict) -> Dict:
        """ìƒˆë¡œìš´ ì‹¤ì‹œê°„ ëŒ€í™” ë°ì´í„° ë¶„ì„"""
        conversation_entries = session.get("conversation_entries", [])
        
        if not conversation_entries:
            return {"error": "ë¶„ì„í•  ëŒ€í™” ì—”íŠ¸ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        # ì—­í• ë³„ ë¶„ë¦¬
        doctor_entries = [entry for entry in conversation_entries if entry["speaker_role"] == "doctor"]
        patient_entries = [entry for entry in conversation_entries if entry["speaker_role"] == "patient"]
        
        # ê°ì • ë¶„ì„ í†µê³„ (ì˜ì‚¬ ë°œì–¸ë§Œ)
        emotion_stats = {}
        if doctor_entries:
            emotions = [entry.get("emotion", {}).get("predicted_emotion") for entry in doctor_entries if entry.get("emotion")]
            emotions = [e for e in emotions if e]  # None ì œê±°
            
            if emotions:
                from collections import Counter
                emotion_counts = Counter(emotions)
                total_emotional_entries = len(emotions)
                
                emotion_stats = {
                    "dominant_emotion": emotion_counts.most_common(1)[0][0] if emotion_counts else None,
                    "emotion_distribution": {
                        emotion: count / total_emotional_entries 
                        for emotion, count in emotion_counts.items()
                    },
                    "total_emotional_entries": total_emotional_entries,
                    "emotional_consistency": max(emotion_counts.values()) / total_emotional_entries if total_emotional_entries > 0 else 0
                }
        
        # ëŒ€í™” íŒ¨í„´ ë¶„ì„
        conversation_pattern = {
            "total_entries": len(conversation_entries),
            "doctor_utterances": len(doctor_entries),
            "patient_utterances": len(patient_entries),
            "conversation_balance": len(patient_entries) / len(doctor_entries) if len(doctor_entries) > 0 else 0,
            "avg_doctor_utterance_length": sum(len(entry["text"]) for entry in doctor_entries) / len(doctor_entries) if doctor_entries else 0,
            "avg_patient_utterance_length": sum(len(entry["text"]) for entry in patient_entries) / len(patient_entries) if patient_entries else 0
        }
        
        # ì‹œê°„ ë¶„ì„
        if len(conversation_entries) >= 2:
            first_time = datetime.fromisoformat(conversation_entries[0]["timestamp"])
            last_time = datetime.fromisoformat(conversation_entries[-1]["timestamp"])
            duration_seconds = (last_time - first_time).total_seconds()
            
            time_analysis = {
                "conversation_duration_seconds": duration_seconds,
                "conversation_duration_minutes": duration_seconds / 60,
                "entries_per_minute": len(conversation_entries) / (duration_seconds / 60) if duration_seconds > 0 else 0
            }
        else:
            time_analysis = {
                "conversation_duration_seconds": 0,
                "conversation_duration_minutes": 0,
                "entries_per_minute": 0
            }
        
        return {
            "emotion_analysis": emotion_stats,
            "conversation_pattern": conversation_pattern,
            "time_analysis": time_analysis,
            "quality_indicators": {
                "has_emotional_data": len([e for e in doctor_entries if e.get("emotion")]) > 0,
                "conversation_completeness": len(conversation_entries) >= 10,  # ìµœì†Œ 10ê°œ ë°œì–¸
                "balanced_interaction": 0.3 <= conversation_pattern["conversation_balance"] <= 3.0
            }
        }

    async def _cleanup_audio_files(self, audio_file_path: str):
        """í‰ê°€ ì™„ë£Œ í›„ ì„ì‹œ WAV íŒŒì¼ë“¤ë§Œ ì‚­ì œ (TTS ìºì‹œ íŒŒì¼ì€ ë³´ì¡´)"""

        try:
            file_path_obj = Path(audio_file_path)
            # TTS ìºì‹œ íŒŒì¼ì€ ì‚­ì œí•˜ì§€ ì•ŠìŒ
            if "cache/tts" in str(file_path_obj):
                print(f"ğŸ”’ TTS ìºì‹œ íŒŒì¼ ë³´ì¡´: {audio_file_path}")
                return
                
            if file_path_obj.exists() and file_path_obj.suffix == '.wav':
                file_path_obj.unlink()  # WAV íŒŒì¼ë§Œ ì‚­ì œ
                print(f"ğŸ—‘ï¸ ì„ì‹œ WAV íŒŒì¼ ì‚­ì œ: {audio_file_path}")
                    
        except Exception as e:
            print(f"âŒ WAV íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨ ({audio_file_path}): {e}")