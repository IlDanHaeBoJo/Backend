from typing import Dict, List, Optional, TypedDict, Annotated
from datetime import datetime
from pathlib import Path
import json
import asyncio
import aiofiles
import torch
import numpy as np
import librosa
import logging
import os

# LangGraph ê´€ë ¨ import
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage, BaseMessage as AnyMessage
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# CPX í‰ê°€ ìƒíƒœ ì •ì˜ (LangGraphìš©)
class CPXEvaluationState(TypedDict):
    """CPX í‰ê°€ ìƒíƒœ ì •ì˜"""
    # ì…ë ¥ ë°ì´í„°
    user_id: str
    scenario_id: str
    conversation_log: List[Dict]
    
    # ë¶„ì„ ê²°ê³¼ë“¤
    conversation_analysis: Optional[Dict]
    checklist_results: Optional[Dict]
    question_analysis: Optional[Dict]
    empathy_analysis: Optional[Dict]
    
    # ì œì–´ í”Œë˜ê·¸ë“¤
    confidence_score: float
    retry_count: int
    needs_enhancement: bool
    
    # ìµœì¢… ê²°ê³¼
    final_scores: Optional[Dict]
    feedback: Optional[Dict]
    
    # ë©”íƒ€ë°ì´í„°
    evaluation_metadata: Optional[Dict]
    
    # ë©”ì‹œì§€ ì¶”ì 
    messages: Annotated[List[AnyMessage], add_messages]

class EvaluationService:
    def __init__(self):
        """CPX í‰ê°€ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.evaluation_criteria = {
            "communication": {"name": "ì˜ì‚¬ì†Œí†µ ëŠ¥ë ¥", "weight": 0.3},
            "history_taking": {"name": "ë³‘ë ¥ ì²­ì·¨", "weight": 0.4},
            "clinical_reasoning": {"name": "ì„ìƒì  ì¶”ë¡ ", "weight": 0.2},
            "professionalism": {"name": "ì „ë¬¸ê°€ íƒœë„", "weight": 0.1}
        }
        
        self.session_data = {}  # ì„¸ì…˜ë³„ í‰ê°€ ë°ì´í„°
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥ ë””ë ‰í„°ë¦¬
        self.evaluation_dir = Path("evaluation_results")
        self.evaluation_dir.mkdir(parents=True, exist_ok=True)
        
        # ê°ì • ë¶„ì„ ëª¨ë¸ ê´€ë ¨ (SER)
        self.emotion_model = None
        self.emotion_processor = None
        self.emotion_labels = ["Anxious", "Dry", "Kind"]
        self.ser_model_path = Path("Backend/SER/results_quick_test/adversary_model_augment_v1_epoch_5")  # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        
        # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ ê´€ë ¨
        self.llm = None
        self.langgraph_workflow = None
        self._initialize_langgraph_components()

    async def start_evaluation_session(self, user_id: str, scenario_id: str) -> str:
        """í‰ê°€ ì„¸ì…˜ ì‹œì‘"""
        session_id = f"{user_id}_{scenario_id}_{int(datetime.now().timestamp())}"
        
        self.session_data[session_id] = {
            "user_id": user_id,
            "scenario_id": scenario_id,
            "start_time": datetime.now(),
            "interactions": [],
            "status": "active"
        }
        
        return session_id

    async def load_emotion_model(self):
        """ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ (ì„œë¹„ìŠ¤ ì‹œì‘ ì‹œ í•œ ë²ˆë§Œ)"""
        if self.emotion_model is not None:
            return 
        
        try:
            print("ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì¤‘...")
            
            # ëª¨ë¸ ê²½ë¡œ í™•ì¸
            if self.ser_model_path.exists():
                from transformers import Wav2Vec2Processor
                from SER.finetune_direct import custom_Wav2Vec2ForEmotionClassification
                
                self.emotion_model = custom_Wav2Vec2ForEmotionClassification.from_pretrained(
                    str(self.ser_model_path)
                )
                self.emotion_processor = Wav2Vec2Processor.from_pretrained(
                    str(self.ser_model_path)
                )
                
                # ëª¨ë¸ì„ í‰ê°€ ëª¨ë“œë¡œ ì„¤ì •
                self.emotion_model.eval()
                
                print("âœ… ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print(f"âš ï¸ ê°ì • ë¶„ì„ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ: {self.ser_model_path}")
                print("   ê¸°ë³¸ ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤...")
                
                from transformers import Wav2Vec2ForSequenceClassification, Wav2Vec2Processor, Wav2Vec2Config
                
                model_name = "kresnik/wav2vec2-large-xlsr-korean"
                label2id = {label: i for i, label in enumerate(self.emotion_labels)}
                id2label = {i: label for i, label in enumerate(self.emotion_labels)}
                
                config = Wav2Vec2Config.from_pretrained(
                    model_name,
                    num_labels=len(self.emotion_labels),
                    label2id=label2id,
                    id2label=id2label,
                    finetuning_task="emotion_classification"
                )
                
                self.emotion_model = Wav2Vec2ForSequenceClassification.from_pretrained(
                    model_name,
                    config=config,
                    ignore_mismatched_sizes=True
                )
                self.emotion_processor = Wav2Vec2Processor.from_pretrained(model_name)
                self.emotion_model.eval()
                
                print("âœ… ê¸°ë³¸ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                
        except Exception as e:
            print(f"âŒ ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.emotion_model = None
            self.emotion_processor = None

    async def analyze_single_audio(self, audio_file_path: str) -> Dict:
        """ë‹¨ì¼ ìŒì„± íŒŒì¼ ê°ì • ë¶„ì„"""
        if self.emotion_model is None or self.emotion_processor is None:
            await self.load_emotion_model()
            
        if self.emotion_model is None:
            return {"error": "ê°ì • ë¶„ì„ ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
            audio_path = Path(audio_file_path)
            if not audio_path.exists():
                return {"error": f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}"}
            
            # ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
            audio_data = await self._preprocess_audio(str(audio_path))
            if audio_data is None:
                return {"error": "ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì‹¤íŒ¨"}
            
            # ê°ì • ë¶„ì„ ìˆ˜í–‰
            with torch.no_grad():
                inputs = {
                    "input_values": audio_data.unsqueeze(0),  # ë°°ì¹˜ ì°¨ì› ì¶”ê°€
                    "attention_mask": None
                }
                
                outputs = self.emotion_model(**inputs)
                logits = outputs.logits
                
                # ì˜ˆì¸¡ ê²°ê³¼ ê³„ì‚°
                probabilities = torch.nn.functional.softmax(logits, dim=-1)
                predicted_id = torch.argmax(logits, dim=-1).item()
                confidence = probabilities[0][predicted_id].item()
                
                predicted_emotion = self.emotion_labels[predicted_id]
                
                # ëª¨ë“  ê°ì •ë³„ í™•ë¥ 
                emotion_scores = {
                    emotion: probabilities[0][i].item() 
                    for i, emotion in enumerate(self.emotion_labels)
                }
                
                return {
                    "predicted_emotion": predicted_emotion,
                    "confidence": confidence,
                    "emotion_scores": emotion_scores,
                    "file_path": str(audio_path)
                }
                
        except Exception as e:
            return {"error": f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}

    async def _preprocess_audio(self, file_path: str) -> Optional[torch.Tensor]:
        """ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (Wav2Vec2ìš©)"""
        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ (16kHzë¡œ ë¦¬ìƒ˜í”Œë§)
            audio, sr = librosa.load(file_path, sr=16000, res_type='kaiser_fast')
            
            # ê¸¸ì´ ì œí•œ (ìµœëŒ€ 10ì´ˆ)
            max_duration = 10.0
            target_length = int(16000 * max_duration)
            
            if len(audio) > target_length:
                # ê°€ìš´ë° ë¶€ë¶„ ì‚¬ìš©
                start_idx = (len(audio) - target_length) // 2
                audio = audio[start_idx:start_idx + target_length]
            elif len(audio) < target_length:
                # íŒ¨ë”© ì¶”ê°€
                pad_length = target_length - len(audio)
                audio = np.pad(audio, (0, pad_length), mode='constant', constant_values=0)
            
            # ì •ê·œí™”
            if np.max(np.abs(audio)) > 0:
                audio = audio / np.max(np.abs(audio)) * 0.8
            
            # Wav2Vec2 processorë¡œ ë³€í™˜
            inputs = self.emotion_processor(
                audio,
                sampling_rate=16000,
                return_tensors="pt",
                padding=True
            )
            
            return inputs.input_values.squeeze(0)
            
        except Exception as e:
            print(f"âŒ ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None

    async def record_interaction(self, session_id: str, student_question: str, patient_response: str, 
                               audio_file_path: str = None, interaction_type: str = "question"):
        """í•™ìƒ-í™˜ì ìƒí˜¸ì‘ìš© ê¸°ë¡ (ìŒì„± íŒŒì¼ ê²½ë¡œ í¬í•¨)"""
        if session_id not in self.session_data:
            return
        
        interaction = {
            "timestamp": datetime.now(),
            "type": interaction_type,
            "student_question": student_question,
            "patient_response": patient_response,
            "audio_file_path": audio_file_path,  # WAV íŒŒì¼ ê²½ë¡œ ì¶”ê°€
            "analysis": self._simple_analysis(student_question)
        }
        
        self.session_data[session_id]["interactions"].append(interaction)

    def _simple_analysis(self, question: str) -> Dict:
        """ê°„ë‹¨í•œ ì§ˆë¬¸ ë¶„ì„"""
        score = 5.0  # ê¸°ë³¸ ì ìˆ˜
        
        # ê¸ì •ì  ìš”ì†Œ
        if "ì•ˆë…•í•˜ì„¸ìš”" in question or "ê°ì‚¬" in question:
            score += 1.0
        if any(word in question for word in ["ì–¸ì œ", "ì–´ë–¤", "ì–´ë””", "ì–´ë–»ê²Œ"]):
            score += 1.0
        if "?" in question:
            score += 0.5
            
        return {
            "communication_score": min(10.0, score),
            "question_type": "ê°œë°©í˜•" if any(w in question for w in ["ì–¸ì œ", "ì–´ë–¤", "ì–´ë””"]) else "íì‡„í˜•"
        }

    async def end_evaluation_session(self, session_id: str) -> Dict:
        """í‰ê°€ ì„¸ì…˜ ì¢…ë£Œ ë° ì¢…í•© í‰ê°€ ì‹¤í–‰"""
        if session_id not in self.session_data:
            return {"error": "ì„¸ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        session = self.session_data[session_id]
        session["end_time"] = datetime.now()
        session["status"] = "completed"
        
        # ì¢…í•© í‰ê°€ ì‹¤í–‰
        evaluation_result = await self._comprehensive_evaluation(session_id, session)
        
        # í‰ê°€ ê²°ê³¼ ì €ì¥
        await self._save_evaluation_result(session_id, evaluation_result)
        
        return evaluation_result

    def _calculate_scores(self, session: Dict) -> Dict:
        """ì ìˆ˜ ê³„ì‚°"""
        interactions = session["interactions"]
        
        if not interactions:
            return {category: 5.0 for category in self.evaluation_criteria.keys()}
        
        # í‰ê·  ì˜ì‚¬ì†Œí†µ ì ìˆ˜
        avg_comm = sum(i["analysis"]["communication_score"] for i in interactions) / len(interactions)
        
        scores = {
            "communication": round(avg_comm, 1),
            "history_taking": round(min(10.0, len(interactions) * 1.5), 1),  # ì§ˆë¬¸ ê°œìˆ˜ ê¸°ë°˜
            "clinical_reasoning": round(avg_comm * 0.9, 1),  # ì˜ì‚¬ì†Œí†µ ê¸°ë°˜
            "professionalism": round(avg_comm * 1.1, 1)  # ì˜ì‚¬ì†Œí†µ ê¸°ë°˜
        }
        
        # ê°€ì¤‘ í‰ê·  ì´ì 
        total = sum(scores[cat] * self.evaluation_criteria[cat]["weight"] for cat in scores)
        scores["total"] = round(total, 1)
        
        return scores

    def get_session_summary(self, user_id: str) -> list:
        """ì‚¬ìš©ìì˜ ì„¸ì…˜ ìš”ì•½"""
        return [
            {
                "session_id": sid,
                "scenario_id": data["scenario_id"],
                "date": data["start_time"].strftime("%Y-%m-%d %H:%M"),
                "status": data["status"]
            }
            for sid, data in self.session_data.items()
            if data["user_id"] == user_id
        ]

    async def _comprehensive_evaluation(self, session_id: str, session: Dict) -> Dict:
        """ì¢…í•©ì ì¸ ì„¸ì…˜ í‰ê°€ ìˆ˜í–‰ (SER + LangGraph í†µí•©)"""
        print(f"ğŸ” [{session_id}] ì¢…í•© í‰ê°€ ì‹œì‘...")
        
        # ê¸°ë³¸ ì ìˆ˜ ê³„ì‚°
        basic_scores = self._calculate_scores(session)
        
        # ëŒ€í™” í…ìŠ¤íŠ¸ ë¶„ì„ (ê¸°ì¡´ ë°©ì‹)
        conversation_analysis = await self._analyze_conversation_text(session)
        
        # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ (ìƒˆë¡œ ì¶”ê°€)
        langgraph_analysis = None
        if self.llm and self.langgraph_workflow:
            try:
                # ì„¸ì…˜ ë°ì´í„°ë¥¼ conversation_log í˜•ì‹ìœ¼ë¡œ ë³€í™˜
                conversation_log = []
                for interaction in session["interactions"]:
                    conversation_log.append({
                        "role": "assistant",
                        "content": interaction["student_question"],
                        "timestamp": interaction["timestamp"].isoformat()
                    })
                    conversation_log.append({
                        "role": "user",
                        "content": interaction["patient_response"],
                        "timestamp": interaction["timestamp"].isoformat()
                    })
                
                langgraph_analysis = await self.evaluate_conversation_with_langgraph(
                    session["user_id"], 
                    session["scenario_id"], 
                    conversation_log
                )
                print(f"âœ… [{session_id}] LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì™„ë£Œ")
                
            except Exception as e:
                print(f"âŒ [{session_id}] LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì‹¤íŒ¨: {e}")
                langgraph_analysis = {"error": str(e)}
        
        # ìŒì„± íŒŒì¼ ë¶„ì„ (SER - ê°ì • ë¶„ì„)
        audio_analysis = await self._analyze_audio_files(session)
        
        # ì¢…í•© ê²°ê³¼ êµ¬ì„±
        evaluation_result = {
            "session_id": session_id,
            "user_id": session["user_id"],
            "scenario_id": session["scenario_id"],
            "start_time": session["start_time"].isoformat(),
            "end_time": session["end_time"].isoformat(),
            "duration_minutes": (session["end_time"] - session["start_time"]).total_seconds() / 60,
            "total_interactions": len(session["interactions"]),
            
            # ì ìˆ˜ ì •ë³´
            "scores": basic_scores,
            
            # ìƒì„¸ ë¶„ì„ ê²°ê³¼
            "conversation_analysis": conversation_analysis,
            "langgraph_text_analysis": langgraph_analysis,  # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ ê²°ê³¼
            "audio_analysis": audio_analysis,  # SER ê¸°ë°˜ ìŒì„± ê°ì • ë¶„ì„ ê²°ê³¼
            
            # ì¸í„°ë™ì…˜ ìƒì„¸
            "interactions": [
                {
                    "timestamp": interaction["timestamp"].isoformat(),
                    "student_question": interaction["student_question"],
                    "patient_response": interaction["patient_response"],
                    "audio_file": interaction.get("audio_file_path"),
                    "analysis": interaction["analysis"]
                }
                for interaction in session["interactions"]
            ]
        }
        
        print(f"âœ… [{session_id}] ì¢…í•© í‰ê°€ ì™„ë£Œ")
        return evaluation_result

    async def _analyze_conversation_text(self, session: Dict) -> Dict:
        """ëŒ€í™” í…ìŠ¤íŠ¸ ë¶„ì„"""
        interactions = session["interactions"]
        
        if not interactions:
            return {"error": "ë¶„ì„í•  ëŒ€í™”ê°€ ì—†ìŠµë‹ˆë‹¤"}
        
        # ì§ˆë¬¸ ìœ í˜• ë¶„ì„
        question_types = {"ê°œë°©í˜•": 0, "íì‡„í˜•": 0}
        medical_keywords = []
        total_words = 0
        
        for interaction in interactions:
            question = interaction["student_question"]
            analysis = interaction["analysis"]
            
            # ì§ˆë¬¸ ìœ í˜• ì¹´ìš´íŠ¸
            q_type = analysis.get("question_type", "íì‡„í˜•")
            question_types[q_type] += 1
            
            # ì˜ë£Œ í‚¤ì›Œë“œ ì¶”ì¶œ
            medical_terms = ["í†µì¦", "ì–¸ì œ", "ì–´ë””", "ì–´ë–¤", "ì¦ìƒ", "ì•„í”„", "ë¶ˆí¸", "ê¸°ê°„", "ì •ë„"]
            for term in medical_terms:
                if term in question and term not in medical_keywords:
                    medical_keywords.append(term)
            
            total_words += len(question.split())
        
        return {
            "question_distribution": question_types,
            "medical_keywords_used": medical_keywords,
            "avg_question_length": total_words / len(interactions) if interactions else 0,
            "conversation_flow_quality": self._assess_conversation_flow(interactions)
        }

    async def _analyze_audio_files(self, session: Dict) -> Dict:
        """ìŒì„± íŒŒì¼ ê°ì • ë¶„ì„ (Wav2Vec2 ì»¤ìŠ¤í…€ ëª¨ë¸ ì‚¬ìš©)"""
        print("ğŸµ ìŒì„± íŒŒì¼ ê°ì • ë¶„ì„ ì‹œì‘...")
        
        # ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ë‹¤ë©´ ë¡œë“œ
        if self.emotion_model is None:
            await self.load_emotion_model()
        
        audio_files = []
        emotion_analyses = []
        total_duration = 0
        successful_analyses = 0
        
        for i, interaction in enumerate(session["interactions"]):
            audio_path = interaction.get("audio_file_path")
            if audio_path and Path(audio_path).exists():
                audio_files.append(audio_path)
                
                print(f"  ğŸ“‚ ë¶„ì„ ì¤‘ ({i+1}/{len(session['interactions'])}): {Path(audio_path).name}")
                
                # ê°œë³„ íŒŒì¼ ê°ì • ë¶„ì„
                emotion_result = await self.analyze_single_audio(audio_path)
                
                if "error" not in emotion_result:
                    emotion_analyses.append({
                        "interaction_index": i,
                        "file_name": Path(audio_path).name,
                        "predicted_emotion": emotion_result["predicted_emotion"],
                        "confidence": round(emotion_result["confidence"], 3),
                        "emotion_scores": {k: round(v, 3) for k, v in emotion_result["emotion_scores"].items()},
                        "timestamp": interaction["timestamp"].isoformat()
                    })
                    successful_analyses += 1
                else:
                    print(f"    âŒ ë¶„ì„ ì‹¤íŒ¨: {emotion_result['error']}")
                    emotion_analyses.append({
                        "interaction_index": i,
                        "file_name": Path(audio_path).name,
                        "error": emotion_result["error"]
                    })
        
        # ì „ì²´ ê°ì • í†µê³„ ê³„ì‚°
        emotion_summary = self._calculate_emotion_statistics(emotion_analyses)
        
        print(f"âœ… ìŒì„± ê°ì • ë¶„ì„ ì™„ë£Œ: {successful_analyses}/{len(audio_files)}ê°œ ì„±ê³µ")
        
        return {
            "total_audio_files": len(audio_files),
            "successful_analyses": successful_analyses,
            "audio_file_paths": audio_files,
            "emotion_analyses": emotion_analyses,
            "emotion_summary": emotion_summary,
            "model_info": {
                "model_type": "Wav2Vec2-based Emotion Classification",
                "emotion_labels": self.emotion_labels,
                "model_loaded": self.emotion_model is not None
            }
        }

    def _calculate_emotion_statistics(self, emotion_analyses: List[Dict]) -> Dict:
        """ê°ì • ë¶„ì„ ê²°ê³¼ í†µê³„ ê³„ì‚°"""
        if not emotion_analyses:
            return {"error": "ë¶„ì„ëœ ìŒì„±ì´ ì—†ìŠµë‹ˆë‹¤"}
        
        # ì„±ê³µí•œ ë¶„ì„ë§Œ í•„í„°ë§
        valid_analyses = [a for a in emotion_analyses if "error" not in a]
        
        if not valid_analyses:
            return {"error": "ì„±ê³µí•œ ê°ì • ë¶„ì„ì´ ì—†ìŠµë‹ˆë‹¤"}
        
        # ê°ì •ë³„ íšŸìˆ˜ ê³„ì‚°
        emotion_counts = {emotion: 0 for emotion in self.emotion_labels}
        confidence_sum = 0
        
        for analysis in valid_analyses:
            emotion = analysis["predicted_emotion"]
            emotion_counts[emotion] += 1
            confidence_sum += analysis["confidence"]
        
        # ë¹„ìœ¨ ê³„ì‚°
        total_valid = len(valid_analyses)
        emotion_percentages = {
            emotion: round(count / total_valid * 100, 1) 
            for emotion, count in emotion_counts.items()
        }
        
        # ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚œ ê°ì •
        dominant_emotion = max(emotion_counts, key=emotion_counts.get)
        
        # í‰ê·  ì‹ ë¢°ë„
        avg_confidence = round(confidence_sum / total_valid, 3) if total_valid > 0 else 0
        
        return {
            "total_analyzed": total_valid,
            "emotion_counts": emotion_counts,
            "emotion_percentages": emotion_percentages,
            "dominant_emotion": dominant_emotion,
            "average_confidence": avg_confidence,
            "emotion_trend": self._assess_emotion_trend(valid_analyses)
        }

    def _assess_emotion_trend(self, analyses: List[Dict]) -> str:
        """ê°ì • ë³€í™” ì¶”ì´ í‰ê°€"""
        if len(analyses) < 2:
            return "ë¶„ì„ ë°ì´í„°ê°€ ë¶€ì¡±í•¨"
        
        # ì‹œê°„ìˆœìœ¼ë¡œ ì •ë ¬
        sorted_analyses = sorted(analyses, key=lambda x: x["interaction_index"])
        
        emotions = [a["predicted_emotion"] for a in sorted_analyses]
        
        # ê°ì • ë³€í™” íŒ¨í„´ ë¶„ì„
        anxious_count = emotions.count("Anxious")
        dry_count = emotions.count("Dry")
        kind_count = emotions.count("Kind")
        
        total = len(emotions)
        
        if anxious_count / total > 0.5:
            return "ì „ë°˜ì ìœ¼ë¡œ ë¶ˆì•ˆí•œ ìŒì„±"
        elif dry_count / total > 0.5:
            return "ì „ë°˜ì ìœ¼ë¡œ ê±´ì¡°í•œ ìŒì„±"
        elif kind_count / total > 0.5:
            return "ì „ë°˜ì ìœ¼ë¡œ ì¹œì ˆí•œ ìŒì„±"
        else:
            return "ê°ì •ì´ í˜¼ì¬ëœ ìŒì„±"

    def _assess_conversation_flow(self, interactions: List[Dict]) -> str:
        """ëŒ€í™” íë¦„ í’ˆì§ˆ í‰ê°€"""
        if len(interactions) < 3:
            return "ì¶©ë¶„í•˜ì§€ ì•Šì€ ëŒ€í™”ëŸ‰"
        elif len(interactions) < 5:
            return "ê¸°ë³¸ì ì¸ ëŒ€í™” ì§„í–‰"
        elif len(interactions) < 8:
            return "ì ì ˆí•œ ëŒ€í™” ì§„í–‰"
        else:
            return "ì¶©ë¶„í•œ ëŒ€í™” ì§„í–‰"

    async def _save_evaluation_result(self, session_id: str, result: Dict):
        """í‰ê°€ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        try:
            # JSON íŒŒì¼ë¡œ ì €ì¥
            json_path = self.evaluation_dir / f"{session_id}_evaluation.json"
            
            async with aiofiles.open(json_path, 'w', encoding='utf-8') as f:
                await f.write(json.dumps(result, ensure_ascii=False, indent=2))
            
            # ëŒ€í™” í…ìŠ¤íŠ¸ë§Œ ë³„ë„ ì €ì¥
            text_path = self.evaluation_dir / f"{session_id}_conversation.txt"
            async with aiofiles.open(text_path, 'w', encoding='utf-8') as f:
                await f.write(f"=== CPX ëŒ€í™” ê¸°ë¡ ===\n")
                await f.write(f"ì‚¬ìš©ì ID: {result['user_id']}\n")
                await f.write(f"ì‹œë‚˜ë¦¬ì˜¤ ID: {result['scenario_id']}\n")
                await f.write(f"ì‹œì‘ ì‹œê°„: {result['start_time']}\n")
                await f.write(f"ì¢…ë£Œ ì‹œê°„: {result['end_time']}\n")
                await f.write(f"ì´ ì†Œìš”ì‹œê°„: {result['duration_minutes']:.1f}ë¶„\n\n")
                
                for i, interaction in enumerate(result['interactions'], 1):
                    await f.write(f"--- ëŒ€í™” {i} ---\n")
                    await f.write(f"ì‹œê°„: {interaction['timestamp']}\n")
                    await f.write(f"í•™ìƒ: {interaction['student_question']}\n")
                    await f.write(f"í™˜ì: {interaction['patient_response']}\n")
                    if interaction.get('audio_file'):
                        await f.write(f"ìŒì„±íŒŒì¼: {interaction['audio_file']}\n")
                    await f.write("\n")
            
            print(f"ğŸ’¾ [{session_id}] í‰ê°€ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {json_path}")
            
        except Exception as e:
            print(f"âŒ [{session_id}] í‰ê°€ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

    async def get_evaluation_result(self, session_id: str) -> Dict:
        """ì €ì¥ëœ í‰ê°€ ê²°ê³¼ ì¡°íšŒ"""
        json_path = self.evaluation_dir / f"{session_id}_evaluation.json"
        
        if not json_path.exists():
            return {"error": "í‰ê°€ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}
        
        try:
            async with aiofiles.open(json_path, 'r', encoding='utf-8') as f:
                content = await f.read()
                return json.loads(content)
        except Exception as e:
            return {"error": f"í‰ê°€ ê²°ê³¼ ë¡œë“œ ì‹¤íŒ¨: {e}"}

    # =============================================================================
    # LangGraph ê¸°ë°˜ í…ìŠ¤íŠ¸ í‰ê°€ ê¸°ëŠ¥ (í†µí•©)
    # =============================================================================
    
    def _initialize_langgraph_components(self):
        """LangGraph ì»´í¬ë„ŒíŠ¸ë“¤ ì´ˆê¸°í™”"""
        try:
            # OpenAI API ì„¤ì •
            api_key = os.getenv("OPENAI_API_KEY")
            if api_key:
                self.llm = ChatOpenAI(
                    openai_api_key=api_key,
                    model_name="gpt-3.5-turbo",
                    temperature=0.3,
                    max_tokens=2000
                )
                
                # ë³‘ë ¥ì²­ì·¨ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì„¤ì •
                self._setup_history_taking_checklist()
                
                # ì›Œí¬í”Œë¡œìš° ìƒì„±
                self.langgraph_workflow = self._create_evaluation_workflow()
                print("âœ… LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
            else:
                print("âš ï¸ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•„ í…ìŠ¤íŠ¸ í‰ê°€ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                
        except Exception as e:
            print(f"âŒ LangGraph ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.llm = None
            self.langgraph_workflow = None

    def _setup_history_taking_checklist(self):
        """ë³‘ë ¥ì²­ì·¨ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì„¤ì •"""
        self.history_taking_checklist = {
            "ìê¸°ì†Œê°œ_ë°_ë©´ë‹´_ì£¼ì œ_í˜‘ìƒ": {
                "name": "ìê¸°ì†Œê°œ ë° ë©´ë‹´ ì£¼ì œ í˜‘ìƒ",
                "required_elements": [
                    "ì•ˆë…•í•˜ì„¸ìš”, í•™ìƒì˜ì‚¬ â—‹â—‹â—‹ì…ë‹ˆë‹¤",
                    "í™˜ìë¶„ ì„±í•¨ê³¼ ë‚˜ì´ í™•ì¸", 
                    "ë³‘ì›ì— ì˜¤ì‹œëŠ” ë° ë¶ˆí¸í•˜ì§€ëŠ” ì•Šìœ¼ì…¨ë‚˜ìš”?",
                    "ì˜¤ëŠ˜ ___ê°€ ë¶ˆí¸í•´ì„œ ì˜¤ì…¨êµ°ìš”",
                    "ì•½ 10ë¶„ ì •ë„ ë¬¸ì§„ê³¼ ì‹ ì²´ì§„ì°°ì„ í•œ ë’¤, ì„¤ëª…ì„ ë“œë¦¬ê³  í•©ë‹ˆë‹¤"
                ],
                "weight": 0.1
            },
            "ì–¸ì œ_OPQRST": {
                "name": "ì–¸ì œ (OPQRST)",
                "required_elements": [
                    "ì¦ìƒì˜ ë°œìƒ ì‹œì  (O: Onset)",
                    "ì¦ìƒì˜ ìœ ì§€ ê¸°ê°„ (D: Duration)", 
                    "ì¦ìƒì˜ ì•…í™”/ì™„í™” ì–‘ìƒ (Co: Course)",
                    "ê³¼ê±° ìœ ì‚¬í•œ ì¦ìƒì˜ ê²½í—˜ ì—¬ë¶€ (Ex: Experience)"
                ],
                "weight": 0.25
            },
            "ì–´ë””ì„œ": {
                "name": "ì–´ë””ì„œ",
                "required_elements": [
                    "(í†µì¦, ë°œì§„ ë“± ì¼ë¶€ ì„ìƒí‘œí˜„) ì¦ìƒì˜ ìœ„ì¹˜ (L: Location)",
                    "ì¦ìƒì´ ì´‰ë°œ/ì•…í™”/ì™„í™”ë˜ëŠ” ìƒí™© (F: Factor)"
                ],
                "weight": 0.15
            },
            "1ì°¨_ìš”ì•½": {
                "name": "1ì°¨ ìš”ì•½ (3ê°€ì§€ ì´ìƒ ì–¸ê¸‰)",
                "required_elements": [
                    "ëª¸ ìƒíƒœì— ëŒ€í•´ ëª‡ ê°€ì§€ ë” ì—¬ì­¤ê² ìŠµë‹ˆë‹¤"
                ],
                "weight": 0.1
            },
            "ì–´ë–»ê²Œ": {
                "name": "ì–´ë–»ê²Œ",
                "required_elements": [
                    "ì¦ìƒì˜ ì–‘ìƒ, ë¬¼ì„±í•¨ì˜ ì •ë„ (C: Character)",
                    "ì‘ê¸‰, ì¶œí˜ˆê²½í–¥ì„± ë“±",
                    "ì£¼ì†Œì— í”íˆ ë™ë°˜ë˜ëŠ” ë‹¤ë¥¸ ì¦ìƒ (ê³„í†µ ë¬¸ì§„) (A: Associated sx.)"
                ],
                "weight": 0.15
            },
            "ì™œ": {
                "name": "ì™œ",
                "required_elements": [
                    "ê°ë³„ì— ë„ì›€ì´ ë˜ëŠ” ë‹¤ë¥¸ ì¦ìƒ"
                ],
                "weight": 0.1
            },
            "ëˆ„ê°€": {
                "name": "ëˆ„ê°€", 
                "required_elements": [
                    "ê³¼ê±° ë³‘ë ¥/ìˆ˜ìˆ  ì´ë ¥/ê±´ê°•ê²€ì§„ ì—¬ë¶€ (ê³¼: ê³¼ê±°ë ¥)",
                    "ì•½ë¬¼ë ¥ (ì•½: ì•½ë¬¼ë ¥)",
                    "ì§ì—…, ìŒì£¼, í¡ì—°, ìƒí™œìŠµê´€ (ì‚¬: ì‚¬íšŒë ¥)",
                    "ê°€ì¡±ë ¥ (ê°€: ê°€ì¡±ë ¥)"
                ],
                "weight": 0.1
            },
            "2ì°¨_ìš”ì•½": {
                "name": "2ì°¨ ìš”ì•½ (3ê°€ì§€ ì´ìƒ ì–¸ê¸‰)",
                "required_elements": [
                    "ì§ˆë¬¸ ë‚´ìš©ì´ ë§ì•˜ëŠ”ë°, ì˜ ëŒ€ë‹µí•´ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤",
                    "ë§ì€ ë„ì›€ì´ ë˜ì—ˆìŠµë‹ˆë‹¤"
                ],
                "weight": 0.05
            }
        }

    async def evaluate_conversation_with_langgraph(self, user_id: str, scenario_id: str, conversation_log: List[Dict]) -> Dict:
        """LangGraphë¥¼ ì‚¬ìš©í•œ ëŒ€í™” í…ìŠ¤íŠ¸ í‰ê°€"""
        if not self.llm or not self.langgraph_workflow:
            return {
                "error": "LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ê¸°ëŠ¥ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤",
                "user_id": user_id,
                "scenario_id": scenario_id
            }
        
        # ì´ˆê¸° ìƒíƒœ êµ¬ì„±
        initial_state = CPXEvaluationState(
            user_id=user_id,
            scenario_id=scenario_id,
            conversation_log=conversation_log,
            conversation_analysis=None,
            checklist_results=None,
            question_analysis=None,
            empathy_analysis=None,
            confidence_score=0.0,
            retry_count=0,
            needs_enhancement=False,
            final_scores=None,
            feedback=None,
            evaluation_metadata=None,
            messages=[]
        )
        
        try:
            # ì›Œí¬í”Œë¡œìš° ì‹¤í–‰
            print(f"ğŸš€ [{user_id}] LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì›Œí¬í”Œë¡œìš° ì‹œì‘")
            final_state = self.langgraph_workflow.invoke(initial_state)
            
            # ìµœì¢… ê²°ê³¼ ë°˜í™˜
            result = final_state.get("final_evaluation_result", {})
            print(f"ğŸ‰ [{user_id}] LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì›Œí¬í”Œë¡œìš° ì™„ë£Œ")
            
            return result
            
        except Exception as e:
            print(f"âŒ [{user_id}] LangGraph í…ìŠ¤íŠ¸ í‰ê°€ ì›Œí¬í”Œë¡œìš° ì˜¤ë¥˜: {e}")
            return {
                "error": str(e),
                "user_id": user_id,
                "scenario_id": scenario_id,
                "evaluation_date": datetime.now().isoformat()
            }

    def _create_evaluation_workflow(self):
        """CPX í‰ê°€ ì›Œí¬í”Œë¡œìš° ìƒì„± (ê°„ì†Œí™”ëœ ë²„ì „)"""
        try:
            # StateGraph ìƒì„±
            workflow = StateGraph(CPXEvaluationState)
            
            # ë…¸ë“œ ì¶”ê°€ (í•µì‹¬ ê¸°ëŠ¥ë§Œ)
            workflow.add_node("initialize", self._initialize_evaluation)
            workflow.add_node("analyze_conversation", self._analyze_conversation)
            workflow.add_node("evaluate_checklist", self._evaluate_checklist)
            workflow.add_node("calculate_scores", self._calculate_final_scores)
            workflow.add_node("finalize_results", self._finalize_results)
            
            # ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸ ì„¤ì •
            workflow.set_entry_point("initialize")
            
            # ìˆœì°¨ ì‹¤í–‰ ì—£ì§€
            workflow.add_edge("initialize", "analyze_conversation")
            workflow.add_edge("analyze_conversation", "evaluate_checklist")
            workflow.add_edge("evaluate_checklist", "calculate_scores")
            workflow.add_edge("calculate_scores", "finalize_results")
            workflow.add_edge("finalize_results", END)
            
            return workflow.compile()
            
        except Exception as e:
            print(f"âŒ ì›Œí¬í”Œë¡œìš° ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    # ì›Œí¬í”Œë¡œìš° ë…¸ë“œë“¤ (ê°„ì†Œí™”ëœ ë²„ì „)
    def _initialize_evaluation(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """1ë‹¨ê³„: í‰ê°€ ì´ˆê¸°í™”"""
        print(f"ğŸ¯ [{state['user_id']}] CPX í…ìŠ¤íŠ¸ í‰ê°€ ì´ˆê¸°í™” - ì‹œë‚˜ë¦¬ì˜¤: {state['scenario_id']}")
        
        metadata = {
            "user_id": state["user_id"],
            "scenario_id": state["scenario_id"],
            "evaluation_date": datetime.now().isoformat(),
            "total_interactions": len(state["conversation_log"]),
            "conversation_duration_minutes": len(state["conversation_log"]) * 0.5,
            "conversation_transcript": json.dumps(state["conversation_log"], ensure_ascii=False)
        }
        
        return {
            **state,
            "evaluation_metadata": metadata,
            "confidence_score": 0.0,
            "retry_count": 0,
            "needs_enhancement": False,
            "messages": [HumanMessage(content="CPX í…ìŠ¤íŠ¸ í‰ê°€ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")]
        }

    def _analyze_conversation(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """2ë‹¨ê³„: ëŒ€í™” ë¶„ì„"""
        print(f"ğŸ” [{state['user_id']}] ëŒ€í™” ë‚´ìš© ë¶„ì„ ì¤‘...")
        
        # ëŒ€í™” ë¡œê·¸ì—ì„œ ì˜ì‚¬ ë°œì–¸ë§Œ ì¶”ì¶œ
        doctor_messages = [
            msg for msg in state["conversation_log"] 
            if msg.get("role") == "assistant" or msg.get("speaker") == "doctor"
        ]
        
        conversation_analysis = {
            "total_doctor_messages": len(doctor_messages),
            "total_patient_messages": len(state["conversation_log"]) - len(doctor_messages),
            "conversation_flow": "analyzed",
            "key_topics": ["ë³‘ë ¥ì²­ì·¨", "ì¦ìƒë¬¸ì§„", "í™˜ììƒë‹´"]
        }
        
        return {
            **state,
            "conversation_analysis": conversation_analysis
        }

    def _evaluate_checklist(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """3ë‹¨ê³„: ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€"""
        print(f"âœ… [{state['user_id']}] ë³‘ë ¥ì²­ì·¨ ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€ ì¤‘...")
        
        # ê°„ì†Œí™”ëœ ì²´í¬ë¦¬ìŠ¤íŠ¸ í‰ê°€
        checklist_results = {}
        total_score = 0.0
        
        for category, details in self.history_taking_checklist.items():
            # ì‹¤ì œë¡œëŠ” LLMì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ ë¶„ì„
            # ì—¬ê¸°ì„œëŠ” ê°„ì†Œí™”ëœ ë²„ì „ìœ¼ë¡œ êµ¬í˜„
            score = 0.7  # ê¸°ë³¸ ì ìˆ˜
            
            checklist_results[category] = {
                "name": details["name"],
                "score": score,
                "weight": details["weight"],
                "weighted_score": score * details["weight"],
                "feedback": f"{details['name']} í•­ëª©ì´ ì ì ˆíˆ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤."
            }
            
            total_score += score * details["weight"]
        
        return {
            **state,
            "checklist_results": checklist_results,
            "confidence_score": total_score
        }

    def _calculate_final_scores(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """4ë‹¨ê³„: ìµœì¢… ì ìˆ˜ ê³„ì‚°"""
        print(f"ğŸ“Š [{state['user_id']}] ìµœì¢… ì ìˆ˜ ê³„ì‚° ì¤‘...")
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ê¸°ë°˜ ì ìˆ˜
        checklist_score = state.get("confidence_score", 0.0)
        
        final_scores = {
            "overall_score": checklist_score * 100,
            "communication": 75.0,
            "history_taking": checklist_score * 100,
            "clinical_reasoning": 70.0,
            "professionalism": 80.0,
            "detailed_breakdown": state.get("checklist_results", {})
        }
        
        return {
            **state,
            "final_scores": final_scores
        }

    def _finalize_results(self, state: CPXEvaluationState) -> CPXEvaluationState:
        """5ë‹¨ê³„: ê²°ê³¼ ìµœì¢…í™”"""
        print(f"ğŸ¯ [{state['user_id']}] í…ìŠ¤íŠ¸ í‰ê°€ ê²°ê³¼ ìµœì¢…í™”...")
        
        final_result = {
            "user_id": state["user_id"],
            "scenario_id": state["scenario_id"],
            "evaluation_date": datetime.now().isoformat(),
            "text_evaluation_scores": state.get("final_scores", {}),
            "conversation_analysis": state.get("conversation_analysis", {}),
            "checklist_results": state.get("checklist_results", {}),
            "metadata": state.get("evaluation_metadata", {})
        }
        
        return {
            **state,
            "final_evaluation_result": final_result
        }