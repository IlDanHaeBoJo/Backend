"""
SER (Speech Emotion Recognition) ì„œë¹„ìŠ¤
ìŒì„± ê°ì • ë¶„ì„ ì „ë‹´ ì„œë¹„ìŠ¤
"""

from typing import Dict, Optional
import os
import torch
import numpy as np
import librosa
import logging
import boto3
import json
import base64
from core.config import settings

logger = logging.getLogger(__name__)

class SERService:
    def __init__(self):
        """SER ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        self.emotion_model = None
        self.emotion_processor = None
        self.emotion_labels = ["Anxious", "Dry", "Kind"]
        
        # SageMaker í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.sagemaker_runtime = None
        self.endpoint_name = settings.SAGEMAKER_SER_ENDPOINT
        
        if self.endpoint_name:
            try:
                # SageMaker ì „ìš© ìê²©ì¦ëª… ì‚¬ìš©
                access_key = settings.AWS_ACCESS_KEY_ID_SAGE or settings.AWS_ACCESS_KEY_ID
                secret_key = settings.AWS_SECRET_ACCESS_KEY_SAGE or settings.AWS_SECRET_ACCESS_KEY
                
                self.sagemaker_runtime = boto3.client(
                    'sagemaker-runtime',
                    region_name=settings.SAGEMAKER_REGION,
                    aws_access_key_id=access_key,
                    aws_secret_access_key=secret_key
                )
                print(f"ğŸ­ SageMaker SER ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ - ì—”ë“œí¬ì¸íŠ¸: {self.endpoint_name}")
            except Exception as e:
                logger.error(f"SageMaker í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.sagemaker_runtime = None
        else:
            print("âš ï¸ SageMaker ì—”ë“œí¬ì¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ SAGEMAKER_SER_ENDPOINTë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    
    async def load_model(self):
        """ê°ì • ë¶„ì„ ëª¨ë¸ ë¡œë“œ (SageMaker ì‚¬ìš©ìœ¼ë¡œ ì¸í•´ ë¶ˆí•„ìš”)"""
        if self.sagemaker_runtime and self.endpoint_name:
            print("ğŸ­ SageMaker ì—”ë“œí¬ì¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ")
            print("ğŸ’¡ ì—”ë“œí¬ì¸íŠ¸ ìƒíƒœ í™•ì¸ì€ ê¶Œí•œì´ í•„ìš”í•˜ë¯€ë¡œ ì‹¤ì œ í˜¸ì¶œë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤")
            return True
        else:
            print("âš ï¸ SageMaker í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
    
    async def _invoke_sagemaker_endpoint(self, audio_buffer: bytearray) -> Dict:
        """
        SageMaker ì—”ë“œí¬ì¸íŠ¸ë¥¼ í˜¸ì¶œí•˜ì—¬ ê°ì • ë¶„ì„ ìˆ˜í–‰
        
        Args:
            audio_buffer: raw ì˜¤ë””ì˜¤ ë²„í¼ (bytearray)
            
        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if not self.sagemaker_runtime or not self.endpoint_name:
            return {"error": "SageMaker ì—”ë“œí¬ì¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}
        
        try:
            # ì˜¤ë””ì˜¤ ë²„í¼ë¥¼ base64ë¡œ ì¸ì½”ë”© (SageMaker ì „ì†¡ìš©)
            audio_base64 = base64.b64encode(audio_buffer).decode('utf-8')
            
            # SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œì„ ìœ„í•œ í˜ì´ë¡œë“œ êµ¬ì„± (raw ì˜¤ë””ì˜¤ ë²„í¼)
            payload = {
                "instances": [{
                    "audio_data": audio_base64
                }]
            }
            
            # SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ
            response = self.sagemaker_runtime.invoke_endpoint(
                EndpointName=self.endpoint_name,
                ContentType='application/json',
                Body=json.dumps(payload)
            )
            
            # ì‘ë‹µ íŒŒì‹±
            result = json.loads(response['Body'].read().decode())
            
            # ê²°ê³¼ í˜•ì‹ í†µì¼ (SageMaker ì‘ë‹µì„ ê¸°ì¡´ í˜•ì‹ì— ë§ê²Œ ë³€í™˜)
            if 'predictions' in result and len(result['predictions']) > 0:
                prediction = result['predictions'][0]
                
                # ê°ì • ë¼ë²¨ê³¼ í™•ë¥  ì¶”ì¶œ
                if 'emotion_scores' in prediction:
                    emotion_scores = prediction['emotion_scores']
                    predicted_emotion = max(emotion_scores.keys(), key=lambda k: emotion_scores[k])
                    confidence = emotion_scores[predicted_emotion]
                else:
                    # ê¸°ë³¸ í˜•ì‹ì´ ë‹¤ë¥¼ ê²½ìš° ëŒ€ë¹„
                    predicted_emotion = prediction.get('predicted_emotion', 'Unknown')
                    confidence = prediction.get('confidence', 0.0)
                    emotion_scores = prediction.get('emotion_scores', {})
                
                return {
                    "success": True,
                    "predicted_emotion": predicted_emotion,
                    "confidence": confidence,
                    "emotion_scores": emotion_scores,
                    "source": "sagemaker_endpoint"
                }
            else:
                return {"error": "SageMaker ì—”ë“œí¬ì¸íŠ¸ì—ì„œ ìœ íš¨í•˜ì§€ ì•Šì€ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤"}
                
        except Exception as e:
            logger.error(f"SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": f"SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
    
    async def analyze_emotion_from_buffer(self, audio_buffer: bytearray) -> Dict:
        """
        ì˜¤ë””ì˜¤ ë²„í¼ì—ì„œ ì§ì ‘ ê°ì • ë¶„ì„ (SageMaker ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
        
        Args:
            audio_buffer: ë¶„ì„í•  ì˜¤ë””ì˜¤ ë²„í¼ (16-bit PCM)
            
        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            if not audio_buffer or len(audio_buffer) == 0:
                return {"error": "ì˜¤ë””ì˜¤ ë²„í¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}
            
            # SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ (raw ë²„í¼ ì§ì ‘ ì „ì†¡)
            result = await self._invoke_sagemaker_endpoint(audio_buffer)
            
            if result.get("success"):
                result["source"] = "audio_buffer_sagemaker"
            
            return result
                
        except Exception as e:
            logger.error(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
    
    async def analyze_emotion(self, audio_file_path: str) -> Dict:
        """
        ìŒì„± íŒŒì¼ì˜ ê°ì • ë¶„ì„ (SageMaker ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
        
        Args:
            audio_file_path: ë¶„ì„í•  ìŒì„± íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì˜¤ë””ì˜¤ íŒŒì¼ ì¡´ì¬ í™•ì¸
            if not os.path.exists(audio_file_path):
                return {"error": f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file_path}"}
            
            # íŒŒì¼ì„ ë°”ì´ë„ˆë¦¬ë¡œ ì½ê¸°
            with open(audio_file_path, 'rb') as f:
                audio_buffer = bytearray(f.read())
            
            # SageMaker ì—”ë“œí¬ì¸íŠ¸ í˜¸ì¶œ (raw íŒŒì¼ ë°ì´í„° ì§ì ‘ ì „ì†¡)
            result = await self._invoke_sagemaker_endpoint(audio_buffer)
            
            if result.get("success"):
                result["file_path"] = audio_file_path
                result["source"] = "audio_file_sagemaker"
            
            return result
                
        except Exception as e:
            logger.error(f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": f"ê°ì • ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}"}
    
    # SageMakerìš© ì „ì²˜ë¦¬ ë©”ì„œë“œë“¤ (í˜„ì¬ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ - raw ë²„í¼ ì§ì ‘ ì „ì†¡)
    # async def _preprocess_audio_from_buffer_for_sagemaker(self, audio_buffer: bytearray) -> Optional[np.ndarray]:
    #     """ì˜¤ë””ì˜¤ ë²„í¼ ì „ì²˜ë¦¬ (SageMakerìš©) - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
    #     pass
    
    # async def _preprocess_audio_for_sagemaker(self, file_path: str) -> Optional[np.ndarray]:
    #     """ì˜¤ë””ì˜¤ íŒŒì¼ ì „ì²˜ë¦¬ (SageMakerìš©) - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
    #     pass
    
    async def _preprocess_audio_from_buffer(self, audio_buffer: bytearray) -> Optional[torch.Tensor]:
        """ì˜¤ë””ì˜¤ ë²„í¼ ì „ì²˜ë¦¬ (Wav2Vec2ìš©)"""
        try:
            # 16-bit PCM ë²„í¼ë¥¼ numpy ë°°ì—´ë¡œ ë³€í™˜
            audio_data = np.frombuffer(audio_buffer, dtype=np.int16)
            
            # float32ë¡œ ì •ê·œí™” (-1.0 ~ 1.0)
            audio = audio_data.astype(np.float32) / 32768.0
            
            # ê¸¸ì´ ì œí•œ (ìµœëŒ€ 15ì´ˆ)
            max_duration = 15.0
            target_length = int(16000 * max_duration)
            
            if len(audio) > target_length:
                # ê°€ìš´ë° ë¶€ë¶„ ì‚¬ìš©
                start_idx = np.random.randint(0, len(audio) - target_length + 1)
                audio = audio[start_idx:start_idx + target_length]
            elif len(audio) < target_length:
                # íŒ¨ë”© ì¶”ê°€
                pad_length = target_length - len(audio)
                audio = np.pad(audio, (0, pad_length), mode='constant', constant_values=0)
            
            # Wav2Vec2 processorë¡œ ë³€í™˜
            inputs = self.emotion_processor(
                audio,
                sampling_rate=16000,
                return_tensors="pt",
                padding=True
            )
            
            return inputs.input_values.squeeze(0)
            
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ë²„í¼ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    async def _preprocess_audio(self, file_path: str) -> Optional[torch.Tensor]:
        """ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ (Wav2Vec2ìš©)"""
        try:
            # ì˜¤ë””ì˜¤ ë¡œë“œ (16kHzë¡œ ë¦¬ìƒ˜í”Œë§)
            audio, sr = librosa.load(file_path, sr=16000, res_type='kaiser_fast')
            
            # ê¸¸ì´ ì œí•œ (ìµœëŒ€ 15ì´ˆ)
            max_duration = 15.0
            target_length = int(16000 * max_duration)
            
            if len(audio) > target_length:
                # ê°€ìš´ë° ë¶€ë¶„ ì‚¬ìš©
                start_idx = np.random.randint(0, len(audio) - target_length + 1)
                audio = audio[start_idx:start_idx + target_length]
            elif len(audio) < target_length:
                # íŒ¨ë”© ì¶”ê°€
                pad_length = target_length - len(audio)
                audio = np.pad(audio, (0, pad_length), mode='constant', constant_values=0)
            
            # Wav2Vec2 processorë¡œ ë³€í™˜
            inputs = self.emotion_processor(
                audio,
                sampling_rate=16000,
                return_tensors="pt",
                padding=True
            )
            
            return inputs.input_values.squeeze(0)
            
        except Exception as e:
            logger.error(f"ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return None
    
    def is_model_loaded(self) -> bool:
        """ëª¨ë¸ ë¡œë“œ ìƒíƒœ í™•ì¸ (SageMaker ì—”ë“œí¬ì¸íŠ¸ ì—°ê²° ìƒíƒœ)"""
        return self.sagemaker_runtime is not None and self.endpoint_name is not None
    
    def get_model_info(self) -> Dict:
        """ëª¨ë¸ ì •ë³´ ë°˜í™˜ (SageMaker ì—”ë“œí¬ì¸íŠ¸ ì •ë³´)"""
        return {
            "model_loaded": self.is_model_loaded(),
            "sagemaker_endpoint": self.endpoint_name,
            "sagemaker_region": settings.SAGEMAKER_REGION,
            "emotion_labels": self.emotion_labels,
            "using_sagemaker": True
        }


