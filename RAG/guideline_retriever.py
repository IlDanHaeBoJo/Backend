"""
ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ë° í‰ê°€ë¥¼ ìœ„í•œ RAG ìœ í‹¸ë¦¬í‹°
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Optional
import torch
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_core.documents import Document

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆì„ importí•˜ê¸° ìœ„í•œ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent))

class GuidelineRetriever:
    """CPX ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ë° í‰ê°€ ë„êµ¬"""
    
    def __init__(self, index_path: str = "faiss_guideline_index", model_name: str = "intfloat/multilingual-e5-large"):
        """
        ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ê¸° ì´ˆê¸°í™”
        
        Args:
            index_path: FAISS ì¸ë±ìŠ¤ ê²½ë¡œ
            model_name: ì„ë² ë”© ëª¨ë¸ëª…
        """
        self.index_path = index_path
        self.model_name = model_name
        self.vectorstore = None
        self.embeddings = None
        
        self._initialize_vectorstore()
    
    def _initialize_vectorstore(self):
        """ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        try:
            device = "cuda" if torch.cuda.is_available() else "cpu"
            print(f"ğŸ”§ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” (ì¥ì¹˜: {device})")
            
            # ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™”
            self.embeddings = HuggingFaceEmbeddings(model_name=self.model_name)
            
            # FAISS ì¸ë±ìŠ¤ ë¡œë“œ
            if os.path.exists(self.index_path):
                self.vectorstore = FAISS.load_local(
                    self.index_path, 
                    self.embeddings, 
                    allow_dangerous_deserialization=True
                )
                print(f"âœ… ê°€ì´ë“œë¼ì¸ ì¸ë±ìŠ¤ ë¡œë“œ ì™„ë£Œ: {len(self.vectorstore.index_to_docstore_id.values())}ê°œ ë¬¸ì„œ")
            else:
                print(f"âŒ ê°€ì´ë“œë¼ì¸ ì¸ë±ìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.index_path}")
                print("ë¨¼ì € RAG/index_guideline.pyë¥¼ ì‹¤í–‰í•˜ì—¬ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”.")
                
        except Exception as e:
            print(f"âŒ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.vectorstore = None
    
    def search_guidelines(self, query: str, k: int = 5, category: Optional[str] = None) -> List[Document]:
        """
        ê°€ì´ë“œë¼ì¸ì—ì„œ ê´€ë ¨ ë‚´ìš© ê²€ìƒ‰
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            k: ë°˜í™˜í•  ë¬¸ì„œ ìˆ˜
            category: íŠ¹ì • ì¹´í…Œê³ ë¦¬ë¡œ í•„í„°ë§ (ì˜ˆ: "ê¸°ì–µë ¥ ì €í•˜")
            
        Returns:
            ê´€ë ¨ ë¬¸ì„œë“¤ì˜ ë¦¬ìŠ¤íŠ¸
        """
        if not self.vectorstore:
            print("âŒ ë²¡í„°ìŠ¤í† ì–´ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            # ê¸°ë³¸ ê²€ìƒ‰
            results = self.vectorstore.similarity_search(query, k=k*2)  # ì—¬ìœ ìˆê²Œ ê²€ìƒ‰
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°ë§
            if category:
                filtered_results = []
                for doc in results:
                    if doc.metadata.get("category") == category:
                        filtered_results.append(doc)
                results = filtered_results[:k]
            else:
                results = results[:k]
            
            return results
            
        except Exception as e:
            print(f"âŒ ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def get_evaluation_criteria(self, category: str, area: str = None) -> Dict:
        """
        íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ í‰ê°€ ê¸°ì¤€ ê°€ì ¸ì˜¤ê¸°
        
        Args:
            category: ì§ˆë³‘/ì¦ìƒ ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "ê¸°ì–µë ¥ ì €í•˜")
            area: í‰ê°€ ì˜ì—­ (ì˜ˆ: "ë³‘ë ¥ ì²­ì·¨", "ì‹ ì²´ ì§„ì°°", "í™˜ì êµìœ¡")
            
        Returns:
            í‰ê°€ ê¸°ì¤€ ë”•ì…”ë„ˆë¦¬
        """
        if not self.vectorstore:
            return {}
        
        # ì¿¼ë¦¬ êµ¬ì„±
        if area:
            query = f"{category} {area} í‰ê°€ ê¸°ì¤€"
        else:
            query = f"{category} CPX í‰ê°€ ê¸°ì¤€"
        
        # ê²€ìƒ‰ ìˆ˜í–‰
        results = self.search_guidelines(query, k=10, category=category)
        
        # ê²°ê³¼ êµ¬ì¡°í™”
        evaluation_criteria = {
            "category": category,
            "area": area,
            "criteria": [],
            "questions": [],
            "actions": []
        }
        
        for doc in results:
            doc_type = doc.metadata.get("type", "unknown")
            
            if doc_type == "subcategory":
                # ì„¸ë¶€ ì¹´í…Œê³ ë¦¬ì˜ ì§ˆë¬¸/í–‰ë™ ì¶”ì¶œ
                content_lines = doc.page_content.split('\n')
                current_section = None
                
                for line in content_lines:
                    line = line.strip()
                    if line.startswith("í•„ìˆ˜ ì§ˆë¬¸ë“¤:"):
                        current_section = "questions"
                    elif line.startswith("í•„ìˆ˜ í–‰ë™ë“¤:"):
                        current_section = "actions"
                    elif line.startswith("- ") and current_section:
                        item = line[2:].strip()  # "- " ì œê±°
                        if current_section == "questions":
                            evaluation_criteria["questions"].append({
                                "question": item,
                                "subcategory": doc.metadata.get("subcategory", ""),
                                "area": doc.metadata.get("area", "")
                            })
                        elif current_section == "actions":
                            evaluation_criteria["actions"].append({
                                "action": item,
                                "subcategory": doc.metadata.get("subcategory", ""),
                                "area": doc.metadata.get("area", "")
                            })
        
        return evaluation_criteria
    
    def evaluate_conversation_completeness(self, conversation_log: List[Dict], category: str) -> Dict:
        """
        ëŒ€í™” ë¡œê·¸ë¥¼ ê°€ì´ë“œë¼ì¸ê³¼ ë¹„êµí•˜ì—¬ ì™„ì„±ë„ í‰ê°€
        
        Args:
            conversation_log: ëŒ€í™” ë¡œê·¸ [{"role": "student/patient", "content": "..."}]
            category: í‰ê°€í•  ì¹´í…Œê³ ë¦¬ (ì˜ˆ: "ê¸°ì–µë ¥ ì €í•˜")
            
        Returns:
            ì™„ì„±ë„ í‰ê°€ ê²°ê³¼
        """
        if not self.vectorstore:
            return {"error": "ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ê¸°ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}
        
        # ì „ì²´ ëŒ€í™” í…ìŠ¤íŠ¸ êµ¬ì„±
        conversation_text = "\n".join([
            f"{entry['role']}: {entry['content']}" 
            for entry in conversation_log
        ])
        
        # ê° í‰ê°€ ì˜ì—­ë³„ë¡œ ê¸°ì¤€ ê°€ì ¸ì˜¤ê¸°
        areas = ["ë³‘ë ¥ ì²­ì·¨", "ì‹ ì²´ ì§„ì°°", "í™˜ì êµìœ¡"]
        evaluation_results = {
            "category": category,
            "overall_completeness": 0.0,
            "area_results": {},
            "missing_items": [],
            "completed_items": []
        }
        
        total_score = 0
        area_count = 0
        
        for area in areas:
            criteria = self.get_evaluation_criteria(category, area)
            
            if not criteria.get("questions") and not criteria.get("actions"):
                continue
            
            area_result = self._evaluate_area_completeness(
                conversation_text, 
                criteria, 
                area
            )
            
            evaluation_results["area_results"][area] = area_result
            total_score += area_result["completeness_score"]
            area_count += 1
            
            # ëˆ„ë½ëœ í•­ëª©ê³¼ ì™„ë£Œëœ í•­ëª© ìˆ˜ì§‘
            evaluation_results["missing_items"].extend(area_result.get("missing_items", []))
            evaluation_results["completed_items"].extend(area_result.get("completed_items", []))
        
        # ì „ì²´ ì™„ì„±ë„ ê³„ì‚°
        if area_count > 0:
            evaluation_results["overall_completeness"] = total_score / area_count
        
        return evaluation_results
    
    def _evaluate_area_completeness(self, conversation_text: str, criteria: Dict, area: str) -> Dict:
        """íŠ¹ì • ì˜ì—­ì˜ ì™„ì„±ë„ í‰ê°€"""
        
        result = {
            "area": area,
            "completeness_score": 0.0,
            "total_items": 0,
            "completed_items": [],
            "missing_items": []
        }
        
        # ì§ˆë¬¸ í•­ëª© í‰ê°€
        questions = criteria.get("questions", [])
        actions = criteria.get("actions", [])
        all_items = questions + actions
        
        if not all_items:
            return result
        
        result["total_items"] = len(all_items)
        completed_count = 0
        
        conversation_lower = conversation_text.lower()
        
        for item in all_items:
            item_text = item.get("question", item.get("action", ""))
            item_key_words = self._extract_keywords(item_text)
            
            # í‚¤ì›Œë“œ ê¸°ë°˜ ë§¤ì¹­ (ê°„ë‹¨í•œ ë°©ì‹)
            is_completed = any(
                keyword.lower() in conversation_lower 
                for keyword in item_key_words
                if len(keyword) > 2  # 2ê¸€ì ì´ìƒ í‚¤ì›Œë“œë§Œ
            )
            
            if is_completed:
                completed_count += 1
                result["completed_items"].append({
                    "item": item_text,
                    "subcategory": item.get("subcategory", ""),
                    "type": "question" if "question" in item else "action"
                })
            else:
                result["missing_items"].append({
                    "item": item_text,
                    "subcategory": item.get("subcategory", ""),
                    "type": "question" if "question" in item else "action"
                })
        
        # ì™„ì„±ë„ ì ìˆ˜ ê³„ì‚°
        result["completeness_score"] = completed_count / len(all_items) if all_items else 0.0
        
        return result
    
    def _extract_keywords(self, text: str) -> List[str]:
        """í…ìŠ¤íŠ¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)"""
        
        # ë¶ˆìš©ì–´ ì œê±°ë¥¼ ìœ„í•œ ê°„ë‹¨í•œ ë¦¬ìŠ¤íŠ¸
        stop_words = {
            "ì´", "ê°€", "ì„", "ë¥¼", "ì˜", "ì—", "ì—ì„œ", "ìœ¼ë¡œ", "ë¡œ", "ê³¼", "ì™€", "ë„", "ë§Œ", "ê¹Œì§€", "ë¶€í„°",
            "ì€", "ëŠ”", "ì´ë‹¤", "ìˆë‹¤", "ì—†ë‹¤", "í•˜ë‹¤", "ë˜ë‹¤", "ì´ì•¼", "ì•¼", "ì•„", "ì–´", "ì§€", "ê³ ", "ì„œ",
            "ì–´ë–»ê²Œ", "ë¬´ì—‡", "ëˆ„êµ¬", "ì–¸ì œ", "ì–´ë””ì„œ", "ì™œ", "ì–´ë–¤", "ëª‡", "ì–¼ë§ˆë‚˜"
        }
        
        # ë‹¨ì–´ ë¶„ë¦¬ ë° ì •ì œ
        words = []
        for word in text.replace("?", "").replace(".", "").replace(",", "").split():
            word = word.strip()
            if len(word) > 1 and word not in stop_words:
                words.append(word)
        
        return words

def main():
    """í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    
    print("ğŸ§ª ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ê¸° í…ŒìŠ¤íŠ¸")
    
    retriever = GuidelineRetriever()
    
    if not retriever.vectorstore:
        print("âŒ ê²€ìƒ‰ê¸° ì´ˆê¸°í™” ì‹¤íŒ¨")
        return
    
    # í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ê²€ìƒ‰
    print("\nğŸ” í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ê²€ìƒ‰")
    results = retriever.search_guidelines("ê¸°ì–µë ¥ ì €í•˜ ë³‘ë ¥ì²­ì·¨", k=3)
    for i, doc in enumerate(results):
        print(f"  {i+1}. [{doc.metadata.get('type')}] {doc.page_content[:100]}...")
    
    # í…ŒìŠ¤íŠ¸ 2: í‰ê°€ ê¸°ì¤€ ê°€ì ¸ì˜¤ê¸°
    print("\nğŸ“‹ í…ŒìŠ¤íŠ¸ 2: í‰ê°€ ê¸°ì¤€")
    criteria = retriever.get_evaluation_criteria("ê¸°ì–µë ¥ ì €í•˜", "ë³‘ë ¥ ì²­ì·¨")
    print(f"  ì§ˆë¬¸ ìˆ˜: {len(criteria.get('questions', []))}")
    print(f"  í–‰ë™ ìˆ˜: {len(criteria.get('actions', []))}")
    
    # í…ŒìŠ¤íŠ¸ 3: ëŒ€í™” ì™„ì„±ë„ í‰ê°€
    print("\nâ­ í…ŒìŠ¤íŠ¸ 3: ëŒ€í™” ì™„ì„±ë„ í‰ê°€")
    test_conversation = [
        {"role": "student", "content": "ì–¸ì œë¶€í„° ê¸°ì–µë ¥ì´ ë–¨ì–´ì§€ì…¨ë‚˜ìš”?"},
        {"role": "patient", "content": "3ê°œì›” ì „ë¶€í„°ìš”."},
        {"role": "student", "content": "ê°€ì¡± ì¤‘ì— ì¹˜ë§¤ í™˜ìê°€ ìˆë‚˜ìš”?"},
        {"role": "patient", "content": "ì•„ë²„ì§€ê°€ ì¹˜ë§¤ì˜€ìŠµë‹ˆë‹¤."}
    ]
    
    evaluation = retriever.evaluate_conversation_completeness(test_conversation, "ê¸°ì–µë ¥ ì €í•˜")
    print(f"  ì „ì²´ ì™„ì„±ë„: {evaluation['overall_completeness']:.2%}")
    print(f"  ì™„ë£Œëœ í•­ëª©: {len(evaluation['completed_items'])}ê°œ")
    print(f"  ëˆ„ë½ëœ í•­ëª©: {len(evaluation['missing_items'])}ê°œ")

if __name__ == "__main__":
    main()
