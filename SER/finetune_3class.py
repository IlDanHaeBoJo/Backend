"""
3ê°œ í´ë˜ìŠ¤ ìŒì„± ê°ì • ë¶„ì„ íŒŒì¸íŠœë‹ ìŠ¤í¬ë¦½íŠ¸
- Anxious (21-30 í´ë”)
- Kind (31-40 í´ë”) 
- Dry (91-100 í´ë”)
"""

import os
import sys
import torch
import numpy as np
from typing import Dict, Any
import warnings
warnings.filterwarnings('ignore')

# í˜„ì¬ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

try:
    # íŒ¨í‚¤ì§€ë¡œ ì‹¤í–‰ë  ë•Œ
    from .model import create_model
    from .data_loader import load_dataset_from_numbered_folders, create_data_splits, create_dataloaders
    from .trainer import create_trainer
    from .config import model_config, training_config, data_config
    from .preprocessing import preprocessor
except ImportError:
    # ì§ì ‘ ì‹¤í–‰ë  ë•Œ
    from model import create_model
    from data_loader import load_dataset_from_numbered_folders, create_data_splits, create_dataloaders
    from trainer import create_trainer
    from config import model_config, training_config, data_config
    from preprocessing import preprocessor

def setup_environment(seed=42):
    """í™˜ê²½ ì„¤ì •"""
    # ëœë¤ ì‹œë“œ ì„¤ì •
    torch.manual_seed(seed)
    np.random.seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
    
    # GPU ì„¤ì •
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}")
    if torch.cuda.is_available():
        print(f"ğŸ® GPU: {torch.cuda.get_device_name()}")
        print(f"ğŸ’¾ GPU ë©”ëª¨ë¦¬: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f}GB")
    
    return device

def print_data_summary(audio_paths, labels):
    """ë°ì´í„° ìš”ì•½ ì •ë³´ ì¶œë ¥"""
    from collections import Counter
    label_counts = Counter(labels)
    
    print(f"\n{'='*50}")
    print(f"ğŸ“Š ë°ì´í„°ì…‹ ìš”ì•½")
    print(f"{'='*50}")
    print(f"ì´ íŒŒì¼ ìˆ˜: {len(audio_paths):,}ê°œ")
    print(f"\ní´ë˜ìŠ¤ë³„ ë¶„í¬:")
    for label, count in label_counts.items():
        percentage = (count / len(audio_paths)) * 100
        print(f"  {label}: {count:,}ê°œ ({percentage:.1f}%)")
    
    # í´ë˜ìŠ¤ ê· í˜• í™•ì¸
    min_count = min(label_counts.values())
    max_count = max(label_counts.values())
    imbalance_ratio = max_count / min_count
    print(f"\ní´ë˜ìŠ¤ ë¶ˆê· í˜• ë¹„ìœ¨: {imbalance_ratio:.2f}")
    if imbalance_ratio > 2.0:
        print("âš ï¸  í´ë˜ìŠ¤ ë¶ˆê· í˜•ì´ ìˆìŠµë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ì¡°ì •ì„ ê³ ë ¤í•´ë³´ì„¸ìš”.")

def create_class_weights(labels):
    """í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• ë°ì´í„° ëŒ€ì‘)"""
    from collections import Counter
    from sklearn.utils.class_weight import compute_class_weight
    
    label_counts = Counter(labels)
    classes = list(label_counts.keys())
    class_weights = compute_class_weight(
        'balanced',
        classes=np.array(classes),
        y=np.array(labels)
    )
    
    weight_dict = {classes[i]: class_weights[i] for i in range(len(classes))}
    print(f"\nğŸ‹ï¸  í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜:")
    for label, weight in weight_dict.items():
        print(f"  {label}: {weight:.3f}")
    
    return weight_dict

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    print("ğŸµ wav2vec2-large-xlsr-korean 3ê°œ í´ë˜ìŠ¤ ê°ì • ë¶„ì„ íŒŒì¸íŠœë‹")
    print("="*70)
    
    # 1. í™˜ê²½ ì„¤ì •
    device = setup_environment()
    
    # 2. ë°ì´í„° ê²½ë¡œ ì„¤ì •
    data_dir = "/data/ghdrnjs/SER/small/"
    output_dir = "./results_3class"
    
    print(f"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {data_dir}")
    print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ê²½ë¡œ: {output_dir}")
    
    # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    os.makedirs(output_dir, exist_ok=True)
    
    # 3. ë°ì´í„° ë¡œë“œ
    print(f"\nğŸ“‚ íŒŒì¼ëª… ë²ˆí˜¸ ê¸°ë°˜ìœ¼ë¡œ ë°ì´í„° ë¡œë“œ ì¤‘...")
    print(f"   - 000021-000030 â†’ Anxious")
    print(f"   - 000031-000040 â†’ Kind")
    print(f"   - 000091-000100 â†’ Dry")
    print(f"   - ë°ì´í„° êµ¬ì¡°: [PERSON]/wav_48000/[PERSON]_[6ìë¦¬ë²ˆí˜¸].wav")
    
    audio_paths, labels = load_dataset_from_numbered_folders(data_dir)
    
    if len(audio_paths) == 0:
        print("âŒ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
        return
    
    # 4. ë°ì´í„° ìš”ì•½ ì¶œë ¥
    print_data_summary(audio_paths, labels)
    
    # 5. í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    class_weights = create_class_weights(labels)
    
    # 6. ë°ì´í„° ë¶„í• 
    print(f"\nğŸ”€ ë°ì´í„° ë¶„í•  ì¤‘...")
    train_data, val_data, test_data = create_data_splits(
        audio_paths, labels,
        train_ratio=0.7,    # í›ˆë ¨ìš© 70%
        val_ratio=0.15,     # ê²€ì¦ìš© 15%
        test_ratio=0.15,    # í…ŒìŠ¤íŠ¸ìš© 15%
        random_state=42
    )
    
    # 7. ëª¨ë¸ ìƒì„±
    print(f"\nğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
    print(f"   - ëª¨ë¸: {model_config.model_name}")
    print(f"   - í´ë˜ìŠ¤ ìˆ˜: {model_config.num_labels}")
    print(f"   - ê°ì • ë¼ë²¨: {model_config.emotion_labels}")
    
    model = create_model()
    model.to(device)
    
    # 8. ë°ì´í„°ë¡œë” ìƒì„±
    print(f"\nğŸ”„ ë°ì´í„°ë¡œë” ìƒì„± ì¤‘...")
    train_loader, val_loader, test_loader = create_dataloaders(
        train_data, val_data, test_data, model.processor
    )
    
    # 9. í›ˆë ¨ ì„¤ì • ì—…ë°ì´íŠ¸
    training_config.output_dir = output_dir
    training_config.num_epochs = 15  # 3ê°œ í´ë˜ìŠ¤ì´ë¯€ë¡œ ì¶©ë¶„í•œ ì—í¬í¬
    
    print(f"\nâš™ï¸  í›ˆë ¨ ì„¤ì •:")
    print(f"   - ì—í¬í¬: {training_config.num_epochs}")
    print(f"   - ë°°ì¹˜ í¬ê¸°: {training_config.batch_size}")
    print(f"   - í•™ìŠµë¥ : {training_config.learning_rate}")
    print(f"   - ê°€ì¤‘ì¹˜ ê°ì‡ : {training_config.weight_decay}")
    print(f"   - ë“œë¡­ì•„ì›ƒ: {training_config.dropout_rate}")
    print(f"   - ë¼ë²¨ ìŠ¤ë¬´ë”©: {training_config.label_smoothing}")
    
    # 10. í›ˆë ¨ê¸° ìƒì„±
    print(f"\nğŸ‹ï¸  í›ˆë ¨ê¸° ìƒì„± ì¤‘...")
    trainer = create_trainer(model, class_weights=class_weights)
    
    # 11. í›ˆë ¨ ì‹œì‘
    print(f"\nğŸš€ í›ˆë ¨ ì‹œì‘!")
    print("="*50)
    
    try:
        # í›ˆë ¨ ì‹¤í–‰
        trainer.train(
            train_data=train_data,
            val_data=val_data,
            test_data=test_data,
            output_dir=output_dir
        )
        
        print(f"\nâœ… í›ˆë ¨ ì™„ë£Œ!")
        
        # 12. ìµœì¢… í‰ê°€
        print(f"\nğŸ“Š ìµœì¢… í‰ê°€ ì¤‘...")
        eval_results = trainer.evaluate()
        
        if eval_results:
            print(f"\nğŸ¯ ìµœì¢… ê²°ê³¼:")
            print(f"   - ì •í™•ë„: {eval_results.get('eval_accuracy', 'N/A'):.4f}")
            print(f"   - F1 ìŠ¤ì½”ì–´: {eval_results.get('eval_f1', 'N/A'):.4f}")
            print(f"   - ì†ì‹¤: {eval_results.get('eval_loss', 'N/A'):.4f}")
        
        # 13. ëª¨ë¸ ì €ì¥
        model_save_path = os.path.join(output_dir, "final_model")
        model.save_model(model_save_path)
        print(f"\nğŸ’¾ ëª¨ë¸ ì €ì¥ ì™„ë£Œ: {model_save_path}")
        
        # 14. ê°„ë‹¨í•œ ì¶”ë¡  í…ŒìŠ¤íŠ¸
        print(f"\nğŸ§ª ì¶”ë¡  í…ŒìŠ¤íŠ¸...")
        if len(test_data[0]) > 0:
            test_audio_path = test_data[0][0]
            predicted_emotion = model.predict(test_audio_path)
            actual_emotion = test_data[1][0]
            print(f"   - í…ŒìŠ¤íŠ¸ íŒŒì¼: {os.path.basename(test_audio_path)}")
            print(f"   - ì˜ˆì¸¡ ê°ì •: {predicted_emotion}")
            print(f"   - ì‹¤ì œ ê°ì •: {actual_emotion}")
            print(f"   - ê²°ê³¼: {'âœ… ì •í™•' if predicted_emotion == actual_emotion else 'âŒ í‹€ë¦¼'}")
        
        print(f"\nğŸ‰ ëª¨ë“  ê³¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except KeyboardInterrupt:
        print(f"\nâ¹ï¸  í›ˆë ¨ì´ ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

def test_data_loading():
    """ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    data_dir = "/data/ghdrnjs/SER/small/"
    print(f"ğŸ“‚ ë°ì´í„° ë¡œë”© í…ŒìŠ¤íŠ¸: {data_dir}")
    print(f"   íŒŒì¼ëª… íŒ¨í„´: [PERSON]_[6ìë¦¬ë²ˆí˜¸].wav")
    print(f"   ê°ì • ë§¤í•‘: 000021-030(Anxious), 000031-040(Kind), 000091-100(Dry)")
    
    audio_paths, labels = load_dataset_from_numbered_folders(data_dir)
    print_data_summary(audio_paths, labels)
    
    if len(audio_paths) > 0:
        print(f"\nğŸ“„ ì²« 5ê°œ íŒŒì¼ ì˜ˆì‹œ:")
        for i in range(min(5, len(audio_paths))):
            filename = os.path.basename(audio_paths[i])
            print(f"   {i+1}. {filename} â†’ {labels[i]}")
    else:
        print(f"\nğŸ’¡ ë°ì´í„° í™•ì¸ íŒ:")
        print(f"   1. ê²½ë¡œê°€ ì˜¬ë°”ë¥¸ì§€ í™•ì¸: {data_dir}")
        print(f"   2. person í´ë” í•˜ìœ„ì— wav_48000 í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸")
        print(f"   3. íŒŒì¼ëª…ì´ [PERSON]_[6ìë¦¬ë²ˆí˜¸].wav íŒ¨í„´ì¸ì§€ í™•ì¸")
        print(f"   4. ë²ˆí˜¸ê°€ 21-30, 31-40, 91-100 ë²”ìœ„ì— ìˆëŠ”ì§€ í™•ì¸")

if __name__ == "__main__":
    # ëª…ë ¹í–‰ ì¸ìë¡œ í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì‹¤í–‰ ê°€ëŠ¥
    if len(sys.argv) > 1 and sys.argv[1] == "test":
        test_data_loading()
    else:
        main()