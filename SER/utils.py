import os
import re
import json
import pickle
import numpy as np
import torch
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Any, Optional, Tuple
import logging
from datetime import datetime
import yaml

def setup_logging(log_level: str = "INFO", log_file: Optional[str] = None):
    """ë¡œê¹… ì„¤ì •"""
    
    log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    
    # ë¡œê·¸ ë ˆë²¨ ì„¤ì •
    level = getattr(logging, log_level.upper(), logging.INFO)
    
    # í•¸ë“¤ëŸ¬ ì„¤ì •
    handlers = [logging.StreamHandler()]
    
    if log_file:
        handlers.append(logging.FileHandler(log_file, encoding='utf-8'))
    
    logging.basicConfig(
        level=level,
        format=log_format,
        handlers=handlers,
        force=True
    )
    
    return logging.getLogger(__name__)

def save_config_to_file(config_dict: Dict[str, Any], file_path: str):
    """ì„¤ì •ì„ íŒŒì¼ë¡œ ì €ì¥"""
    
    os.makedirs(os.path.dirname(file_path), exist_ok=True)
    
    if file_path.endswith('.json'):
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)
    elif file_path.endswith('.yaml') or file_path.endswith('.yml'):
        with open(file_path, 'w', encoding='utf-8') as f:
            yaml.dump(config_dict, f, default_flow_style=False, allow_unicode=True)
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .json ë˜ëŠ” .yaml/.ymlì„ ì‚¬ìš©í•˜ì„¸ìš”.")

def load_config_from_file(file_path: str) -> Dict[str, Any]:
    """íŒŒì¼ì—ì„œ ì„¤ì • ë¡œë“œ"""
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    
    if file_path.endswith('.json'):
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    elif file_path.endswith('.yaml') or file_path.endswith('.yml'):
        with open(file_path, 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .json ë˜ëŠ” .yaml/.ymlì„ ì‚¬ìš©í•˜ì„¸ìš”.")

def create_directory(dir_path: str, exist_ok: bool = True):
    """ë””ë ‰í† ë¦¬ ìƒì„±"""
    os.makedirs(dir_path, exist_ok=exist_ok)
    return dir_path

def get_device() -> torch.device:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ë””ë°”ì´ìŠ¤ ë°˜í™˜"""
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print(f"GPU ì‚¬ìš©: {torch.cuda.get_device_name()}")
    else:
        device = torch.device("cpu")
        print("CPU ì‚¬ìš©")
    
    return device

def count_parameters(model: torch.nn.Module) -> Dict[str, int]:
    """ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°"""
    
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    return {
        'total': total_params,
        'trainable': trainable_params,
        'non_trainable': total_params - trainable_params
    }

def format_time(seconds: float) -> str:
    """ì´ˆë¥¼ ì‹œ:ë¶„:ì´ˆ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    seconds = int(seconds % 60)
    
    if hours > 0:
        return f"{hours:02d}:{minutes:02d}:{seconds:02d}"
    else:
        return f"{minutes:02d}:{seconds:02d}"

def plot_training_history(history: Dict[str, List[float]], 
                         save_path: Optional[str] = None,
                         figsize: Tuple[int, int] = (12, 4)):
    """í›ˆë ¨ íˆìŠ¤í† ë¦¬ ì‹œê°í™”"""
    
    fig, axes = plt.subplots(1, 2, figsize=figsize)
    
    # Loss ê·¸ë˜í”„
    if 'train_loss' in history and 'val_loss' in history:
        axes[0].plot(history['train_loss'], label='Train Loss')
        axes[0].plot(history['val_loss'], label='Validation Loss')
        axes[0].set_title('Loss')
        axes[0].set_xlabel('Epoch')
        axes[0].set_ylabel('Loss')
        axes[0].legend()
        axes[0].grid(True)
    
    # Accuracy/F1 ê·¸ë˜í”„
    if 'val_accuracy' in history:
        axes[1].plot(history['val_accuracy'], label='Accuracy', color='green')
    if 'val_f1' in history:
        axes[1].plot(history['val_f1'], label='F1 Score', color='red')
    
    axes[1].set_title('Metrics')
    axes[1].set_xlabel('Epoch')
    axes[1].set_ylabel('Score')
    axes[1].legend()
    axes[1].grid(True)
    
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"í›ˆë ¨ íˆìŠ¤í† ë¦¬ ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")
    
    plt.show()

def calculate_class_weights(labels: List[str], emotion_labels: List[str]) -> torch.Tensor:
    """í´ë˜ìŠ¤ ë¶ˆê· í˜•ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    
    from collections import Counter
    from sklearn.utils.class_weight import compute_class_weight
    
    # ë¼ë²¨ ì¹´ìš´íŠ¸
    label_counts = Counter(labels)
    
    # ëª¨ë“  ê°ì •ì— ëŒ€í•œ ì¹´ìš´íŠ¸ (ì—†ëŠ” ê²½ìš° 0)
    class_counts = [label_counts.get(emotion, 0) for emotion in emotion_labels]
    
    # sklearnì„ ì‚¬ìš©í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°
    try:
        weights = compute_class_weight(
            'balanced',
            classes=np.arange(len(emotion_labels)),
            y=[emotion_labels.index(label) for label in labels]
        )
        return torch.FloatTensor(weights)
    except:
        # ê· ë“± ê°€ì¤‘ì¹˜ ë°˜í™˜
        return torch.ones(len(emotion_labels))

def save_predictions(predictions: List[Dict], 
                    save_path: str,
                    format: str = 'json'):
    """ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
    
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    
    if format.lower() == 'json':
        with open(save_path, 'w', encoding='utf-8') as f:
            json.dump(predictions, f, indent=2, ensure_ascii=False)
    
    elif format.lower() == 'csv':
        import pandas as pd
        
        # ì˜ˆì¸¡ ê²°ê³¼ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
        df_data = []
        for pred in predictions:
            if pred.get('status') == 'success':
                row = {
                    'audio_path': pred['audio_path'],
                    'predicted_emotion': pred['predicted_emotion'],
                    'confidence': pred.get('confidence', 0)
                }
                
                # ê° ê°ì •ë³„ í™•ë¥  ì¶”ê°€
                if 'probabilities' in pred:
                    for emotion, prob in pred['probabilities'].items():
                        row[f'prob_{emotion}'] = prob
                
                df_data.append(row)
        
        df = pd.DataFrame(df_data)
        df.to_csv(save_path, index=False, encoding='utf-8')
    
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹ì…ë‹ˆë‹¤. 'json' ë˜ëŠ” 'csv'ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")
    
    print(f"ì˜ˆì¸¡ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")

def load_predictions(file_path: str) -> List[Dict]:
    """ì €ì¥ëœ ì˜ˆì¸¡ ê²°ê³¼ ë¡œë“œ"""
    
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
    
    if file_path.endswith('.json'):
        with open(file_path, 'r', encoding='utf-8') as f:
            return json.load(f)
    
    elif file_path.endswith('.csv'):
        import pandas as pd
        df = pd.read_csv(file_path)
        
        predictions = []
        for _, row in df.iterrows():
            pred = {
                'audio_path': row['audio_path'],
                'predicted_emotion': row['predicted_emotion'],
                'confidence': row.get('confidence', 0),
                'status': 'success'
            }
            
            # ê°ì •ë³„ í™•ë¥  ë³µì›
            probabilities = {}
            for col in df.columns:
                if col.startswith('prob_'):
                    emotion = col.replace('prob_', '')
                    probabilities[emotion] = row[col]
            
            if probabilities:
                pred['probabilities'] = probabilities
            
            predictions.append(pred)
        
        return predictions
    
    else:
        raise ValueError("ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. .json ë˜ëŠ” .csvë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.")

def create_emotion_distribution_plot(predictions: List[Dict], 
                                   save_path: Optional[str] = None,
                                   figsize: Tuple[int, int] = (10, 6)):
    """ê°ì • ë¶„í¬ ì‹œê°í™”"""
    
    # ì„±ê³µì ì¸ ì˜ˆì¸¡ë§Œ í•„í„°ë§
    successful_preds = [p for p in predictions if p.get('status') == 'success']
    
    if not successful_preds:
        print("ì‹œê°í™”í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ê°ì •ë³„ ì¹´ìš´íŠ¸
    from collections import Counter
    emotion_counts = Counter([p['predicted_emotion'] for p in successful_preds])
    
    # ê·¸ë˜í”„ ìƒì„±
    emotions = list(emotion_counts.keys())
    counts = list(emotion_counts.values())
    
    plt.figure(figsize=figsize)
    bars = plt.bar(emotions, counts, alpha=0.8)
    
    # ê° ë°” ìœ„ì— ì¹´ìš´íŠ¸ í‘œì‹œ
    for bar, count in zip(bars, counts):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                str(count), ha='center', va='bottom')
    
    plt.title('Predicted Emotion Distribution')
    plt.xlabel('Emotions')
    plt.ylabel('Count')
    plt.xticks(rotation=45, ha='right')
    plt.grid(axis='y', alpha=0.3)
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ê°ì • ë¶„í¬ ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")
    
    plt.show()

def validate_audio_files(file_paths: List[str], 
                        valid_extensions: List[str] = None) -> Tuple[List[str], List[str]]:
    """ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ ê²€ì¦"""
    
    if valid_extensions is None:
        valid_extensions = ['.wav', '.mp3', '.m4a', '.flac', '.ogg']
    
    valid_files = []
    invalid_files = []
    
    for file_path in file_paths:
        # íŒŒì¼ ì¡´ì¬ í™•ì¸
        if not os.path.exists(file_path):
            invalid_files.append(f"{file_path} (íŒŒì¼ ì—†ìŒ)")
            continue
        
        # í™•ì¥ì í™•ì¸
        _, ext = os.path.splitext(file_path.lower())
        if ext not in valid_extensions:
            invalid_files.append(f"{file_path} (ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹)")
            continue
        
        # íŒŒì¼ í¬ê¸° í™•ì¸ (0ë°”ì´íŠ¸ê°€ ì•„ë‹Œì§€)
        if os.path.getsize(file_path) == 0:
            invalid_files.append(f"{file_path} (ë¹ˆ íŒŒì¼)")
            continue
        
        valid_files.append(file_path)
    
    return valid_files, invalid_files

def create_summary_report(model_info: Dict, 
                         training_results: Optional[Dict] = None,
                         evaluation_results: Optional[Dict] = None) -> str:
    """ì¢…í•© ë³´ê³ ì„œ ìƒì„±"""
    
    report_lines = []
    report_lines.append("=" * 80)
    report_lines.append("ìŒì„± ê°ì • ë¶„ì„ ëª¨ë¸ ì¢…í•© ë³´ê³ ì„œ")
    report_lines.append("=" * 80)
    report_lines.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    report_lines.append("")
    
    # ëª¨ë¸ ì •ë³´
    report_lines.append("ğŸ“‹ ëª¨ë¸ ì •ë³´")
    report_lines.append("-" * 40)
    for key, value in model_info.items():
        if isinstance(value, list):
            report_lines.append(f"  {key}: {', '.join(map(str, value))}")
        else:
            report_lines.append(f"  {key}: {value}")
    report_lines.append("")
    
    # í›ˆë ¨ ê²°ê³¼
    if training_results:
        report_lines.append("ğŸ”¥ í›ˆë ¨ ê²°ê³¼")
        report_lines.append("-" * 40)
        for key, value in training_results.items():
            if isinstance(value, float):
                report_lines.append(f"  {key}: {value:.4f}")
            else:
                report_lines.append(f"  {key}: {value}")
        report_lines.append("")
    
    # í‰ê°€ ê²°ê³¼
    if evaluation_results:
        report_lines.append("ğŸ“Š í‰ê°€ ê²°ê³¼")
        report_lines.append("-" * 40)
        
        if 'overall_metrics' in evaluation_results:
            overall = evaluation_results['overall_metrics']
            report_lines.append("  ì „ì²´ ì„±ëŠ¥:")
            for metric, value in overall.items():
                if isinstance(value, float):
                    report_lines.append(f"    {metric}: {value:.4f}")
                else:
                    report_lines.append(f"    {metric}: {value}")
        
        report_lines.append("")
    
    return "\n".join(report_lines)

class ModelCheckpoint:
    """ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê´€ë¦¬"""
    
    def __init__(self, checkpoint_dir: str, save_best_only: bool = True):
        self.checkpoint_dir = checkpoint_dir
        self.save_best_only = save_best_only
        self.best_score = -float('inf')
        
        os.makedirs(checkpoint_dir, exist_ok=True)
    
    def save(self, model, optimizer, epoch: int, score: float, 
             is_best: bool = False, extra_info: Optional[Dict] = None):
        """ì²´í¬í¬ì¸íŠ¸ ì €ì¥"""
        
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'score': score,
            'timestamp': datetime.now().isoformat()
        }
        
        if extra_info:
            checkpoint.update(extra_info)
        
        # ìµœì‹  ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if not self.save_best_only:
            checkpoint_path = os.path.join(self.checkpoint_dir, f'checkpoint_epoch_{epoch}.pt')
            torch.save(checkpoint, checkpoint_path)
        
        # ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ì €ì¥
        if is_best or score > self.best_score:
            self.best_score = score
            best_path = os.path.join(self.checkpoint_dir, 'best_checkpoint.pt')
            torch.save(checkpoint, best_path)
            print(f"ìµœê³  ì„±ëŠ¥ ì²´í¬í¬ì¸íŠ¸ ì €ì¥: {best_path} (score: {score:.4f})")
    
    def load(self, checkpoint_path: str, model, optimizer=None):
        """ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ"""
        
        if not os.path.exists(checkpoint_path):
            raise FileNotFoundError(f"ì²´í¬í¬ì¸íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {checkpoint_path}")
        
        checkpoint = torch.load(checkpoint_path, map_location='cpu')
        
        model.load_state_dict(checkpoint['model_state_dict'])
        
        if optimizer and 'optimizer_state_dict' in checkpoint:
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        
        epoch = checkpoint.get('epoch', 0)
        score = checkpoint.get('score', 0)
        
        print(f"ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ ì™„ë£Œ: epoch {epoch}, score {score:.4f}")
        
        return epoch, score, checkpoint

def print_system_info():
    """ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥"""
    
    print("=" * 60)
    print("ì‹œìŠ¤í…œ ì •ë³´")
    print("=" * 60)
    
    # Python ì •ë³´
    import sys
    print(f"Python ë²„ì „: {sys.version}")
    
    # PyTorch ì •ë³´
    print(f"PyTorch ë²„ì „: {torch.__version__}")
    print(f"CUDA ì‚¬ìš© ê°€ëŠ¥: {torch.cuda.is_available()}")
    
    if torch.cuda.is_available():
        print(f"CUDA ë²„ì „: {torch.version.cuda}")
        print(f"GPU ê°œìˆ˜: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"  GPU {i}: {torch.cuda.get_device_name(i)}")
    
    # ë©”ëª¨ë¦¬ ì •ë³´
    try:
        import psutil
        memory = psutil.virtual_memory()
        print(f"ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬: {memory.total // (1024**3):.1f}GB (ì‚¬ìš©ë¥ : {memory.percent}%)")
    except ImportError:
        pass
    
    print("=" * 60)

def extract_number_from_filename(filename: str) -> Optional[int]:
    """F####_######.wav í˜•ì‹ì—ì„œ ë§ˆì§€ë§‰ í•œ ìë¦¬ ì¶”ì¶œ"""
    try:
        # Fë¡œ ì‹œì‘í•˜ëŠ” ëª¨ë“  íŒŒì¼ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ìì˜ ë§ˆì§€ë§‰ í•œ ìë¦¬ ì¶”ì¶œ
        match = re.search(r'F\d+_\d*(\d)\.wav', filename)
        if match:
            return int(match.group(1))
        return None
    except (ValueError, AttributeError):
        return None

def get_emotion_from_filename(filename: str) -> Optional[str]:
    """íŒŒì¼ëª…ì—ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ê°ì • ë¼ë²¨ ë°˜í™˜"""
    try:
        match = re.search(r'_(\d{6})\.', filename)
        if not match:
            return None
        
        file_num = int(match.group(1))
        
        if 21 <= file_num <= 30:
            return "Anxious"
        elif 31 <= file_num <= 40:
            return "Kind"
        elif 91 <= file_num <= 100:
            return "Dry"
        else:
            return None
    except (ValueError, AttributeError):
        return None