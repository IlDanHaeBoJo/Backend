import numpy as np
from typing import Tuple, List, Optional, Literal
from collections import Counter
import re
import os
import random
from tqdm import tqdm

EMOTION_LABELS = ["Anxious", "Dry", "Kind"]

def simple_augmentation(audio: np.ndarray, sample_rate: int) -> np.ndarray:
    """ê°„ë‹¨í•œ ì˜¤ë””ì˜¤ ì¦ê°• (NumPy 2.x í˜¸í™˜)"""
    if np.random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ë…¸ì´ì¦ˆ ì¶”ê°€
        noise = np.random.normal(0, 0.005, audio.shape)
        audio = audio + noise
    
    if np.random.random() < 0.3:  # 30% í™•ë¥ ë¡œ ë³¼ë¥¨ ì¡°ì •
        volume_factor = np.random.uniform(0.8, 1.2)
        audio = audio * volume_factor
    
    return audio





def extract_number_from_filename(filename: str, type: Literal['content', 'emotion'] = 'emotion') -> Optional[int]:
    try:
        if type == "content":
            # íŒŒì¼ëª…ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì ê·¸ë£¹ ì „ì²´ë¥¼ ì¶”ì¶œ (ì˜ˆ: F2001_000123.wav -> 123)
            match = re.search(r'_(\d+)\.wav$', os.path.basename(filename))
            if match:
                return int(match.group(1))
            return None
        else:
            # F..._...xxxD.wav ì—ì„œ ë§ˆì§€ë§‰ ìˆ«ì Dë¥¼ ì¶”ì¶œ
            match = re.search(r'_(\d+)\.wav$', os.path.basename(filename))
            if match:
                return int(match.group(1)) % 10
            return None
    except (ValueError, AttributeError):
        return None



def get_emotion_from_filename(filename: str) -> Optional[str]:
    """íŒŒì¼ëª…ì—ì„œ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ê°ì • ë¼ë²¨ ë°˜í™˜"""
    file_num = extract_number_from_filename(filename, type="content")
    if file_num is None:
        return None
        
    if 21 <= file_num <= 30:
        return "Anxious"
    elif 31 <= file_num <= 40:
        return "Kind"
    elif 141 <= file_num <= 150:
        return "Dry"
    else:
        return None


# ë°ì´í„° ì „ì²´ë¥¼ ìŠ¤ìº”í•´ì„œ (ê²½ë¡œ, ê°ì •, í™”ì, ìŠ¤í¬ë¦½íŠ¸ID) ì¸ë±ìŠ¤ ìƒì„±
def build_corpus_index(data_dir: str,
                       accept_exts={'.wav', '.flac'},
                       require_emotion=True) -> List[Dict[str, Any]]:
    """
    return: [{"path": p, "emotion": e, "speaker": s, "content_id": c}, ...]
    """
    index = []
    speakers = sorted([d for d in os.listdir(data_dir)
                       if os.path.isdir(os.path.join(data_dir, d))])
    print(f"ğŸ“ í™”ì í´ë” ìˆ˜: {len(speakers)}")

    for spk in tqdm(speakers, desc="ì¸ë±ìŠ¤ êµ¬ì¶•"):
        spk_dir = os.path.join(data_dir, spk)
        # í•˜ìœ„ ë””ë ‰í† ë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ íƒìƒ‰ (ê°ì •ë³„ í´ë”/ë‹¨ì¼ í´ë” ë‘˜ ë‹¤ ëŒ€ì‘)
        for root, _, files in os.walk(spk_dir):
            for fn in files:
                ext = os.path.splitext(fn)[1].lower()
                if ext not in accept_exts:
                    continue
                path = os.path.join(root, fn)

                # ê°ì • ë¼ë²¨
                emo = infer_emotion_from_path(path)
                if require_emotion and emo not in EMOTION_LABELS:
                    # ê°ì • ë¯¸ë§¤ì¹­ ìƒ˜í”Œì€ ì œì™¸
                    continue

                # ìŠ¤í¬ë¦½íŠ¸(ëŒ€í™”) ID: íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ (ê¸°ì¡´ ê·œì¹™ ê·¸ëŒ€ë¡œ)
                cid = extract_number_from_filename(fn, type="content")
                if cid is None:
                    # ìŠ¤í¬ë¦½íŠ¸ ID ì—†ìœ¼ë©´ ì œì™¸(ë¶ˆêµì°¨ ì¡°ê±´ì„ ë³´ì¥í•˜ê¸° ìœ„í•´)
                    continue

                index.append({
                    "path": path,
                    "emotion": emo,
                    "speaker": spk,
                    "content_id": cid
                })
    print(f"âœ… ì¸ë±ìŠ¤ ìƒ˜í”Œ ìˆ˜: {len(index)}")
    return index


def split_speaker_and_content(
    index: List[Dict[str, Any]],
    val_content_ratio: float = 0.2,
    test_content_ratio: float = 0.2,
    val_speaker_ratio: float = 0.2,
    test_speaker_ratio: float = 0.2,
    seed: int = 42,
    fixed_val_content_ids: Optional[List[int]] = None,
    fixed_test_content_ids: Optional[List[int]] = None,
) -> Tuple[Tuple[List[str], List[str]],
           Tuple[List[str], List[str]],
           Tuple[List[str], List[str]]]:
    """
    index: build_corpus_index() ë°˜í™˜ ë¦¬ìŠ¤íŠ¸
    ë°˜í™˜: ((train_paths, train_labels), (val_paths, val_labels), (test_paths, test_labels))
    """
    rng = random.Random(seed)

    # ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ ID, í™”ì ëª©ë¡
    all_contents = sorted(set([it["content_id"] for it in index]))
    all_speakers = sorted(set([it["speaker"] for it in index]))

    # --- 2-1) ìŠ¤í¬ë¦½íŠ¸(ëŒ€í™”) ë¶ˆêµì°¨ ì„¸íŠ¸ ë§Œë“¤ê¸°
    if fixed_val_content_ids is not None and fixed_test_content_ids is not None:
        val_contents = set(fixed_val_content_ids)
        test_contents = set(fixed_test_content_ids)
        train_contents = set(all_contents) - val_contents - test_contents
    else:
        contents = all_contents[:]
        rng.shuffle(contents)
        n_val = max(1, int(len(contents) * val_content_ratio))
        n_test = max(1, int(len(contents) * test_content_ratio))
        val_contents = set(contents[:n_val])
        test_contents = set(contents[n_val:n_val+n_test])
        train_contents = set(contents[n_val+n_test:])

    # --- 2-2) í™”ì ë¶ˆêµì°¨ ì„¸íŠ¸ ë§Œë“¤ê¸°
    speakers = all_speakers[:]
    rng.shuffle(speakers)
    n_val_spk = max(1, int(len(speakers) * val_speaker_ratio))
    n_test_spk = max(1, int(len(speakers) * test_speaker_ratio))
    val_speakers = set(speakers[:n_val_spk])
    test_speakers = set(speakers[n_val_spk:n_val_spk+n_test_spk])
    train_speakers = set(speakers[n_val_spk+n_test_spk:])

    # --- 2-3) êµì§‘í•© ì œê±°: ë‘ ì¡°ê±´(í™”ì ì„¸íŠ¸, ìŠ¤í¬ë¦½íŠ¸ ì„¸íŠ¸)ì„ ë™ì‹œì— ë§Œì¡±í•˜ëŠ” ìƒ˜í”Œë§Œ ì±„íƒ
    train_items = [it for it in index
                   if it["speaker"] in train_speakers and it["content_id"] in train_contents]
    val_items   = [it for it in index
                   if it["speaker"] in val_speakers and it["content_id"] in val_contents]
    test_items  = [it for it in index
                   if it["speaker"] in test_speakers and it["content_id"] in test_contents]

    # --- 2-4) ì ê²€ ì¶œë ¥
    def summarize(name, items):
        spks = sorted(set([it["speaker"] for it in items]))
        cids = sorted(set([it["content_id"] for it in items]))
        emo_cnt = Counter([it["emotion"] for it in items])
        print(f"\n[{name}] ìƒ˜í”Œ: {len(items)}, í™”ì: {len(spks)}, ìŠ¤í¬ë¦½íŠ¸ID: {len(cids)}")
        print(f"  ê°ì •ë¶„í¬: {dict(emo_cnt)}")
        print(f"  ì˜ˆì‹œ í™”ì(ìµœëŒ€ 10): {spks[:10]}")
        print(f"  ì˜ˆì‹œ ìŠ¤í¬ë¦½íŠ¸ID(ìµœëŒ€ 20): {cids[:20]}")

    summarize("TRAIN", train_items)
    summarize("VAL",   val_items)
    summarize("TEST",  test_items)

    # --- 2-5) êµì°¨ ê²€ì¦: í™”ì/ìŠ¤í¬ë¦½íŠ¸ ë¶ˆêµì°¨ ì—¬ë¶€ í™•ì¸
    assert set([it["speaker"] for it in train_items]).isdisjoint(set([it["speaker"] for it in val_items + test_items])), \
        "Train í™”ìê°€ Val/Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([it["speaker"] for it in val_items]).isdisjoint(set([it["speaker"] for it in test_items])), \
        "Val í™”ìê°€ Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([it["content_id"] for it in train_items]).isdisjoint(set([it["content_id"] for it in val_items + test_items])), \
        "Train ìŠ¤í¬ë¦½íŠ¸IDê°€ Val/Testì™€ ê²¹ì¹©ë‹ˆë‹¤."
    assert set([it["content_id"] for it in val_items]).isdisjoint(set([it["content_id"] for it in test_items])), \
        "Val ìŠ¤í¬ë¦½íŠ¸IDê°€ Testì™€ ê²¹ì¹©ë‹ˆë‹¤."

    # --- 2-6) ìµœì¢… ë¦¬ìŠ¤íŠ¸ ë³€í™˜
    def to_xy(items):
        return [it["path"] for it in items], [it["emotion"] for it in items]

    return to_xy(train_items), to_xy(val_items), to_xy(test_items)


def load_dataset_subset(data_dir: str, max_per_class: int) -> Tuple[List[str], List[str]]:
    audio_paths = []
    labels = []
    emotion_counts = {label: 0 for label in EMOTION_LABELS}
    
    person_folders = sorted([f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))])
    print(f"ğŸ“ ë°œê²¬ëœ person í´ë”: {len(person_folders)}ê°œ")
    
    for person_folder in tqdm(person_folders, desc="ë°ì´í„°ì…‹ ë¡œë”© ì¤‘"):
        wav_path = os.path.join(data_dir, person_folder, "wav_48000")
        if not os.path.exists(wav_path):
            continue
        
        for audio_file in os.listdir(wav_path):
            if not audio_file.lower().endswith('.wav'):
                continue
            
            emotion_label = get_emotion_from_filename(audio_file)
            if emotion_label and emotion_counts[emotion_label] < max_per_class:
                audio_paths.append(os.path.join(wav_path, audio_file))
                labels.append(emotion_label)
                emotion_counts[emotion_label] += 1
        
        if all(count >= max_per_class for count in emotion_counts.values()):
            break

    print(f"\nğŸ“Š ë¡œë“œëœ ë°ì´í„° ë¶„í¬ (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ìš©):")
    for emotion, count in emotion_counts.items():
        percentage = (count / len(audio_paths) * 100) if len(audio_paths) > 0 else 0
        print(f"  {emotion}: {count}ê°œ ({percentage:.1f}%)")
            
    return audio_paths, labels


# (í•„ìˆ˜) í™”ì ID ì¶”ì¶œ: data_dir ë°”ë¡œ ì•„ë˜ 1ë‹¨ê³„ í´ë”ëª…ì´ í™”ì
def extract_speaker_id(audio_path: str, data_dir: str) -> str:
    rel = os.path.relpath(audio_path, data_dir)
    spk = rel.split(os.sep)[0]
    return spk



def build_speaker_mapping(train_paths, data_dir):
    train_speakers = sorted({extract_speaker_id(p, data_dir) for p in train_paths})
    spk2id = {spk: i for i, spk in enumerate(train_speakers)}
    return spk2id



# (ì„ íƒ) ê²½ë¡œì—ì„œ ê°ì • ë¼ë²¨ ì¶”ë¡  (í´ë”ëª…ì— Anxious/Kind/Dryê°€ ìˆìœ¼ë©´ ê·¸ê±¸ ì‚¬ìš©)
def infer_emotion_from_path(audio_path: str) -> Optional[str]:
    parts = os.path.normpath(audio_path).split(os.sep)
    for p in reversed(parts):
        if p in EMOTION_LABELS:
            return p
    # í´ë”ëª…ì— ì—†ìœ¼ë©´ íŒŒì¼ëª… ê·œì¹™ìœ¼ë¡œ ì¶”ë¡  (ê¸°ì¡´ í•¨ìˆ˜)
    return get_emotion_from_filename(os.path.basename(audio_path))





