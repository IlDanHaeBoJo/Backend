"""
SER ëª¨ë“ˆ ì‚¬ìš© ì˜ˆì‹œ
"""

import os
import sys

# SER ëª¨ë“ˆì„ ì‚¬ìš©í•˜ê¸° ìœ„í•´ Backend ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from SER.config import model_config, training_config, data_config
from SER.model import create_model
from SER.trainer import create_trainer
from SER.inference import create_inference_engine
from SER.data_loader import load_dataset_from_directory, create_data_splits
from SER.utils import setup_logging, print_system_info

def example_training():
    """í›ˆë ¨ ì˜ˆì‹œ"""
    
    print("=" * 60)
    print("ğŸ“š ìŒì„± ê°ì • ë¶„ì„ ëª¨ë¸ í›ˆë ¨ ì˜ˆì‹œ")
    print("=" * 60)
    
    # ë¡œê¹… ì„¤ì •
    logger = setup_logging(log_level="INFO")
    
    # ì‹œìŠ¤í…œ ì •ë³´ ì¶œë ¥
    print_system_info()
    
    # ì„¤ì • í™•ì¸
    print(f"ğŸ¯ ì‚¬ìš©í•  ëª¨ë¸: {model_config.model_name}")
    print(f"ğŸ“Š ê°ì • í´ë˜ìŠ¤ ìˆ˜: {model_config.num_labels}")
    print(f"ğŸµ ìƒ˜í”Œë§ ë ˆì´íŠ¸: {model_config.sampling_rate}Hz")
    print(f"â±ï¸ ìµœëŒ€ ê¸¸ì´: {model_config.max_duration}ì´ˆ")
    print(f"ğŸ’¾ ëª¨ë¸ í¬ê¸°: 317M íŒŒë¼ë¯¸í„° (kresnik í•œêµ­ì–´ ASR ëª¨ë¸)")
    print(f"ğŸ† ì›ë³¸ ì„±ëŠ¥: WER 4.74%, CER 1.78% (Zeroth-Korean)")
    print()
    
    # ë°ì´í„° ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œë¡œ ë³€ê²½ í•„ìš”)
    data_directory = "./data/emotions"  # ì‹¤ì œ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
    
    if not os.path.exists(data_directory):
        print(f"âš ï¸ ë°ì´í„° ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_directory}")
        print("ğŸ“ ì‹¤ì œ ë°ì´í„°ë¥¼ ì¤€ë¹„í•œ í›„ ê²½ë¡œë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
        print("\nì˜ˆìƒ êµ¬ì¡°:")
        print("data/emotions/")
        print("â”œâ”€â”€ Neutral/")
        print("â”‚   â”œâ”€â”€ file1.wav")
        print("â”‚   â””â”€â”€ file2.wav")
        print("â”œâ”€â”€ Angry/")
        print("â”‚   â”œâ”€â”€ file3.wav")
        print("â”‚   â””â”€â”€ file4.wav")
        print("â””â”€â”€ ...")
        return
    
    try:
        # ë°ì´í„° ë¡œë“œ
        print("ğŸ“ ë°ì´í„° ë¡œë“œ ì¤‘...")
        audio_paths, labels = load_dataset_from_directory(data_directory)
        
        if len(audio_paths) == 0:
            print("âŒ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print(f"âœ… {len(audio_paths)}ê°œì˜ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ë¶„í• 
        print("ğŸ”„ ë°ì´í„° ë¶„í•  ì¤‘...")
        train_data, val_data, test_data = create_data_splits(
            audio_paths, labels,
            train_ratio=0.8,
            val_ratio=0.1,
            test_ratio=0.1
        )
        
        # kresnik ëª¨ë¸ì— ìµœì í™”ëœ í›ˆë ¨ ì„¤ì •
        training_config.batch_size = 2  # 317M íŒŒë¼ë¯¸í„° ëª¨ë¸ìš© ì‘ì€ ë°°ì¹˜
        training_config.gradient_accumulation_steps = 8  # íš¨ê³¼ì  ë°°ì¹˜ í¬ê¸° = 16
        training_config.learning_rate = 3e-5  # í° ëª¨ë¸ì— ì í•©í•œ ë‚®ì€ í•™ìŠµë¥ 
        training_config.num_epochs = 3  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´
        training_config.warmup_steps = 500  # ì§§ì€ í…ŒìŠ¤íŠ¸ìš© ì›œì—…
        training_config.output_dir = "./results"
        
        print(f"âš™ï¸ kresnik ëª¨ë¸ ìµœì í™” ì„¤ì •:")
        print(f"  ë°°ì¹˜ í¬ê¸°: {training_config.batch_size}")
        print(f"  Gradient ëˆ„ì : {training_config.gradient_accumulation_steps}")
        print(f"  íš¨ê³¼ì  ë°°ì¹˜ í¬ê¸°: {training_config.batch_size * training_config.gradient_accumulation_steps}")
        print(f"  í•™ìŠµë¥ : {training_config.learning_rate}")
        print()
        
        # ëª¨ë¸ ìƒì„±
        print("ğŸ¤– ëª¨ë¸ ìƒì„± ì¤‘...")
        model = create_model()
        
        # í›ˆë ¨ê¸° ìƒì„±
        print("ğŸ‹ï¸ í›ˆë ¨ ì¤€ë¹„ ì¤‘...")
        trainer = create_trainer(model)
        
        # í›ˆë ¨ ì‹¤í–‰
        print("ğŸš€ í›ˆë ¨ ì‹œì‘!")
        trainer.train(
            train_data=train_data,
            val_data=val_data,
            test_data=test_data
        )
        
        # í‰ê°€
        print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
        eval_results = trainer.evaluate()
        
        if eval_results:
            print(f"âœ… ìµœì¢… ì •í™•ë„: {eval_results.get('eval_accuracy', 'N/A'):.4f}")
            print(f"âœ… ìµœì¢… F1 ìŠ¤ì½”ì–´: {eval_results.get('eval_f1', 'N/A'):.4f}")
        
        print("ğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e

def example_inference():
    """ì¶”ë¡  ì˜ˆì‹œ"""
    
    print("=" * 60)
    print("ğŸ”® ìŒì„± ê°ì • ë¶„ì„ ì¶”ë¡  ì˜ˆì‹œ")
    print("=" * 60)
    
    model_path = "./results"  # í›ˆë ¨ëœ ëª¨ë¸ ê²½ë¡œ
    
    if not os.path.exists(model_path):
        print(f"âš ï¸ í›ˆë ¨ëœ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        print("ğŸ“ ë¨¼ì € ëª¨ë¸ì„ í›ˆë ¨í•˜ê±°ë‚˜ ì˜¬ë°”ë¥¸ ê²½ë¡œë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
        return
    
    try:
        # ì¶”ë¡  ì—”ì§„ ìƒì„±
        print("ğŸ§  ì¶”ë¡  ì—”ì§„ ë¡œë“œ ì¤‘...")
        inference = create_inference_engine(model_path)
        
        # ëª¨ë¸ ì •ë³´ ì¶œë ¥
        model_info = inference.get_model_info()
        print("ğŸ“‹ ëª¨ë¸ ì •ë³´:")
        for key, value in model_info.items():
            print(f"  {key}: {value}")
        print()
        
        # ë‹¨ì¼ íŒŒì¼ ì˜ˆì¸¡ ì˜ˆì‹œ
        audio_file = "sample_audio.wav"  # ì‹¤ì œ ì˜¤ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        
        if os.path.exists(audio_file):
            print(f"ğŸµ ë‹¨ì¼ íŒŒì¼ ì˜ˆì¸¡: {audio_file}")
            result = inference.predict_single(audio_file)
            
            if result['status'] == 'success':
                print(f"  ì˜ˆì¸¡ ê°ì •: {result['predicted_emotion']}")
                print(f"  ì‹ ë¢°ë„: {result['confidence']:.4f}")
                print("  ëª¨ë“  ê°ì •ë³„ í™•ë¥ :")
                for emotion, prob in result['probabilities'].items():
                    print(f"    {emotion}: {prob:.4f}")
            else:
                print(f"  ì˜ˆì¸¡ ì‹¤íŒ¨: {result['error']}")
        else:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_file}")
        
        # ë””ë ‰í† ë¦¬ ë°°ì¹˜ ì˜ˆì¸¡ ì˜ˆì‹œ
        test_directory = "./test_audio"  # í…ŒìŠ¤íŠ¸ ì˜¤ë””ì˜¤ ë””ë ‰í† ë¦¬
        
        if os.path.exists(test_directory):
            print(f"\nğŸ“ ë””ë ‰í† ë¦¬ ë°°ì¹˜ ì˜ˆì¸¡: {test_directory}")
            results = inference.predict_directory(test_directory)
            
            # ê°ì • ë¶„í¬ ë¶„ì„
            distribution = inference.analyze_emotions_distribution(results)
            
            if 'error' not in distribution:
                print(f"  ì´ ìƒ˜í”Œ: {distribution['total_samples']}ê°œ")
                print(f"  í‰ê·  ì‹ ë¢°ë„: {distribution['average_confidence']:.4f}")
                print("  ê°ì •ë³„ ë¶„í¬:")
                
                for emotion, count in distribution['emotion_counts'].items():
                    percentage = distribution['emotion_percentages'][emotion]
                    print(f"    {emotion}: {count}ê°œ ({percentage:.1f}%)")
            else:
                print(f"  ë¶„ì„ ì‹¤íŒ¨: {distribution['error']}")
        else:
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {test_directory}")
        
        print("ğŸ‰ ì¶”ë¡  ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì¶”ë¡  ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        raise e

def example_configuration():
    """ì„¤ì • ì˜ˆì‹œ"""
    
    print("=" * 60)
    print("âš™ï¸ ì„¤ì • ì»¤ìŠ¤í„°ë§ˆì´ì§• ì˜ˆì‹œ")
    print("=" * 60)
    
    # ê¸°ë³¸ ì„¤ì • í™•ì¸
    print("ğŸ“‹ í˜„ì¬ ëª¨ë¸ ì„¤ì •:")
    print(f"  ëª¨ë¸ëª…: {model_config.model_name}")
    print(f"  ê°ì • í´ë˜ìŠ¤: {model_config.emotion_labels}")
    print(f"  ìƒ˜í”Œë§ ë ˆì´íŠ¸: {model_config.sampling_rate}")
    print(f"  ìµœëŒ€ ê¸¸ì´: {model_config.max_duration}")
    print()
    
    print("ğŸ“‹ í˜„ì¬ í›ˆë ¨ ì„¤ì •:")
    print(f"  ë°°ì¹˜ í¬ê¸°: {training_config.batch_size}")
    print(f"  í•™ìŠµë¥ : {training_config.learning_rate}")
    print(f"  ì—í¬í¬ ìˆ˜: {training_config.num_epochs}")
    print(f"  ì¶œë ¥ ë””ë ‰í† ë¦¬: {training_config.output_dir}")
    print()
    
    print("ğŸ“‹ í˜„ì¬ ë°ì´í„° ì„¤ì •:")
    print(f"  ì •ê·œí™”: {data_config.normalize_audio}")
    print(f"  ë…¸ì´ì¦ˆ ì œê±°: {data_config.apply_noise_reduction}")
    print(f"  ë°ì´í„° ì¦ê°•: {data_config.data_augmentation}")
    print()
    
    # ì„¤ì • ìˆ˜ì • ì˜ˆì‹œ
    print("ğŸ”§ ì„¤ì • ìˆ˜ì • ì˜ˆì‹œ:")
    
    # ëª¨ë¸ ì„¤ì • ìˆ˜ì •
    original_duration = model_config.max_duration
    model_config.max_duration = 8.0
    print(f"  ìµœëŒ€ ì˜¤ë””ì˜¤ ê¸¸ì´: {original_duration} â†’ {model_config.max_duration}")
    
    # í›ˆë ¨ ì„¤ì • ìˆ˜ì •
    original_batch_size = training_config.batch_size
    training_config.batch_size = 16
    print(f"  ë°°ì¹˜ í¬ê¸°: {original_batch_size} â†’ {training_config.batch_size}")
    
    original_lr = training_config.learning_rate
    training_config.learning_rate = 5e-5
    print(f"  í•™ìŠµë¥ : {original_lr} â†’ {training_config.learning_rate}")
    
    # ë°ì´í„° ì„¤ì • ìˆ˜ì •
    original_augmentation = data_config.data_augmentation
    data_config.data_augmentation = True
    print(f"  ë°ì´í„° ì¦ê°•: {original_augmentation} â†’ {data_config.data_augmentation}")
    
    print("\nâœ… ì„¤ì •ì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤!")

def example_utils():
    """ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì˜ˆì‹œ"""
    
    print("=" * 60)
    print("ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ì˜ˆì‹œ")
    print("=" * 60)
    
    from SER.utils import (
        validate_audio_files, 
        create_emotion_distribution_plot,
        save_predictions,
        create_summary_report
    )
    
    # ì˜¤ë””ì˜¤ íŒŒì¼ ê²€ì¦ ì˜ˆì‹œ
    test_files = ["audio1.wav", "audio2.mp3", "nonexistent.wav", "invalid.txt"]
    valid_files, invalid_files = validate_audio_files(test_files)
    
    print("ğŸ“ íŒŒì¼ ê²€ì¦ ê²°ê³¼:")
    print(f"  ìœ íš¨í•œ íŒŒì¼: {valid_files}")
    print(f"  ë¬´íš¨í•œ íŒŒì¼: {invalid_files}")
    print()
    
    # ë”ë¯¸ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±
    dummy_predictions = [
        {'predicted_emotion': 'Joy', 'confidence': 0.85, 'status': 'success'},
        {'predicted_emotion': 'Neutral', 'confidence': 0.92, 'status': 'success'},
        {'predicted_emotion': 'Sad', 'confidence': 0.78, 'status': 'success'},
        {'predicted_emotion': 'Angry', 'confidence': 0.89, 'status': 'success'},
    ]
    
    # ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì˜ˆì‹œ
    print("ğŸ’¾ ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥:")
    save_predictions(dummy_predictions, "example_predictions.json", format='json')
    print("  JSON í˜•ì‹ìœ¼ë¡œ ì €ì¥ ì™„ë£Œ")
    
    # ìš”ì•½ ë³´ê³ ì„œ ìƒì„± ì˜ˆì‹œ
    print("\nğŸ“Š ìš”ì•½ ë³´ê³ ì„œ ìƒì„±:")
    model_info = {
        'model_name': model_config.model_name,
        'num_labels': model_config.num_labels,
        'emotion_labels': model_config.emotion_labels
    }
    
    training_results = {
        'final_accuracy': 0.85,
        'final_f1_score': 0.82,
        'training_time': '2h 30m'
    }
    
    report = create_summary_report(model_info, training_results)
    print(report)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    
    print("ğŸ¤ SER (Speech Emotion Recognition) ëª¨ë“ˆ ì˜ˆì‹œ")
    print("=" * 60)
    
    while True:
        print("\nì„ íƒí•˜ì„¸ìš”:")
        print("1. ğŸ“š í›ˆë ¨ ì˜ˆì‹œ")
        print("2. ğŸ”® ì¶”ë¡  ì˜ˆì‹œ") 
        print("3. âš™ï¸ ì„¤ì • ì˜ˆì‹œ")
        print("4. ğŸ› ï¸ ìœ í‹¸ë¦¬í‹° ì˜ˆì‹œ")
        print("0. ì¢…ë£Œ")
        
        choice = input("\në²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”: ").strip()
        
        if choice == '1':
            example_training()
        elif choice == '2':
            example_inference()
        elif choice == '3':
            example_configuration()
        elif choice == '4':
            example_utils()
        elif choice == '0':
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

if __name__ == "__main__":
    main()